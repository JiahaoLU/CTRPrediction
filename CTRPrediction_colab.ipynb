{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CTRPrediction_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "14BAV0L--W8SLx2nrYIB4fN8nUmp-ChQS",
      "authorship_tag": "ABX9TyMfHjGPpoykmLCFPpe/RWhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiahaoLU/CTRPrediction/blob/Jiahao/CTRPrediction_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-4a8uQXyo-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cebe125b-a360-4d32-b424-4f25861eb543"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "octJXhQRlVgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class DataPreprocessor(Dataset):\n",
        "\n",
        "    def __init__(self, path=None):\n",
        "        \"\"\"\n",
        "        Initialise the preprocessor as a Data set in torch\n",
        "        or initialise it as a data provider (cut smaller data, etc)\n",
        "        :param path: file path\n",
        "        \"\"\"\n",
        "        if path is not None:\n",
        "            self.path = path\n",
        "            self.data = self.read_data_by_chunk()\n",
        "            self.labels = np.asarray(self.data.iloc[:, 1])\n",
        "            self.one_hot_data = self.get_one_hot_dataset()\n",
        "            print('Data set initiated from {0}.'.format(self.path))\n",
        "        else:\n",
        "            self.path = './Data/train.csv'\n",
        "            print('Data provider is ready.')\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        return number of data\n",
        "        \"\"\"\n",
        "        return np.size(self.one_hot_data, 0)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        called when iterate on Data Loader\n",
        "        :param index: index of one sample\n",
        "        :return: one hot encoding of a sample, which consists of field-relative index of value 1,\n",
        "                 and corresponding label\n",
        "        \"\"\"\n",
        "        return self.one_hot_data[index], self.labels[index]\n",
        "\n",
        "    def open_csv(self, iterator=False):\n",
        "        \"\"\"\n",
        "        Open a csv file\n",
        "        :param iterator: Open a csv file as iterator/or not\n",
        "        :return: pandas data frame\n",
        "        \"\"\"\n",
        "        try:\n",
        "            csv_file = pd.read_csv(self.path, sep=',', engine='python', iterator=iterator)\n",
        "            if csv_file is None:\n",
        "              print(\"file empty\")\n",
        "            return csv_file\n",
        "        except FileNotFoundError:\n",
        "            print(\"file not found\")\n",
        "\n",
        "    def cut_smaller_data_for_exam(self, new_path, size=2000, skip_size=40000):\n",
        "        \"\"\"\n",
        "        Cut a smaller data set for debugging code of size (smaller_data_size, num_fields + 2)\n",
        "        :param new_path: name and path for new csv file\n",
        "        :param size: the size of the smaller data set\n",
        "        :param skip_size: interval to skip to retrieve data uniformly from original set\n",
        "        :return: none\n",
        "        \"\"\"\n",
        "        print(\"Producing smaller data\")\n",
        "        print(\"Read file\")\n",
        "        data_file = self.open_csv(iterator=True)\n",
        "\n",
        "        print(\"cut by chunk\")\n",
        "        chunk_size = 100\n",
        "        loops = math.floor(size/chunk_size)\n",
        "        chunks = []\n",
        "        for loop in range(loops * 2):\n",
        "            try:\n",
        "                print(\"chunk: \", loop)\n",
        "                if loop % 2 == 0:  # avoid load data of same timestamp\n",
        "                    chunk = data_file.get_chunk(chunk_size)\n",
        "                    chunks.append(chunk)\n",
        "                else:\n",
        "                    chunk = data_file.get_chunk(skip_size)\n",
        "                    del chunk\n",
        "            except StopIteration:\n",
        "                print(\"Iteration is stopped.\")\n",
        "\n",
        "        print('Start concatenation')\n",
        "        data_frame = pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "        if os.path.exists(new_path):\n",
        "            os.remove(new_path)\n",
        "        data_frame.to_csv(new_path, index=False)\n",
        "        print(\"New smaller file created\")\n",
        "\n",
        "    def read_data_by_chunk(self, chunk_size=1000000):\n",
        "        \"\"\"\n",
        "        Read csv by chunk to avoid drive memory overflow\n",
        "        :param chunk_size: the size of data to read in every chunk\n",
        "        :return: csv registered in pandas data frame of size (data_size, num_fields + 2)\n",
        "        \"\"\"\n",
        "        print(\"Reading large data\")\n",
        "        data_file = self.open_csv(iterator=True)\n",
        "\n",
        "        print(\"Cut by chunk\")\n",
        "        loop = True\n",
        "        chunks = []\n",
        "        index = 0\n",
        "        while loop:\n",
        "            try:\n",
        "                print(\"chunk: \", index)\n",
        "                chunk = data_file.get_chunk(chunk_size)\n",
        "                chunks.append(chunk)\n",
        "                index += 1\n",
        "\n",
        "            except StopIteration:\n",
        "                loop = False\n",
        "                print(\"Iteration is stopped.\")\n",
        "\n",
        "        print('Start concatenation')\n",
        "        whole_data = pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "        print(\"Data imported\")\n",
        "        return whole_data\n",
        "\n",
        "    def get_feature_set(self, feature_array):\n",
        "        \"\"\"\n",
        "        Get array of feature set of one field.\n",
        "        :param feature_array: one column (one field) of the data frame\n",
        "        :return: an array of size (num_features)\n",
        "        \"\"\"\n",
        "        return np.array(np.unique(feature_array))\n",
        "\n",
        "    def one_hot_encoding(self, feature_instances, feature_set):\n",
        "        \"\"\"\n",
        "        One hot encoding for one column (one field) for every sample.\n",
        "        The one hot vector is represented by the index where the value is 1.\n",
        "        :param feature_instances: one column of data frame\n",
        "        :param feature_set: array of nonrecurring feature set\n",
        "        :return: one hot encoding of the whole column of size (data_size, 1)\n",
        "        \"\"\"\n",
        "        one_hot_vector = np.zeros((len(feature_instances), 1), dtype=int)\n",
        "        for i in range(len(feature_instances)):\n",
        "            if feature_instances[i] not in feature_set:\n",
        "                raise Exception(\"instance is not in the set\")\n",
        "\n",
        "            index = np.argwhere(feature_set == feature_instances[i])\n",
        "            one_hot_vector[i, 0] = int(index)\n",
        "\n",
        "        return one_hot_vector\n",
        "\n",
        "    def get_field_dims(self):\n",
        "        \"\"\"\n",
        "        Get an array which contains the dimension of each field.\n",
        "        If sum up the array, the sum is the total dimension of all features.\n",
        "        (the total length of the one hot encoding vector)\n",
        "        The length of array is number of fields.\n",
        "        :return: an array of size (num_fields)\n",
        "        \"\"\"\n",
        "        dims = []\n",
        "        for i in range(2, self.data.shape[1]):\n",
        "            dims.append(len(self.get_feature_set(self.one_hot_data[:, i-2])))\n",
        "        return np.array(dims)\n",
        "\n",
        "    def get_one_hot_dataset(self):\n",
        "        \"\"\"\n",
        "        Get one hot encoding for the whole data frame.\n",
        "        The one hot vector is represented by the index where the value is 1.\n",
        "        :return: an array of size (data_size, num_fields)\n",
        "        \"\"\"\n",
        "        print('one hot encoding: feature {0}'.format(self.data.columns[2]))\n",
        "        features = np.asarray(self.data.iloc[:, 2])\n",
        "        one_hot_array = self.one_hot_encoding(features, self.get_feature_set(features))\n",
        "        for i in range(3, self.data.shape[1]):\n",
        "            print('one hot encoding: feature {0}'.format(self.data.columns[i]))\n",
        "            features = np.asarray(self.data.iloc[:, i])\n",
        "            next_array = self.one_hot_encoding(features, self.get_feature_set(features))\n",
        "            one_hot_array = np.hstack((one_hot_array, next_array))\n",
        "        return one_hot_array\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # print('Start generating smaller data')\n",
        "#     # provider = DataPreprocessor()\n",
        "#     # provider.cut_smaller_data_for_exam('./Data/train20k.csv', size=20000, skip_size=40000)\n",
        "#     print(\"Start data cleaning\")\n",
        "#     f = \"/content/drive/My Drive/train20k.csv\"\n",
        "\n",
        "#     processor = DataPreprocessor(f)\n",
        "#     print(processor.data.head())\n",
        "#     loader = DataLoader(processor, batch_size=10, shuffle=True)\n",
        "#     print(len(processor))\n",
        "#     # print(processor.get_field_dims())\n",
        "#     # for data, label in loader:\n",
        "#     #     print(data.size(), label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aVyScX_nWEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class FieldAwareFactorizationMachineModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A pytorch implementation of Field-aware Factorization Machine.\n",
        "\n",
        "    Reference:\n",
        "        Y Juan, et al. Field-aware Factorization Machines for CTR Prediction, 2015.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, field_dims, embed_dim):\n",
        "        \"\"\"\n",
        "        Initialisation of the FFM model\n",
        "        :param field_dims: list of dimensions of each field\n",
        "        :param embed_dim: dimension of latent vector\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear = FeaturesLinear(field_dims)\n",
        "        self.ffm = FieldAwareFactorizationMachine(field_dims, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: Integer tensor of size ``(batch_size, num_fields)``\n",
        "        \"\"\"\n",
        "        ffm_term = torch.sum(torch.sum(self.ffm(x), dim=1), dim=1, keepdim=True)\n",
        "        x = self.linear(x) + ffm_term\n",
        "        return torch.sigmoid(x.squeeze(1))\n",
        "\n",
        "\n",
        "class FeaturesLinear(nn.Module):\n",
        "\n",
        "    def __init__(self, field_dims, output_dim=1):\n",
        "        \"\"\"\n",
        "        Initialisation of linear first-degree terms. Use nn.Embedding to realize\n",
        "        inner product of input one-hot encoding vector and weight vector\n",
        "        :param field_dims: list of dimensions of each field\n",
        "        :param output_dim: the sum of linear terms\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc = nn.Embedding(sum(field_dims), output_dim)\n",
        "        self.bias = nn.Parameter(torch.zeros((output_dim,)))\n",
        "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: Integer tensor of size ``(batch_size, num_fields)``\n",
        "        \"\"\"\n",
        "        x = x.to(torch.int64)  # field-relative one hot encoding\n",
        "        x = x + x.new_tensor(self.offsets).unsqueeze(0)  # absolute-position one hot encoding\n",
        "        return torch.sum(self.fc(x), dim=1) + self.bias  # element wise linear poly sum\n",
        "\n",
        "\n",
        "class FieldAwareFactorizationMachine(nn.Module):\n",
        "\n",
        "    def __init__(self, field_dims, embed_dim):\n",
        "        \"\"\"\n",
        "        Use latent vector product to replace simple scalar weight factor.\n",
        "        More adaptive to situations where dependency exists among fields.\n",
        "        :param field_dims: list of dimensions of each field\n",
        "        :param embed_dim: dimension of latent vector\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_fields = len(field_dims)\n",
        "        self.embeddings = nn.ModuleList([\n",
        "            nn.Embedding(sum(field_dims), embed_dim) for _ in range(self.num_fields)\n",
        "        ])\n",
        "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n",
        "        for embedding in self.embeddings:\n",
        "            nn.init.xavier_uniform_(embedding.weight.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: Integer tensor of size ``(batch_size, num_fields)``\n",
        "        \"\"\"\n",
        "        x = x.to(torch.int64)\n",
        "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
        "        xs = [self.embeddings[i](x) for i in range(self.num_fields)]  # generation of latent mat\n",
        "        ix = list()\n",
        "        for i in range(self.num_fields - 1):\n",
        "            for j in range(i + 1, self.num_fields):\n",
        "                ix.append(xs[j][:, i] * xs[i][:, j])  # product of latent vector\n",
        "        ix = torch.stack(ix, dim=1)\n",
        "        return ix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5mzjg8OnhNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.utils.data import DataLoader\n",
        "# from Data_Preprocessor import *\n",
        "# from Deep_Model import FieldAwareFactorizationMachineModel\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import threading\n",
        "\n",
        "\n",
        "def fun_timer():\n",
        "    global boom\n",
        "    boom = True\n",
        "\n",
        "\n",
        "def run_train(model, optimizer, data_loader, criterion, device, log_interval=10):\n",
        "    \"\"\"\n",
        "    train the model using backward propagation\n",
        "    :param model: the model to be trained. instance of subclass of nn.Module\n",
        "    :param optimizer: torch optimiser with learning rate\n",
        "    :param data_loader: torch DataLoader of training data set\n",
        "    :param criterion: nn.BCELoss\n",
        "    :param device: CUDA GPU or CPU\n",
        "    :param log_interval: interval for showing training loss\n",
        "    :return: none\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, (fields, target) in enumerate(data_loader):\n",
        "        fields, target = fields.to(device), target.to(device)\n",
        "        y = model(fields)\n",
        "        loss = criterion(y, target.float())\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if i % log_interval == 0:\n",
        "            print('    - loss:', total_loss / log_interval)\n",
        "            total_loss = 0\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def run_test(model, data_loader, device, criterion):\n",
        "    \"\"\"\n",
        "    evaluate / test the model\n",
        "    :param model: the model to be evaluated/tested. instance of subclass of nn.Module\n",
        "    :param data_loader: torch DataLoader of eval/test data set\n",
        "    :param device: CUDA GPU or CPU\n",
        "    :return: auc score, accuracy of prediction\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    targets, predicts = list(), list()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for fields, target in data_loader:\n",
        "            fields, target = fields.to(device), target.to(device)\n",
        "            y = model(fields)\n",
        "            loss = criterion(y, target.float())\n",
        "            targets.extend(target.tolist())\n",
        "            predicts.extend(y.tolist())\n",
        "            predict_click = torch.round(y.data)\n",
        "            correct += (predict_click == target).sum().item()\n",
        "    return roc_auc_score(targets, predicts), correct / len(targets) * 100, loss.item()\n",
        "\n",
        "\n",
        "def main_process(dataset_path, epoch, learning_rate, batch_size, weight_decay, embeddim, boomtime = 60):\n",
        "    \"\"\"\n",
        "    Main process for train/evaluate/test the model, determine the hyper parameters here.\n",
        "    :param boomtime: time boom for adjusting hyperparameters to control the same training time cost\n",
        "    :param dataset_path: path of the original csv file\n",
        "    :param epoch: number of epochs\n",
        "    :param learning_rate: learning rate of gradient descent\n",
        "    :param batch_size: size of batches\n",
        "    :param weight_decay: L2 regularisation\n",
        "    :param embeddim: dimension of latent vector\n",
        "    :return: the trained model\n",
        "    \"\"\"\n",
        "    global boom\n",
        "    boom = False\n",
        "    timer = threading.Timer(boomtime, fun_timer)\n",
        "    timer.start()\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if device.type == 'cuda':\n",
        "        print(torch.cuda.get_device_name(0))\n",
        "\n",
        "    # Prepare the data\n",
        "    dataset = DataPreprocessor(dataset_path)\n",
        "    train_length = int(len(dataset) * 0.8)\n",
        "    valid_length = int(len(dataset) * 0.1)\n",
        "    test_length = len(dataset) - train_length - valid_length\n",
        "    train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
        "        dataset, (train_length, valid_length, test_length))\n",
        "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    field_dims = dataset.get_field_dims()\n",
        "\n",
        "    # Prepare the model and loss function\n",
        "    model = FieldAwareFactorizationMachineModel(field_dims, embed_dim=embeddim).to(device)\n",
        "    criterion = torch.nn.BCELoss().to(device)  # binary cross entropy loss\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    epoch_list = []\n",
        "    train_loss_list = []\n",
        "    val_auc_list = []\n",
        "    val_acc_list = []\n",
        "    val_loss_list = []\n",
        "    best_model = None\n",
        "    best_val_auc = 0\n",
        "    best_val_acc = 0\n",
        "    best_val_loss = 999999\n",
        "\n",
        "    # train\n",
        "    for epoch_i in range(epoch):\n",
        "        print('Memory Usage:')\n",
        "        print('Allocated:', round(torch.cuda.memory_allocated(0) / 1024 ** 3, 1), 'GB')\n",
        "        print('Cached:   ', round(torch.cuda.memory_cached(0) / 1024 ** 3, 1), 'GB')\n",
        "        train_loss = run_train(model, optimizer, train_data_loader, criterion, device)\n",
        "        val_auc, val_acc,val_loss = run_test(model, valid_data_loader, device, criterion)\n",
        "        epoch_list.append(epoch_i)\n",
        "        train_loss_list.append(train_loss)\n",
        "        val_auc_list.append(val_auc)\n",
        "        val_acc_list.append(val_acc)\n",
        "        val_loss_list.append(val_loss)\n",
        "        print('epoch:', epoch_i, 'train loss:', train_loss, 'validation: auc:',\\\n",
        "              val_auc, '--- acc:', val_acc, '--- loss:', val_loss)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = model\n",
        "            best_val_auc = val_auc\n",
        "            best_val_acc = val_acc\n",
        "        if boom:\n",
        "            print('time up, break')\n",
        "            break\n",
        "        else:\n",
        "            print(timer)\n",
        "    test_auc, test_acc, test_loss = run_test(model, test_data_loader, device, criterion)\n",
        "    print('test auc:', test_auc, 'test acc:', test_acc, 'test loss', test_loss)\n",
        "    return model, epoch_list, train_loss_list, val_auc_list, val_acc_list, val_loss_list, \\\n",
        "           test_auc, test_acc, test_loss, best_model, best_val_auc, best_val_acc, best_val_loss\n",
        "\n",
        "\n",
        "def main_train_test(save_model=True):\n",
        "    DATASET_PATH = \"/content/drive/My Drive/train20k.csv\"\n",
        "    EPOCH = 1000\n",
        "    LEARNING_RATE = 0.001\n",
        "    BATCH_SIZE = 3200\n",
        "    WEIGHT_DECAY = 1e-6\n",
        "    EMBED_DIM = 10\n",
        "    trained_model,epoch_list,train_loss_list,val_auc_list,val_acc_list,val_loss_list,auc,acc,loss,\\\n",
        "    best_model,best_val_auc,best_val_acc,best_val_loss = \\\n",
        "        main_process(DATASET_PATH, EPOCH, LEARNING_RATE, BATCH_SIZE, WEIGHT_DECAY, EMBED_DIM)\n",
        "    print(trained_model,epoch_list,train_loss_list,val_auc_list,val_acc_list,val_loss_list,auc,acc,loss,\\\n",
        "    best_model,best_val_auc,best_val_acc,best_val_loss)\n",
        "    # if save_model:\n",
        "    #     model_name = \"FFM\"\n",
        "    #     torch.save(trained_model, f'{model_name}.pt')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBS-Fwnh20q6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99d7ff69-c1b6-4a02-8e56-245eb2806d40"
      },
      "source": [
        "import json\n",
        "\n",
        "\n",
        "class HyperFinder():\n",
        "    def __init__(self):\n",
        "        self.DATASET_PATH = \"/content/drive/My Drive/train20k.csv\"\n",
        "        self.EPOCH = 1000\n",
        "        self.LEARNING_RATE = [0.01,0.02,0.05,0.1,0.2,0.5]\n",
        "        self.BATCH_SIZE = [40*i for i in range(1,11)]\n",
        "        self.WEIGHT_DECAY = [pow(10,-6+i) for i in range(4)]\n",
        "        self.EMBED_DIM = [pow(2,i) for i in range(5)]\n",
        "        self.save_best = True\n",
        "\n",
        "        self.best_learning_rate = None\n",
        "        self.model_best = None\n",
        "        self.epoch_list = []\n",
        "        self.train_loss_list = []\n",
        "        self.val_acc_list = []\n",
        "        self.val_acc_list = []\n",
        "        self.val_loss_list = []\n",
        "        self.auc_best = 0\n",
        "        self.acc_best = 1\n",
        "        self.loss_best = 999999\n",
        "        self.Total_Epoch = 1\n",
        "        self.data_save = {}\n",
        "\n",
        "    def save_model(self,trained_model,*args):\n",
        "        model_name = ''\n",
        "        for i in args:\n",
        "            print(i)\n",
        "            model_name += (str(i)[:7] + ' ')\n",
        "        torch.save(trained_model, f'/content/{model_name}.pt')\n",
        "\n",
        "    def obj_2_json(self, hpname):\n",
        "        load_dict = self.data_save\n",
        "        with open(\"/content/\" + hpname + \".json\",\"w\") as dump_f:\n",
        "            json.dump(load_dict,dump_f)\n",
        "\n",
        "    def find_best_Learning_Rate(self):\n",
        "        BATCH_SIZE = 12800\n",
        "        WEIGHT_DECAY = 1e-6\n",
        "        EMBED_DIM = 8\n",
        "        for LEARNING_RATE in self.LEARNING_RATE:\n",
        "            self.data_save[str(LEARNING_RATE)] = {}\n",
        "            trained_model,epoch_list,train_loss_list,val_auc_list,val_acc_list,val_loss_list,test_auc,test_acc,test_loss,\\\n",
        "            best_model,best_val_auc,best_val_acc,best_val_loss = \\\n",
        "                main_process(self.DATASET_PATH, self.EPOCH, LEARNING_RATE, BATCH_SIZE, WEIGHT_DECAY, EMBED_DIM,60)\n",
        "            self.data_save[str(LEARNING_RATE)]['EPOCH'] = epoch_list\n",
        "            self.data_save[str(LEARNING_RATE)]['train_loss_list'] = train_loss_list\n",
        "            self.data_save[str(LEARNING_RATE)]['val_auc_list'] = val_auc_list\n",
        "            self.data_save[str(LEARNING_RATE)]['val_acc_list'] = val_acc_list\n",
        "            self.data_save[str(LEARNING_RATE)]['val_loss_list'] = val_loss_list\n",
        "            self.data_save[str(LEARNING_RATE)]['test_auc'] = test_auc\n",
        "            self.data_save[str(LEARNING_RATE)]['test_acc'] = test_acc\n",
        "            self.data_save[str(LEARNING_RATE)]['test_loss'] = test_loss\n",
        "            self.data_save[str(LEARNING_RATE)]['best_val_auc'] = best_val_auc\n",
        "            self.data_save[str(LEARNING_RATE)]['best_val_acc'] = best_val_acc\n",
        "            self.data_save[str(LEARNING_RATE)]['best_val_loss'] = best_val_loss\n",
        "            if test_loss < self.loss_best:\n",
        "                self.best_learning_rate = LEARNING_RATE\n",
        "                self.epoch_list = epoch_list\n",
        "                self.auc_best = test_auc\n",
        "                self.acc_best = test_acc\n",
        "                self.loss_best = test_loss\n",
        "                self.Total_Epoch = len(epoch_list)\n",
        "                self.model_best = trained_model\n",
        "\n",
        "        if self.save_best:\n",
        "            self.save_model(self.model_best,self.best_learning_rate,self.auc_best,self.acc_best,self.loss_best)\n",
        "\n",
        "    def find_best_Weight_decay(self):\n",
        "        BATCH_SIZE = 12800\n",
        "        LEARNING_RATE = 0.001\n",
        "        EMBED_DIM = 8\n",
        "        for WEIGHT_DECAY in self.WEIGHT_DECAY:\n",
        "            self.data_save[str(LEARNING_RATE)] = {}\n",
        "            trained_model,epoch_list,train_loss_list,val_auc_list,val_acc_list,val_loss_list,test_auc,test_acc,test_loss,\\\n",
        "            best_model,best_val_auc,best_val_acc,best_val_loss = \\\n",
        "                main_process(self.DATASET_PATH, self.EPOCH, LEARNING_RATE, BATCH_SIZE, WEIGHT_DECAY, EMBED_DIM,60)\n",
        "            self.data_save[str(LEARNING_RATE)]['EPOCH'] = epoch_list\n",
        "            self.data_save[str(LEARNING_RATE)]['train_loss_list'] = train_loss_list\n",
        "            self.data_save[str(LEARNING_RATE)]['val_auc_list'] = val_auc_list\n",
        "            self.data_save[str(LEARNING_RATE)]['val_acc_list'] = val_acc_list\n",
        "            self.data_save[str(LEARNING_RATE)]['val_loss_list'] = val_loss_list\n",
        "            self.data_save[str(LEARNING_RATE)]['test_auc'] = test_auc\n",
        "            self.data_save[str(LEARNING_RATE)]['test_acc'] = test_acc\n",
        "            self.data_save[str(LEARNING_RATE)]['test_loss'] = test_loss\n",
        "            self.data_save[str(LEARNING_RATE)]['best_val_auc'] = best_val_auc\n",
        "            self.data_save[str(LEARNING_RATE)]['best_val_acc'] = best_val_acc\n",
        "            self.data_save[str(LEARNING_RATE)]['best_val_loss'] = best_val_loss\n",
        "            if test_loss < self.loss_best:\n",
        "                self.best_learning_rate = LEARNING_RATE\n",
        "                self.epoch_list = epoch_list\n",
        "                self.auc_best = test_auc\n",
        "                self.acc_best = test_acc\n",
        "                self.loss_best = test_loss\n",
        "                self.Total_Epoch = len(epoch_list)\n",
        "                self.model_best = trained_model\n",
        "\n",
        "        if self.save_best:\n",
        "            self.save_model(self.model_best,self.best_learning_rate,self.auc_best,self.acc_best,self.loss_best)\n",
        "\n",
        "    def find_best_k(self):\n",
        "        BATCH_SIZE = 12800\n",
        "        WEIGHT_DECAY = 1e-6\n",
        "        LEARNING_RATE = 0.001\n",
        "        for EMBED_DIM in self.EMBED_DIM:\n",
        "            self.data_save[str(LEARNING_RATE)] = {}\n",
        "            trained_model,epoch_list,train_loss_list,val_auc_list,val_acc_list,val_loss_list,test_auc,test_acc,test_loss,\\\n",
        "            best_model,best_val_auc,best_val_acc,best_val_loss = \\\n",
        "                main_process(self.DATASET_PATH, self.EPOCH, LEARNING_RATE, BATCH_SIZE, WEIGHT_DECAY, EMBED_DIM,60)\n",
        "            self.data_save[str(LEARNING_RATE)]['EPOCH'] = epoch_list\n",
        "            self.data_save[str(LEARNING_RATE)]['train_loss_list'] = train_loss_list\n",
        "            self.data_save[str(LEARNING_RATE)]['val_auc_list'] = val_auc_list\n",
        "            self.data_save[str(LEARNING_RATE)]['val_acc_list'] = val_acc_list\n",
        "            self.data_save[str(LEARNING_RATE)]['val_loss_list'] = val_loss_list\n",
        "            self.data_save[str(LEARNING_RATE)]['test_auc'] = test_auc\n",
        "            self.data_save[str(LEARNING_RATE)]['test_acc'] = test_acc\n",
        "            self.data_save[str(LEARNING_RATE)]['test_loss'] = test_loss\n",
        "            self.data_save[str(LEARNING_RATE)]['best_val_auc'] = best_val_auc\n",
        "            self.data_save[str(LEARNING_RATE)]['best_val_acc'] = best_val_acc\n",
        "            self.data_save[str(LEARNING_RATE)]['best_val_loss'] = best_val_loss\n",
        "            if test_loss < self.loss_best:\n",
        "                self.best_learning_rate = LEARNING_RATE\n",
        "                self.epoch_list = epoch_list\n",
        "                self.auc_best = test_auc\n",
        "                self.acc_best = test_acc\n",
        "                self.loss_best = test_loss\n",
        "                self.Total_Epoch = len(epoch_list)\n",
        "                self.model_best = trained_model\n",
        "\n",
        "        if self.save_best:\n",
        "            self.save_model(self.model_best,self.best_learning_rate,self.auc_best,self.acc_best,self.loss_best)\n",
        "\n",
        "\n",
        "def main():\n",
        "    hyperFinder = HyperFinder()\n",
        "    hyperFinder.find_best_Learning_Rate()\n",
        "    hyperFinder.obj_2_json('learning_rate')\n",
        "    hyperFinder.find_best_Weight_decay()\n",
        "    hyperFinder.obj_2_json('Weight_decay')\n",
        "    hyperFinder.find_best_k()\n",
        "    hyperFinder.obj_2_json('EMBED_DIM')\n",
        "\n",
        "main()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n",
            "    - loss: 0.19897679090499878\n",
            "epoch: 0 train loss: 1.782700777053833 validation: auc: 0.5444786557349659 --- acc: 45.9 --- loss: 1.553656816482544\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.15538934469223023\n",
            "epoch: 1 train loss: 1.2398271560668945 validation: auc: 0.5493094377130037 --- acc: 60.5 --- loss: 1.0503523349761963\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.09804313778877258\n",
            "epoch: 2 train loss: 0.7946409583091736 validation: auc: 0.5612384941803867 --- acc: 75.7 --- loss: 0.7993385791778564\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.06658251881599427\n",
            "epoch: 3 train loss: 0.7347180247306824 validation: auc: 0.5873265922315365 --- acc: 80.55 --- loss: 0.8761565685272217\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.06948322057723999\n",
            "epoch: 4 train loss: 0.688002347946167 validation: auc: 0.6141818869970386 --- acc: 81.2 --- loss: 0.8722352981567383\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.06290373802185059\n",
            "epoch: 5 train loss: 0.5351648926734924 validation: auc: 0.6347376442969154 --- acc: 80.30000000000001 --- loss: 0.7628569602966309\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.04512756764888763\n",
            "epoch: 6 train loss: 0.3571745753288269 validation: auc: 0.6476606467297814 --- acc: 78.05 --- loss: 0.6720430850982666\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.02783661484718323\n",
            "epoch: 7 train loss: 0.2476952224969864 validation: auc: 0.6558065709546144 --- acc: 74.3 --- loss: 0.6694808602333069\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.019479122757911683\n",
            "epoch: 8 train loss: 0.17860347032546997 validation: auc: 0.6597533718295595 --- acc: 69.5 --- loss: 0.7032121419906616\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.015009960532188416\n",
            "epoch: 9 train loss: 0.1324910968542099 validation: auc: 0.6587867039694758 --- acc: 68.8 --- loss: 0.7018393278121948\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.010614316910505295\n",
            "epoch: 10 train loss: 0.08477510511875153 validation: auc: 0.6526013935702095 --- acc: 70.19999999999999 --- loss: 0.6752361059188843\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.006913027912378311\n",
            "epoch: 11 train loss: 0.0689530298113823 validation: auc: 0.6445995318395161 --- acc: 71.45 --- loss: 0.6510618925094604\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.005310505256056785\n",
            "epoch: 12 train loss: 0.04439324513077736 validation: auc: 0.6377510225027321 --- acc: 74.05000000000001 --- loss: 0.6392855644226074\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.004228032752871513\n",
            "epoch: 13 train loss: 0.04569431394338608 validation: auc: 0.6338204180028677 --- acc: 75.5 --- loss: 0.6365150213241577\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.003701799735426903\n",
            "epoch: 14 train loss: 0.042080383747816086 validation: auc: 0.6330123041304166 --- acc: 76.75 --- loss: 0.6369374990463257\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0032547730952501297\n",
            "epoch: 15 train loss: 0.04017915576696396 validation: auc: 0.6346217123489688 --- acc: 77.9 --- loss: 0.637225329875946\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.002847796492278576\n",
            "epoch: 16 train loss: 0.03678508847951889 validation: auc: 0.6381985539194375 --- acc: 77.95 --- loss: 0.6361315846443176\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0027360139414668084\n",
            "epoch: 17 train loss: 0.022154971957206726 validation: auc: 0.6421606987286699 --- acc: 77.9 --- loss: 0.6342325210571289\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.002271386608481407\n",
            "epoch: 18 train loss: 0.023174993693828583 validation: auc: 0.6463359537363331 --- acc: 78.0 --- loss: 0.6324914693832397\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0019600102677941322\n",
            "epoch: 19 train loss: 0.024033233523368835 validation: auc: 0.649457591922953 --- acc: 78.14999999999999 --- loss: 0.6318031549453735\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0019448498263955117\n",
            "epoch: 20 train loss: 0.018267350271344185 validation: auc: 0.6519705873828534 --- acc: 78.2 --- loss: 0.6320507526397705\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.001832243986427784\n",
            "epoch: 21 train loss: 0.019317472353577614 validation: auc: 0.653411212324248 --- acc: 78.3 --- loss: 0.6327243447303772\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.001791372150182724\n",
            "epoch: 22 train loss: 0.01682749204337597 validation: auc: 0.6539294963268326 --- acc: 78.3 --- loss: 0.6334663033485413\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0017070960253477096\n",
            "epoch: 23 train loss: 0.014917070977389812 validation: auc: 0.6540846405512906 --- acc: 78.3 --- loss: 0.6342449188232422\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0016397921368479728\n",
            "epoch: 24 train loss: 0.011632357724010944 validation: auc: 0.6537385495890384 --- acc: 78.60000000000001 --- loss: 0.6352105736732483\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0014120855368673802\n",
            "epoch: 25 train loss: 0.014983396977186203 validation: auc: 0.6531367263886687 --- acc: 78.7 --- loss: 0.6364847421646118\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0013066026382148265\n",
            "epoch: 26 train loss: 0.01484565157443285 validation: auc: 0.6528835514729324 --- acc: 78.8 --- loss: 0.6379624009132385\n",
            "<Timer(Thread-7, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0013326568529009818\n",
            "epoch: 27 train loss: 0.010213133879005909 validation: auc: 0.6526985718206941 --- acc: 78.85 --- loss: 0.639369785785675\n",
            "time up, break\n",
            "test auc: 0.6634419315755002 test acc: 80.0 test loss 0.5667077302932739\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.13805439472198486\n",
            "epoch: 0 train loss: 1.1717290878295898 validation: auc: 0.49857839231486223 --- acc: 67.10000000000001 --- loss: 0.9015448689460754\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.08388919234275818\n",
            "epoch: 1 train loss: 0.7693663239479065 validation: auc: 0.5568821597161671 --- acc: 81.75 --- loss: 0.7730445265769958\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.07090732455253601\n",
            "epoch: 2 train loss: 0.6033385992050171 validation: auc: 0.6300991836796055 --- acc: 81.65 --- loss: 0.619220495223999\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.04438301920890808\n",
            "epoch: 3 train loss: 0.31964850425720215 validation: auc: 0.6663374951141044 --- acc: 73.35000000000001 --- loss: 0.6204932928085327\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.02553708851337433\n",
            "epoch: 4 train loss: 0.24133792519569397 validation: auc: 0.662632670856009 --- acc: 68.15 --- loss: 0.6848241686820984\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.015265804529190064\n",
            "epoch: 5 train loss: 0.0992686003446579 validation: auc: 0.6394350025556992 --- acc: 74.9 --- loss: 0.588443398475647\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.005766769498586654\n",
            "epoch: 6 train loss: 0.055037856101989746 validation: auc: 0.6187949126552211 --- acc: 79.14999999999999 --- loss: 0.6049114465713501\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.004554025828838348\n",
            "epoch: 7 train loss: 0.04607614502310753 validation: auc: 0.610933318800926 --- acc: 81.05 --- loss: 0.6456984877586365\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.004232877865433693\n",
            "epoch: 8 train loss: 0.03543291240930557 validation: auc: 0.6139249902282089 --- acc: 81.15 --- loss: 0.6687418222427368\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.003272318467497826\n",
            "epoch: 9 train loss: 0.03343134745955467 validation: auc: 0.6210696728705012 --- acc: 80.95 --- loss: 0.6759853959083557\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0023512396961450576\n",
            "epoch: 10 train loss: 0.0278167724609375 validation: auc: 0.6289979779909197 --- acc: 80.4 --- loss: 0.6772676110267639\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.001993384212255478\n",
            "epoch: 11 train loss: 0.018320567905902863 validation: auc: 0.6349625289395351 --- acc: 80.35 --- loss: 0.6802018284797668\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0018359804525971413\n",
            "epoch: 12 train loss: 0.019193343818187714 validation: auc: 0.6390027887188431 --- acc: 81.05 --- loss: 0.6864980459213257\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0017091378569602967\n",
            "epoch: 13 train loss: 0.01689729653298855 validation: auc: 0.641160099521934 --- acc: 81.39999999999999 --- loss: 0.6942592859268188\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0015072367154061795\n",
            "epoch: 14 train loss: 0.010744781233370304 validation: auc: 0.6426164722330797 --- acc: 81.65 --- loss: 0.7036115527153015\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.001173605117946863\n",
            "epoch: 15 train loss: 0.013125195167958736 validation: auc: 0.643604926486064 --- acc: 81.85 --- loss: 0.7137330770492554\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0011051335372030736\n",
            "epoch: 16 train loss: 0.010866894386708736 validation: auc: 0.6446685483628491 --- acc: 81.95 --- loss: 0.7220214009284973\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0010486231185495853\n",
            "epoch: 17 train loss: 0.008604947477579117 validation: auc: 0.6457171367148741 --- acc: 81.89999999999999 --- loss: 0.726432740688324\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0009633460082113743\n",
            "epoch: 18 train loss: 0.007761501241475344 validation: auc: 0.6469865299618149 --- acc: 81.95 --- loss: 0.7280662655830383\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.000764320744201541\n",
            "epoch: 19 train loss: 0.010844635777175426 validation: auc: 0.6485847815628852 --- acc: 82.0 --- loss: 0.7276124954223633\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.000770705658942461\n",
            "epoch: 20 train loss: 0.005626058205962181 validation: auc: 0.6500674629423615 --- acc: 81.89999999999999 --- loss: 0.7261372208595276\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0006459785159677267\n",
            "epoch: 21 train loss: 0.0065918187610805035 validation: auc: 0.6518263853393066 --- acc: 82.0 --- loss: 0.7253462076187134\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0005903932265937329\n",
            "epoch: 22 train loss: 0.006870920769870281 validation: auc: 0.6536792672660032 --- acc: 82.15 --- loss: 0.7259452939033508\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0005941327195614577\n",
            "epoch: 23 train loss: 0.004569181706756353 validation: auc: 0.6557501353017229 --- acc: 82.3 --- loss: 0.7278664708137512\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.00046843178570270537\n",
            "epoch: 24 train loss: 0.008233127184212208 validation: auc: 0.6582438212213235 --- acc: 82.45 --- loss: 0.7300279140472412\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0005015095695853234\n",
            "epoch: 25 train loss: 0.005035109352320433 validation: auc: 0.6609122718662618 --- acc: 82.45 --- loss: 0.7324895262718201\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0004679324571043253\n",
            "epoch: 26 train loss: 0.004256806802004576 validation: auc: 0.6629042138969903 --- acc: 82.65 --- loss: 0.7349075675010681\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0004042143002152443\n",
            "epoch: 27 train loss: 0.005132990889251232 validation: auc: 0.6645315929522837 --- acc: 82.65 --- loss: 0.7365896701812744\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.00039787329733371736\n",
            "epoch: 28 train loss: 0.004336259793490171 validation: auc: 0.6655632685889534 --- acc: 82.69999999999999 --- loss: 0.7375426888465881\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.00041286107152700425\n",
            "epoch: 29 train loss: 0.0035431431606411934 validation: auc: 0.6666813869929944 --- acc: 82.85 --- loss: 0.7378485202789307\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0004124605096876621\n",
            "epoch: 30 train loss: 0.004267165437340736 validation: auc: 0.6680362834120088 --- acc: 82.8 --- loss: 0.737945020198822\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.00045154867693781854\n",
            "epoch: 31 train loss: 0.0028814610559493303 validation: auc: 0.6699154740070358 --- acc: 82.8 --- loss: 0.7378830909729004\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.00037658107466995714\n",
            "epoch: 32 train loss: 0.0050261737778782845 validation: auc: 0.6718717114164587 --- acc: 82.85 --- loss: 0.7372223138809204\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0003910147119313478\n",
            "epoch: 33 train loss: 0.0035914843901991844 validation: auc: 0.6738918413061127 --- acc: 83.0 --- loss: 0.7365508079528809\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.00034067137166857717\n",
            "epoch: 34 train loss: 0.0047374265268445015 validation: auc: 0.6758518370967257 --- acc: 83.05 --- loss: 0.7358149886131287\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.00038189226761460305\n",
            "epoch: 35 train loss: 0.0021107117645442486 validation: auc: 0.6776257930184311 --- acc: 83.05 --- loss: 0.7349740266799927\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0003542913822457194\n",
            "epoch: 36 train loss: 0.003126916941255331 validation: auc: 0.679503104422863 --- acc: 83.05 --- loss: 0.7338050603866577\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0003503992920741439\n",
            "epoch: 37 train loss: 0.00363869103603065 validation: auc: 0.6812789395351634 --- acc: 82.95 --- loss: 0.7322516441345215\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0003719463245943189\n",
            "epoch: 38 train loss: 0.002943743485957384 validation: auc: 0.6826582654319132 --- acc: 83.1 --- loss: 0.7313937544822693\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0003302210010588169\n",
            "epoch: 39 train loss: 0.004340152721852064 validation: auc: 0.6838684641751105 --- acc: 83.1 --- loss: 0.7314684987068176\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.00035218372941017153\n",
            "epoch: 40 train loss: 0.002620731946080923 validation: auc: 0.6849940993415315 --- acc: 83.1 --- loss: 0.7323703765869141\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0003544037695974112\n",
            "epoch: 41 train loss: 0.00240553030744195 validation: auc: 0.6862531570401995 --- acc: 83.05 --- loss: 0.7328137755393982\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.0003554095979779959\n",
            "epoch: 42 train loss: 0.0028627344872802496 validation: auc: 0.6870198668029706 --- acc: 83.05 --- loss: 0.7322847247123718\n",
            "<Timer(Thread-65, started 139804170729216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.00035652625374495985\n",
            "epoch: 43 train loss: 0.0034852446988224983 validation: auc: 0.687683221083015 --- acc: 83.2 --- loss: 0.7309486269950867\n",
            "time up, break\n",
            "test auc: 0.6688183696900115 test acc: 82.45 test loss 0.7696765065193176\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.12636115550994872\n",
            "epoch: 0 train loss: 0.9915401935577393 validation: auc: 0.5881482489566322 --- acc: 82.8 --- loss: 0.9730334877967834\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.6 GB\n",
            "    - loss: 0.08468679785728454\n",
            "epoch: 1 train loss: 0.5626401305198669 validation: auc: 0.645364725095264 --- acc: 64.7 --- loss: 1.049331545829773\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.054868113994598386\n",
            "epoch: 2 train loss: 0.15820816159248352 validation: auc: 0.59317637452368 --- acc: 81.3 --- loss: 0.717755138874054\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.013680832087993621\n",
            "epoch: 3 train loss: 0.16255700588226318 validation: auc: 0.537456904373072 --- acc: 77.5 --- loss: 0.8758962750434875\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.008730980008840561\n",
            "epoch: 4 train loss: 0.06935492157936096 validation: auc: 0.53983215387407 --- acc: 75.0 --- loss: 0.9174370169639587\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.004813719168305397\n",
            "epoch: 5 train loss: 0.04528403282165527 validation: auc: 0.5520277626565051 --- acc: 73.45 --- loss: 0.9802625179290771\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.004560103267431259\n",
            "epoch: 6 train loss: 0.05138495936989784 validation: auc: 0.5602349845763018 --- acc: 75.1 --- loss: 1.0319095849990845\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0033996116369962694\n",
            "epoch: 7 train loss: 0.042766667902469635 validation: auc: 0.5639693340591544 --- acc: 76.2 --- loss: 1.0725685358047485\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.002615287713706493\n",
            "epoch: 8 train loss: 0.020811231806874275 validation: auc: 0.5661903465795681 --- acc: 77.55 --- loss: 1.113922357559204\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0021495213732123375\n",
            "epoch: 9 train loss: 0.019352516159415245 validation: auc: 0.5680820177826167 --- acc: 77.60000000000001 --- loss: 1.1332162618637085\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0017846237868070602\n",
            "epoch: 10 train loss: 0.019162341952323914 validation: auc: 0.5702367991290147 --- acc: 77.10000000000001 --- loss: 1.1799241304397583\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0014596158638596536\n",
            "epoch: 11 train loss: 0.012774383649230003 validation: auc: 0.5718626383596443 --- acc: 76.7 --- loss: 1.1944994926452637\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.001171597745269537\n",
            "epoch: 12 train loss: 0.005895822774618864 validation: auc: 0.5751034295046271 --- acc: 76.8 --- loss: 1.2118124961853027\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00101954136043787\n",
            "epoch: 13 train loss: 0.013572542928159237 validation: auc: 0.580048085646888 --- acc: 77.0 --- loss: 1.2254459857940674\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0009577788412570953\n",
            "epoch: 14 train loss: 0.009912044741213322 validation: auc: 0.5855153329704228 --- acc: 77.2 --- loss: 1.2330117225646973\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0006870444398373365\n",
            "epoch: 15 train loss: 0.016047224402427673 validation: auc: 0.590652331700236 --- acc: 78.05 --- loss: 1.2363821268081665\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0007120738737285137\n",
            "epoch: 16 train loss: 0.011836848221719265 validation: auc: 0.5951760116131374 --- acc: 78.9 --- loss: 1.2245948314666748\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0005885709542781115\n",
            "epoch: 17 train loss: 0.005778156686574221 validation: auc: 0.5986626746506987 --- acc: 79.14999999999999 --- loss: 1.2189900875091553\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0005194749683141708\n",
            "epoch: 18 train loss: 0.002999132964760065 validation: auc: 0.6015541643984758 --- acc: 79.4 --- loss: 1.2045565843582153\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0005038123112171888\n",
            "epoch: 19 train loss: 0.005499597173184156 validation: auc: 0.6041389947377973 --- acc: 79.60000000000001 --- loss: 1.1975364685058594\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0005409253761172294\n",
            "epoch: 20 train loss: 0.007624202873557806 validation: auc: 0.6065750317546724 --- acc: 79.65 --- loss: 1.191580891609192\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0005394899286329746\n",
            "epoch: 21 train loss: 0.005482382141053677 validation: auc: 0.6094783160950825 --- acc: 80.0 --- loss: 1.1837717294692993\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0004262520931661129\n",
            "epoch: 22 train loss: 0.00522718857973814 validation: auc: 0.6134267827980403 --- acc: 80.30000000000001 --- loss: 1.1726702451705933\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00033956957049667834\n",
            "epoch: 23 train loss: 0.0070600565522909164 validation: auc: 0.6169179822173835 --- acc: 80.35 --- loss: 1.1550817489624023\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00030006354209035637\n",
            "epoch: 24 train loss: 0.009744329378008842 validation: auc: 0.6199972781709309 --- acc: 80.45 --- loss: 1.1353724002838135\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0004529485013335943\n",
            "epoch: 25 train loss: 0.0026706524658948183 validation: auc: 0.6232144801306477 --- acc: 80.55 --- loss: 1.1143622398376465\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00047056395560503007\n",
            "epoch: 26 train loss: 0.005105303134769201 validation: auc: 0.6264189802213755 --- acc: 80.7 --- loss: 1.0956087112426758\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0005414926446974278\n",
            "epoch: 27 train loss: 0.005405084695667028 validation: auc: 0.6287597532208311 --- acc: 80.9 --- loss: 1.0862464904785156\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0004163323435932398\n",
            "epoch: 28 train loss: 0.008700275793671608 validation: auc: 0.629287788060243 --- acc: 81.15 --- loss: 1.080984354019165\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0004608986433595419\n",
            "epoch: 29 train loss: 0.0036424642894417048 validation: auc: 0.6288250771184902 --- acc: 81.10000000000001 --- loss: 1.0734097957611084\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00041507319547235967\n",
            "epoch: 30 train loss: 0.0019617206417024136 validation: auc: 0.6284204318635457 --- acc: 81.15 --- loss: 1.0707529783248901\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00036098181735724213\n",
            "epoch: 31 train loss: 0.007402356714010239 validation: auc: 0.630405552531301 --- acc: 81.15 --- loss: 1.0624027252197266\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00038743750192224977\n",
            "epoch: 32 train loss: 0.004393511917442083 validation: auc: 0.6348548357829795 --- acc: 81.15 --- loss: 1.0494226217269897\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0003328261896967888\n",
            "epoch: 33 train loss: 0.0030203047208487988 validation: auc: 0.6398140083469426 --- acc: 81.45 --- loss: 1.0279186964035034\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00040635447949171065\n",
            "epoch: 34 train loss: 0.002847778843715787 validation: auc: 0.6429549990927237 --- acc: 81.55 --- loss: 1.0158195495605469\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0003716049483045936\n",
            "epoch: 35 train loss: 0.006205444224178791 validation: auc: 0.6443013972055889 --- acc: 81.45 --- loss: 1.0086660385131836\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00040500466711819173\n",
            "epoch: 36 train loss: 0.0030159172601997852 validation: auc: 0.644054618036654 --- acc: 81.45 --- loss: 1.0041539669036865\n",
            "<Timer(Thread-155, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00030250833369791506\n",
            "epoch: 37 train loss: 0.004258968401700258 validation: auc: 0.6427862456904373 --- acc: 81.5 --- loss: 1.0006550550460815\n",
            "time up, break\n",
            "test auc: 0.6565323734284133 test acc: 82.1 test loss 0.9299958944320679\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12478827238082886\n",
            "epoch: 0 train loss: 0.8225882649421692 validation: auc: 0.654830667456556 --- acc: 54.1 --- loss: 4.316534042358398\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.42399144172668457\n",
            "epoch: 1 train loss: 1.95158052444458 validation: auc: 0.6669571788795723 --- acc: 84.5 --- loss: 2.5572104454040527\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.18592067956924438\n",
            "epoch: 2 train loss: 0.968442440032959 validation: auc: 0.6396775124559484 --- acc: 73.75 --- loss: 1.6934340000152588\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05553027391433716\n",
            "epoch: 3 train loss: 0.40812405943870544 validation: auc: 0.6682768258597642 --- acc: 75.05 --- loss: 1.2208783626556396\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.014551496505737305\n",
            "epoch: 4 train loss: 0.16834869980812073 validation: auc: 0.5616427041560336 --- acc: 71.15 --- loss: 2.034986972808838\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.018921107053756714\n",
            "epoch: 5 train loss: 0.27615872025489807 validation: auc: 0.5467487316198809 --- acc: 77.55 --- loss: 2.2466094493865967\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.018331436812877654\n",
            "epoch: 6 train loss: 0.18043577671051025 validation: auc: 0.555663469133552 --- acc: 81.39999999999999 --- loss: 2.401121139526367\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.01228974312543869\n",
            "epoch: 7 train loss: 0.145013689994812 validation: auc: 0.5764521813100012 --- acc: 82.19999999999999 --- loss: 2.491041421890259\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.009952110052108765\n",
            "epoch: 8 train loss: 0.08342701196670532 validation: auc: 0.5904926555474541 --- acc: 81.95 --- loss: 2.600153923034668\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.010342300683259965\n",
            "epoch: 9 train loss: 0.1136775091290474 validation: auc: 0.5950611025033419 --- acc: 82.0 --- loss: 2.7984538078308105\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.009818937629461288\n",
            "epoch: 10 train loss: 0.05115486681461334 validation: auc: 0.5954541484384493 --- acc: 82.69999999999999 --- loss: 3.030303716659546\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.008479008823633194\n",
            "epoch: 11 train loss: 0.04408286511898041 validation: auc: 0.5942958971320937 --- acc: 82.8 --- loss: 3.2562999725341797\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.006725094467401505\n",
            "epoch: 12 train loss: 0.11861995607614517 validation: auc: 0.5930161243772026 --- acc: 82.95 --- loss: 3.3913941383361816\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.007814492285251617\n",
            "epoch: 13 train loss: 0.06323689222335815 validation: auc: 0.5942550735204764 --- acc: 82.85 --- loss: 3.4500904083251953\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00835837349295616\n",
            "epoch: 14 train loss: 0.022723782807588577 validation: auc: 0.5964329657309515 --- acc: 82.89999999999999 --- loss: 3.478484869003296\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.006774893403053284\n",
            "epoch: 15 train loss: 0.07874172180891037 validation: auc: 0.6011770491554258 --- acc: 83.0 --- loss: 3.4552862644195557\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0072209931910038\n",
            "epoch: 16 train loss: 0.03757276386022568 validation: auc: 0.607651863835217 --- acc: 83.25 --- loss: 3.453481912612915\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.006517275422811508\n",
            "epoch: 17 train loss: 0.07333732396364212 validation: auc: 0.612297211082756 --- acc: 83.2 --- loss: 3.454916477203369\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.007552740722894668\n",
            "epoch: 18 train loss: 0.03226019814610481 validation: auc: 0.6154472748815165 --- acc: 82.89999999999999 --- loss: 3.471222400665283\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.007131315022706986\n",
            "epoch: 19 train loss: 0.06262124329805374 validation: auc: 0.6174941517802892 --- acc: 83.2 --- loss: 3.4600274562835693\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.005747997760772705\n",
            "epoch: 20 train loss: 0.11730998754501343 validation: auc: 0.6181805580872524 --- acc: 83.3 --- loss: 3.447730302810669\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.006746687740087509\n",
            "epoch: 21 train loss: 0.0732806921005249 validation: auc: 0.618166317292502 --- acc: 83.35000000000001 --- loss: 3.415632724761963\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.007313694059848786\n",
            "epoch: 22 train loss: 0.049264803528785706 validation: auc: 0.6173678834001701 --- acc: 83.15 --- loss: 3.3754403591156006\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0076361440122127535\n",
            "epoch: 23 train loss: 0.027303041890263557 validation: auc: 0.616864708652327 --- acc: 83.0 --- loss: 3.3435447216033936\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.005017032101750374\n",
            "epoch: 24 train loss: 0.1300906240940094 validation: auc: 0.6179023878964638 --- acc: 82.8 --- loss: 3.3099093437194824\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.006328688561916351\n",
            "epoch: 25 train loss: 0.07110851258039474 validation: auc: 0.6191527296755377 --- acc: 82.8 --- loss: 3.259145975112915\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.004849786683917045\n",
            "epoch: 26 train loss: 0.11460034549236298 validation: auc: 0.6202796512334428 --- acc: 82.69999999999999 --- loss: 3.203707695007324\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.006066162511706353\n",
            "epoch: 27 train loss: 0.06378123164176941 validation: auc: 0.6212461265038279 --- acc: 82.75 --- loss: 3.1503822803497314\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0066788941621780396\n",
            "epoch: 28 train loss: 0.03862696513533592 validation: auc: 0.6223910864017499 --- acc: 82.8 --- loss: 3.095324993133545\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.003993287682533264\n",
            "epoch: 29 train loss: 0.13520346581935883 validation: auc: 0.6235037671649046 --- acc: 82.8 --- loss: 3.0434014797210693\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0062396001070737835\n",
            "epoch: 30 train loss: 0.03695765510201454 validation: auc: 0.6245651810669584 --- acc: 82.69999999999999 --- loss: 2.9806697368621826\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0057120248675346375\n",
            "epoch: 31 train loss: 0.039912883192300797 validation: auc: 0.6251063312674687 --- acc: 82.5 --- loss: 2.9354000091552734\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.004998281970620156\n",
            "epoch: 32 train loss: 0.054951876401901245 validation: auc: 0.625012342022117 --- acc: 82.5 --- loss: 2.8800220489501953\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0052816495299339294\n",
            "epoch: 33 train loss: 0.03461664170026779 validation: auc: 0.6247094877870945 --- acc: 82.5 --- loss: 2.8155784606933594\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.005100870132446289\n",
            "epoch: 34 train loss: 0.04234931617975235 validation: auc: 0.6249392392757321 --- acc: 82.39999999999999 --- loss: 2.7446343898773193\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.004218952357769012\n",
            "epoch: 35 train loss: 0.07301706820726395 validation: auc: 0.625036076680034 --- acc: 82.3 --- loss: 2.675938129425049\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.004610095918178558\n",
            "epoch: 36 train loss: 0.056371621787548065 validation: auc: 0.6259569814072183 --- acc: 82.3 --- loss: 2.626779317855835\n",
            "<Timer(Thread-233, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.00339912474155426\n",
            "epoch: 37 train loss: 0.10672131180763245 validation: auc: 0.6280741128934256 --- acc: 82.35 --- loss: 2.5904953479766846\n",
            "time up, break\n",
            "test auc: 0.6066909614960282 test acc: 80.9 test loss 3.0214807987213135\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10917512178421021\n",
            "epoch: 0 train loss: 0.870379626750946 validation: auc: 0.5271477017256045 --- acc: 18.0 --- loss: 21.233848571777344\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.075778579711914\n",
            "epoch: 1 train loss: 13.2079496383667 validation: auc: 0.6527553089682829 --- acc: 66.10000000000001 --- loss: 9.674544334411621\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.9424008369445801\n",
            "epoch: 2 train loss: 8.354276657104492 validation: auc: 0.6281766466156277 --- acc: 74.8 --- loss: 7.507934093475342\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.76240234375\n",
            "epoch: 3 train loss: 5.751840114593506 validation: auc: 0.5869552421314861 --- acc: 84.3 --- loss: 5.296963214874268\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.5240706920623779\n",
            "epoch: 4 train loss: 4.421696186065674 validation: auc: 0.5715979690727913 --- acc: 84.25 --- loss: 4.528799533843994\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.42745275497436525\n",
            "epoch: 5 train loss: 4.311750411987305 validation: auc: 0.5830456692793778 --- acc: 83.85000000000001 --- loss: 4.551650047302246\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.43247175216674805\n",
            "epoch: 6 train loss: 4.011533737182617 validation: auc: 0.5863628250698749 --- acc: 83.89999999999999 --- loss: 4.776085376739502\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.4147801399230957\n",
            "epoch: 7 train loss: 4.044730186462402 validation: auc: 0.5894730146433346 --- acc: 83.75 --- loss: 4.827871322631836\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.4047724723815918\n",
            "epoch: 8 train loss: 4.078146457672119 validation: auc: 0.5858786380483655 --- acc: 83.25 --- loss: 4.756255626678467\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.39450664520263673\n",
            "epoch: 9 train loss: 4.187800407409668 validation: auc: 0.5934594877870945 --- acc: 83.5 --- loss: 4.77958869934082\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3968073844909668\n",
            "epoch: 10 train loss: 3.82865047454834 validation: auc: 0.5989032689269655 --- acc: 83.1 --- loss: 4.811314105987549\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.38892388343811035\n",
            "epoch: 11 train loss: 3.4202680587768555 validation: auc: 0.5950050887106574 --- acc: 83.35000000000001 --- loss: 4.776134490966797\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.36855378150939944\n",
            "epoch: 12 train loss: 3.62570858001709 validation: auc: 0.5855738850407097 --- acc: 83.7 --- loss: 4.671504020690918\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.35725579261779783\n",
            "epoch: 13 train loss: 3.687993049621582 validation: auc: 0.5799563662048852 --- acc: 83.7 --- loss: 4.7004547119140625\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3543787240982056\n",
            "epoch: 14 train loss: 3.6777617931365967 validation: auc: 0.5753964637258476 --- acc: 83.55 --- loss: 4.599708557128906\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3544954776763916\n",
            "epoch: 15 train loss: 3.462636947631836 validation: auc: 0.5786034907036093 --- acc: 83.75 --- loss: 4.688370227813721\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.35454654693603516\n",
            "epoch: 16 train loss: 3.252500295639038 validation: auc: 0.5749141754769717 --- acc: 83.7 --- loss: 4.602414131164551\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3446376323699951\n",
            "epoch: 17 train loss: 3.4945504665374756 validation: auc: 0.5736571879936808 --- acc: 83.55 --- loss: 4.659353256225586\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3393296003341675\n",
            "epoch: 18 train loss: 3.279083490371704 validation: auc: 0.5594581662413416 --- acc: 83.95 --- loss: 4.438632965087891\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3298452854156494\n",
            "epoch: 19 train loss: 3.480355739593506 validation: auc: 0.5575707862437721 --- acc: 83.85000000000001 --- loss: 4.538754940032959\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3403483390808105\n",
            "epoch: 20 train loss: 2.9507639408111572 validation: auc: 0.5587119485964273 --- acc: 83.89999999999999 --- loss: 4.59388542175293\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.33039441108703616\n",
            "epoch: 21 train loss: 3.199646234512329 validation: auc: 0.5637398985295905 --- acc: 83.95 --- loss: 4.700619220733643\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3284847974777222\n",
            "epoch: 22 train loss: 3.1836066246032715 validation: auc: 0.5618525185320209 --- acc: 83.85000000000001 --- loss: 4.6245880126953125\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.324720573425293\n",
            "epoch: 23 train loss: 3.2106311321258545 validation: auc: 0.5622303742860615 --- acc: 83.75 --- loss: 4.6025614738464355\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3231649875640869\n",
            "epoch: 24 train loss: 3.1672213077545166 validation: auc: 0.5602651446105238 --- acc: 83.89999999999999 --- loss: 4.593564510345459\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.32867908477783203\n",
            "epoch: 25 train loss: 3.002063512802124 validation: auc: 0.5622816411471625 --- acc: 83.95 --- loss: 4.637631416320801\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3239503145217896\n",
            "epoch: 26 train loss: 3.1394872665405273 validation: auc: 0.557396099161502 --- acc: 84.25 --- loss: 4.47832727432251\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.32292742729187013\n",
            "epoch: 27 train loss: 3.1085400581359863 validation: auc: 0.5632072928059303 --- acc: 84.3 --- loss: 4.457827091217041\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3270104885101318\n",
            "epoch: 28 train loss: 2.870527982711792 validation: auc: 0.5678849191882368 --- acc: 84.25 --- loss: 4.487340450286865\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3141063928604126\n",
            "epoch: 29 train loss: 3.524653434753418 validation: auc: 0.567721624741767 --- acc: 83.95 --- loss: 4.536346912384033\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3254540920257568\n",
            "epoch: 30 train loss: 3.0301756858825684 validation: auc: 0.5608224343784177 --- acc: 83.89999999999999 --- loss: 4.575974464416504\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.32488508224487306\n",
            "epoch: 31 train loss: 3.0252935886383057 validation: auc: 0.5597581723174141 --- acc: 83.89999999999999 --- loss: 4.609523296356201\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.317694091796875\n",
            "epoch: 32 train loss: 3.2954769134521484 validation: auc: 0.5571502081054807 --- acc: 83.8 --- loss: 4.5666303634643555\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.32336456775665284\n",
            "epoch: 33 train loss: 3.0968902111053467 validation: auc: 0.5630164661562767 --- acc: 83.8 --- loss: 4.656867027282715\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3135540962219238\n",
            "epoch: 34 train loss: 3.4567275047302246 validation: auc: 0.5678279560092356 --- acc: 83.8 --- loss: 4.675882816314697\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3204876184463501\n",
            "epoch: 35 train loss: 3.0913281440734863 validation: auc: 0.571038780532264 --- acc: 83.85000000000001 --- loss: 4.62631893157959\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3206207513809204\n",
            "epoch: 36 train loss: 3.1060402393341064 validation: auc: 0.5716283494349252 --- acc: 83.65 --- loss: 4.607324600219727\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.31976962089538574\n",
            "epoch: 37 train loss: 3.119830369949341 validation: auc: 0.5721087389111678 --- acc: 83.75 --- loss: 4.758053779602051\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.31401925086975097\n",
            "epoch: 38 train loss: 3.299064874649048 validation: auc: 0.5720565226637501 --- acc: 83.7 --- loss: 4.713614463806152\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.31791775226593016\n",
            "epoch: 39 train loss: 3.2435054779052734 validation: auc: 0.5714584092842386 --- acc: 83.5 --- loss: 4.71875\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.31901113986968993\n",
            "epoch: 40 train loss: 3.254351854324341 validation: auc: 0.5634854629967189 --- acc: 83.85000000000001 --- loss: 4.68999719619751\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.32315855026245116\n",
            "epoch: 41 train loss: 3.014636278152466 validation: auc: 0.5553767544659132 --- acc: 83.95 --- loss: 4.5878682136535645\n",
            "<Timer(Thread-311, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.31888532638549805\n",
            "epoch: 42 train loss: 3.057360887527466 validation: auc: 0.554636233138899 --- acc: 84.1 --- loss: 4.609743595123291\n",
            "time up, break\n",
            "test auc: 0.5577018037655457 test acc: 83.05 test loss 4.840654373168945\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13961132764816284\n",
            "epoch: 0 train loss: 2.9373395442962646 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.305247497558594\n",
            "epoch: 1 train loss: 23.020095825195312 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.297476387023926\n",
            "epoch: 2 train loss: 23.330944061279297 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.3112920761108398\n",
            "epoch: 3 train loss: 22.778322219848633 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.303304672241211\n",
            "epoch: 4 train loss: 23.097806930541992 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.3097806930541993\n",
            "epoch: 5 train loss: 22.838768005371094 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2987714767456056\n",
            "epoch: 6 train loss: 23.279138565063477 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.3125869750976564\n",
            "epoch: 7 train loss: 22.726516723632812 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.3158248901367187\n",
            "epoch: 8 train loss: 22.597496032714844 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.3045549392700195\n",
            "epoch: 9 train loss: 23.037364959716797 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.311556816101074\n",
            "epoch: 10 train loss: 22.76968765258789 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.305679130554199\n",
            "epoch: 11 train loss: 22.994192123413086 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113353729248047\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.3074062347412108\n",
            "epoch: 12 train loss: 22.92511558532715 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.305679130554199\n",
            "epoch: 13 train loss: 22.994192123413086 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.3125869750976564\n",
            "epoch: 14 train loss: 22.717880249023438 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2994190216064454\n",
            "epoch: 15 train loss: 23.235963821411133 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2996347427368162\n",
            "epoch: 16 train loss: 23.21869468688965 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.306758499145508\n",
            "epoch: 17 train loss: 22.93375015258789 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.3030889511108397\n",
            "epoch: 18 train loss: 23.080537796020508 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2925111770629885\n",
            "epoch: 19 train loss: 23.503637313842773 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.3011459350585937\n",
            "epoch: 20 train loss: 23.154165267944336 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334800720215\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2996347427368162\n",
            "epoch: 21 train loss: 23.210060119628906 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.3043840408325194\n",
            "epoch: 22 train loss: 22.985557556152344 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.113351821899414\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2945329666137697\n",
            "epoch: 23 train loss: 23.380002975463867 validation: auc: 0.5 --- acc: 16.35 --- loss: 23.11334991455078\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.301577568054199\n",
            "epoch: 24 train loss: 23.0719051361084 validation: auc: 0.5002988643156008 --- acc: 16.400000000000002 --- loss: 23.099533081054688\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2927272796630858\n",
            "epoch: 25 train loss: 23.4000244140625 validation: auc: 0.5005977286312014 --- acc: 16.45 --- loss: 23.085742950439453\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.305679130554199\n",
            "epoch: 26 train loss: 22.856037139892578 validation: auc: 0.5008965929468021 --- acc: 16.5 --- loss: 23.07190704345703\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.301361846923828\n",
            "epoch: 27 train loss: 22.96363067626953 validation: auc: 0.49903211831736644 --- acc: 16.6 --- loss: 23.04427146911621\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2883028030395507\n",
            "epoch: 28 train loss: 23.253244400024414 validation: auc: 0.49894986208371495 --- acc: 16.950000000000003 --- loss: 22.94171905517578\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2879011154174806\n",
            "epoch: 29 train loss: 22.902366638183594 validation: auc: 0.4963587907236904 --- acc: 17.599999999999998 --- loss: 22.767963409423828\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2715791702270507\n",
            "epoch: 30 train loss: 22.58759307861328 validation: auc: 0.4934770806714302 --- acc: 18.75 --- loss: 22.47176742553711\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2436595916748048\n",
            "epoch: 31 train loss: 22.752464294433594 validation: auc: 0.4900844680123786 --- acc: 18.8 --- loss: 22.46657371520996\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2400102615356445\n",
            "epoch: 32 train loss: 22.723159790039062 validation: auc: 0.48670373680929896 --- acc: 18.6 --- loss: 22.489944458007812\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.238009452819824\n",
            "epoch: 33 train loss: 22.57837677001953 validation: auc: 0.4927843003924536 --- acc: 19.25 --- loss: 22.305870056152344\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2233814239501952\n",
            "epoch: 34 train loss: 22.463088989257812 validation: auc: 0.49923593098519203 --- acc: 20.0 --- loss: 22.07337760925293\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.2258655548095705\n",
            "epoch: 35 train loss: 21.6040096282959 validation: auc: 0.5029685360766701 --- acc: 20.9 --- loss: 21.87240982055664\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.1898147583007814\n",
            "epoch: 36 train loss: 21.7183895111084 validation: auc: 0.509655967872543 --- acc: 22.1 --- loss: 21.524883270263672\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.158090019226074\n",
            "epoch: 37 train loss: 20.896133422851562 validation: auc: 0.5123631119178316 --- acc: 23.9 --- loss: 21.00755500793457\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 2.0730026245117186\n",
            "epoch: 38 train loss: 20.149221420288086 validation: auc: 0.5349068036872728 --- acc: 29.25 --- loss: 19.513078689575195\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 1.9417430877685546\n",
            "epoch: 39 train loss: 18.025850296020508 validation: auc: 0.5382820511414423 --- acc: 41.65 --- loss: 16.135671615600586\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 1.6154159545898437\n",
            "epoch: 40 train loss: 11.934819221496582 validation: auc: 0.5323468069044054 --- acc: 73.75 --- loss: 7.266656398773193\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.7530443668365479\n",
            "epoch: 41 train loss: 5.272042274475098 validation: auc: 0.5157228220834226 --- acc: 83.39999999999999 --- loss: 4.615654468536377\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.4764870166778564\n",
            "epoch: 42 train loss: 4.728691101074219 validation: auc: 0.5119719378289107 --- acc: 83.8 --- loss: 4.469289779663086\n",
            "<Timer(Thread-399, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.45781192779541013\n",
            "epoch: 43 train loss: 4.6320881843566895 validation: auc: 0.5101120329902334 --- acc: 83.95 --- loss: 4.434779167175293\n",
            "time up, break\n",
            "test auc: 0.49879227053140096 test acc: 82.65 test loss 4.793982028961182\n",
            "0.01\n",
            "0.6634419315755002\n",
            "80.0\n",
            "0.5667077302932739\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FieldAwareFactorizationMachineModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FeaturesLinear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FieldAwareFactorizationMachine. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.38919098377227784\n",
            "epoch: 0 train loss: 3.876100540161133 validation: auc: 0.49025487918913807 --- acc: 22.900000000000002 --- loss: 3.901195526123047\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3854068279266357\n",
            "epoch: 1 train loss: 3.738839626312256 validation: auc: 0.49033088865673596 --- acc: 23.200000000000003 --- loss: 3.84458589553833\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.378995418548584\n",
            "epoch: 2 train loss: 3.6947410106658936 validation: auc: 0.4903361916428474 --- acc: 23.599999999999998 --- loss: 3.783527374267578\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.37086756229400636\n",
            "epoch: 3 train loss: 3.6933813095092773 validation: auc: 0.4904334130548912 --- acc: 24.15 --- loss: 3.7164783477783203\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.36436655521392824\n",
            "epoch: 4 train loss: 3.595386028289795 validation: auc: 0.4904979327192476 --- acc: 24.75 --- loss: 3.642489433288574\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.356765604019165\n",
            "epoch: 5 train loss: 3.502551794052124 validation: auc: 0.49056687153869677 --- acc: 25.6 --- loss: 3.560476303100586\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.34857635498046874\n",
            "epoch: 6 train loss: 3.387230157852173 validation: auc: 0.4906048762724957 --- acc: 26.5 --- loss: 3.470335006713867\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3370157480239868\n",
            "epoch: 7 train loss: 3.3641018867492676 validation: auc: 0.49063139120305316 --- acc: 27.0 --- loss: 3.3714091777801514\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3277184247970581\n",
            "epoch: 8 train loss: 3.203794240951538 validation: auc: 0.490641997175276 --- acc: 28.050000000000004 --- loss: 3.2574074268341064\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3166330337524414\n",
            "epoch: 9 train loss: 3.0688178539276123 validation: auc: 0.49066762827481486 --- acc: 28.549999999999997 --- loss: 3.1407055854797363\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.3014378547668457\n",
            "epoch: 10 train loss: 3.0479507446289062 validation: auc: 0.49068265340213074 --- acc: 29.549999999999997 --- loss: 3.015303611755371\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.2914459228515625\n",
            "epoch: 11 train loss: 2.7755167484283447 validation: auc: 0.49069856236046516 --- acc: 30.65 --- loss: 2.8819797039031982\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.2751914024353027\n",
            "epoch: 12 train loss: 2.7103939056396484 validation: auc: 0.4908603034368653 --- acc: 31.4 --- loss: 2.7412426471710205\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.2613806247711182\n",
            "epoch: 13 train loss: 2.503363609313965 validation: auc: 0.4910149738651168 --- acc: 33.75 --- loss: 2.594393730163574\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.2449573755264282\n",
            "epoch: 14 train loss: 2.3724467754364014 validation: auc: 0.4910794935294731 --- acc: 35.75 --- loss: 2.442276954650879\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.22803177833557128\n",
            "epoch: 15 train loss: 2.2389931678771973 validation: auc: 0.4913031027771738 --- acc: 37.7 --- loss: 2.287475109100342\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.21136226654052734\n",
            "epoch: 16 train loss: 2.078993797302246 validation: auc: 0.49158592870311935 --- acc: 39.300000000000004 --- loss: 2.1314120292663574\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1948687791824341\n",
            "epoch: 17 train loss: 1.910025954246521 validation: auc: 0.4918678707980464 --- acc: 41.449999999999996 --- loss: 1.9766501188278198\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.17975869178771972\n",
            "epoch: 18 train loss: 1.6942187547683716 validation: auc: 0.49226471092538876 --- acc: 43.95 --- loss: 1.8256523609161377\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.16409682035446166\n",
            "epoch: 19 train loss: 1.526365041732788 validation: auc: 0.4927640754508864 --- acc: 46.85 --- loss: 1.6811593770980835\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14710240364074706\n",
            "epoch: 20 train loss: 1.4507255554199219 validation: auc: 0.49356129102964547 --- acc: 48.8 --- loss: 1.5453948974609375\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1343313932418823\n",
            "epoch: 21 train loss: 1.2609219551086426 validation: auc: 0.4942948707750668 --- acc: 52.449999999999996 --- loss: 1.4206165075302124\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1213527798652649\n",
            "epoch: 22 train loss: 1.1383578777313232 validation: auc: 0.49528299385383906 --- acc: 54.75 --- loss: 1.3086748123168945\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10934443473815918\n",
            "epoch: 23 train loss: 1.0508179664611816 validation: auc: 0.4965928314233745 --- acc: 57.65 --- loss: 1.2106413841247559\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0994063138961792\n",
            "epoch: 24 train loss: 0.9526645541191101 validation: auc: 0.49823498945589595 --- acc: 60.699999999999996 --- loss: 1.1269035339355469\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09143922328948975\n",
            "epoch: 25 train loss: 0.8541011810302734 validation: auc: 0.5001458321180656 --- acc: 62.849999999999994 --- loss: 1.057058572769165\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0832832932472229\n",
            "epoch: 26 train loss: 0.8329761028289795 validation: auc: 0.5025781350811976 --- acc: 65.2 --- loss: 1.0001510381698608\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07923412322998047\n",
            "epoch: 27 train loss: 0.7144716382026672 validation: auc: 0.5054841714702882 --- acc: 67.2 --- loss: 0.9546710252761841\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07399265766143799\n",
            "epoch: 28 train loss: 0.6948460936546326 validation: auc: 0.5088833855677466 --- acc: 69.19999999999999 --- loss: 0.9188156127929688\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0700665295124054\n",
            "epoch: 29 train loss: 0.6710644364356995 validation: auc: 0.5126891619337516 --- acc: 70.95 --- loss: 0.890508770942688\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06577295064926147\n",
            "epoch: 30 train loss: 0.6943234801292419 validation: auc: 0.5166717045034726 --- acc: 72.85000000000001 --- loss: 0.8679120540618896\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06372411251068115\n",
            "epoch: 31 train loss: 0.6521707773208618 validation: auc: 0.5209193963787676 --- acc: 74.2 --- loss: 0.8492914438247681\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06175884008407593\n",
            "epoch: 32 train loss: 0.6216143369674683 validation: auc: 0.5252554713559205 --- acc: 75.1 --- loss: 0.8333438634872437\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.060252076387405394\n",
            "epoch: 33 train loss: 0.5813186168670654 validation: auc: 0.5297771508469752 --- acc: 75.7 --- loss: 0.8190501928329468\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.058310335874557494\n",
            "epoch: 34 train loss: 0.5621793866157532 validation: auc: 0.5344685258935974 --- acc: 76.2 --- loss: 0.8057616353034973\n",
            "<Timer(Thread-489, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05606212615966797\n",
            "epoch: 35 train loss: 0.556752622127533 validation: auc: 0.5390732855003986 --- acc: 76.25 --- loss: 0.793106198310852\n",
            "time up, break\n",
            "test auc: 0.553820492512983 test acc: 76.2 test loss 0.7622331380844116\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10883220434188842\n",
            "epoch: 0 train loss: 1.0373632907867432 validation: auc: 0.5574269069203402 --- acc: 66.75 --- loss: 1.1104438304901123\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1067735195159912\n",
            "epoch: 1 train loss: 1.0575263500213623 validation: auc: 0.5580192701525816 --- acc: 67.10000000000001 --- loss: 1.1000045537948608\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10557098388671875\n",
            "epoch: 2 train loss: 1.044646143913269 validation: auc: 0.558646581068141 --- acc: 67.4 --- loss: 1.0892497301101685\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10381547212600709\n",
            "epoch: 3 train loss: 1.050344705581665 validation: auc: 0.5593857245703182 --- acc: 67.45 --- loss: 1.077853798866272\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1022986650466919\n",
            "epoch: 4 train loss: 1.0414503812789917 validation: auc: 0.5602367006591134 --- acc: 67.85 --- loss: 1.065590500831604\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10032230615615845\n",
            "epoch: 5 train loss: 1.0457819700241089 validation: auc: 0.561185530261199 --- acc: 68.35 --- loss: 1.0524225234985352\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09957815408706665\n",
            "epoch: 6 train loss: 0.9946116805076599 validation: auc: 0.5622287186082434 --- acc: 68.89999999999999 --- loss: 1.038617730140686\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09834943413734436\n",
            "epoch: 7 train loss: 0.9574835300445557 validation: auc: 0.563432666298551 --- acc: 69.65 --- loss: 1.024084448814392\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0948373556137085\n",
            "epoch: 8 train loss: 1.0060409307479858 validation: auc: 0.5648288262471081 --- acc: 70.39999999999999 --- loss: 1.00875723361969\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09435797929763794\n",
            "epoch: 9 train loss: 0.9282689094543457 validation: auc: 0.56642768275891 --- acc: 71.1 --- loss: 0.993074357509613\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09089632630348206\n",
            "epoch: 10 train loss: 0.9649612903594971 validation: auc: 0.5682012776873021 --- acc: 71.85000000000001 --- loss: 0.9768635034561157\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.090566086769104\n",
            "epoch: 11 train loss: 0.8741966485977173 validation: auc: 0.5701164107331325 --- acc: 72.39999999999999 --- loss: 0.960478663444519\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08829587697982788\n",
            "epoch: 12 train loss: 0.8570220470428467 validation: auc: 0.5720717336147787 --- acc: 72.7 --- loss: 0.9440311789512634\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08612807393074036\n",
            "epoch: 13 train loss: 0.8329560160636902 validation: auc: 0.574350322567117 --- acc: 73.05 --- loss: 0.9276313185691833\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08335444927215577\n",
            "epoch: 14 train loss: 0.8330745697021484 validation: auc: 0.5767459862585709 --- acc: 73.7 --- loss: 0.9113142490386963\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08126025199890137\n",
            "epoch: 15 train loss: 0.8037325143814087 validation: auc: 0.57908398627255 --- acc: 74.05000000000001 --- loss: 0.8950932621955872\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07849643230438233\n",
            "epoch: 16 train loss: 0.8011590838432312 validation: auc: 0.5815547874831377 --- acc: 74.05000000000001 --- loss: 0.8790338039398193\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07679157257080078\n",
            "epoch: 17 train loss: 0.7556604146957397 validation: auc: 0.584217800951975 --- acc: 74.4 --- loss: 0.863142728805542\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07364475727081299\n",
            "epoch: 18 train loss: 0.766197144985199 validation: auc: 0.587080016215725 --- acc: 74.45 --- loss: 0.8473455309867859\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07125990986824035\n",
            "epoch: 19 train loss: 0.7461304664611816 validation: auc: 0.5901029908227383 --- acc: 74.5 --- loss: 0.8316383957862854\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06917672753334045\n",
            "epoch: 20 train loss: 0.7128953337669373 validation: auc: 0.5930910177464335 --- acc: 74.75 --- loss: 0.8160814046859741\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06830085515975952\n",
            "epoch: 21 train loss: 0.6314617991447449 validation: auc: 0.5960388548343131 --- acc: 74.95 --- loss: 0.8007243275642395\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06598082184791565\n",
            "epoch: 22 train loss: 0.606960117816925 validation: auc: 0.5988102061214362 --- acc: 75.1 --- loss: 0.7856771349906921\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.062362128496170045\n",
            "epoch: 23 train loss: 0.6343162059783936 validation: auc: 0.6015230200390016 --- acc: 75.14999999999999 --- loss: 0.7710103988647461\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06008425951004028\n",
            "epoch: 24 train loss: 0.6088517904281616 validation: auc: 0.604525899728107 --- acc: 75.5 --- loss: 0.756680428981781\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05799680948257446\n",
            "epoch: 25 train loss: 0.5785350203514099 validation: auc: 0.6071504707452943 --- acc: 75.5 --- loss: 0.742703378200531\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05640354156494141\n",
            "epoch: 26 train loss: 0.5292670130729675 validation: auc: 0.6099323063374129 --- acc: 75.7 --- loss: 0.7290322184562683\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.053818154335021975\n",
            "epoch: 27 train loss: 0.520893931388855 validation: auc: 0.6126704573253839 --- acc: 75.75 --- loss: 0.7156258225440979\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.051165467500686644\n",
            "epoch: 28 train loss: 0.5160031914710999 validation: auc: 0.6150661210168379 --- acc: 75.94999999999999 --- loss: 0.7025076150894165\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.049726802110672\n",
            "epoch: 29 train loss: 0.46575745940208435 validation: auc: 0.6174565425557939 --- acc: 76.25 --- loss: 0.68985915184021\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.047496023774147036\n",
            "epoch: 30 train loss: 0.4492439329624176 validation: auc: 0.6197997847222708 --- acc: 76.35 --- loss: 0.6777797937393188\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04514624774456024\n",
            "epoch: 31 train loss: 0.4399947226047516 validation: auc: 0.6220067309238071 --- acc: 76.14999999999999 --- loss: 0.6662930250167847\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04288185834884643\n",
            "epoch: 32 train loss: 0.43145355582237244 validation: auc: 0.6245142272018788 --- acc: 76.75 --- loss: 0.6554797291755676\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04172895848751068\n",
            "epoch: 33 train loss: 0.3826259970664978 validation: auc: 0.6269570702658122 --- acc: 77.10000000000001 --- loss: 0.645306408405304\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.03910994827747345\n",
            "epoch: 34 train loss: 0.39444828033447266 validation: auc: 0.6296323154238106 --- acc: 77.2 --- loss: 0.6356856226921082\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.037664031982421874\n",
            "epoch: 35 train loss: 0.3635379374027252 validation: auc: 0.6323093079659751 --- acc: 77.25 --- loss: 0.6265835762023926\n",
            "<Timer(Thread-563, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.036290335655212405\n",
            "epoch: 36 train loss: 0.3328695297241211 validation: auc: 0.6353165561154951 --- acc: 77.25 --- loss: 0.6180252432823181\n",
            "time up, break\n",
            "test auc: 0.6598603819348501 test acc: 78.75 test loss 0.5426446199417114\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13856451511383056\n",
            "epoch: 0 train loss: 1.3834644556045532 validation: auc: 0.4969924662679495 --- acc: 54.35 --- loss: 1.4237477779388428\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1362461566925049\n",
            "epoch: 1 train loss: 1.369106650352478 validation: auc: 0.4973319537141371 --- acc: 54.75 --- loss: 1.4027513265609741\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13545950651168823\n",
            "epoch: 2 train loss: 1.293973445892334 validation: auc: 0.49780326341336567 --- acc: 55.7 --- loss: 1.380676507949829\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1326633095741272\n",
            "epoch: 3 train loss: 1.291914701461792 validation: auc: 0.49831791193551184 --- acc: 56.39999999999999 --- loss: 1.3570209741592407\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1307001829147339\n",
            "epoch: 4 train loss: 1.2486482858657837 validation: auc: 0.49889576290774607 --- acc: 57.550000000000004 --- loss: 1.3315129280090332\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12841056585311889\n",
            "epoch: 5 train loss: 1.2080202102661133 validation: auc: 0.49971558897460344 --- acc: 57.95 --- loss: 1.3040580749511719\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12488648891448975\n",
            "epoch: 6 train loss: 1.2053275108337402 validation: auc: 0.5006545968044842 --- acc: 58.599999999999994 --- loss: 1.274659276008606\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12123309373855591\n",
            "epoch: 7 train loss: 1.1994491815567017 validation: auc: 0.5015629063014648 --- acc: 59.5 --- loss: 1.2434637546539307\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11867425441741944\n",
            "epoch: 8 train loss: 1.1379812955856323 validation: auc: 0.5025750483950189 --- acc: 60.650000000000006 --- loss: 1.2107239961624146\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11636252403259277\n",
            "epoch: 9 train loss: 1.0597736835479736 validation: auc: 0.5040007150905781 --- acc: 61.8 --- loss: 1.1767776012420654\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.111564302444458\n",
            "epoch: 10 train loss: 1.0724387168884277 validation: auc: 0.5054290904625697 --- acc: 62.949999999999996 --- loss: 1.1420457363128662\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10727468729019166\n",
            "epoch: 11 train loss: 1.0592440366744995 validation: auc: 0.5069730360290081 --- acc: 63.9 --- loss: 1.106884241104126\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10498489141464233\n",
            "epoch: 12 train loss: 0.9642909169197083 validation: auc: 0.5089738450203694 --- acc: 64.75 --- loss: 1.071729302406311\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1004288673400879\n",
            "epoch: 13 train loss: 0.9603175520896912 validation: auc: 0.511344839790818 --- acc: 66.45 --- loss: 1.0371646881103516\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09615020155906677\n",
            "epoch: 14 train loss: 0.945303201675415 validation: auc: 0.5142142310248187 --- acc: 67.9 --- loss: 1.0037057399749756\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09279714822769165\n",
            "epoch: 15 train loss: 0.8994260430335999 validation: auc: 0.5169752752015255 --- acc: 68.65 --- loss: 0.9717413783073425\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08850693702697754\n",
            "epoch: 16 train loss: 0.8990344405174255 validation: auc: 0.5204062653491665 --- acc: 70.25 --- loss: 0.9417096972465515\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08571426272392273\n",
            "epoch: 17 train loss: 0.8469357490539551 validation: auc: 0.5240846479442952 --- acc: 71.3 --- loss: 0.9138957262039185\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08267043828964234\n",
            "epoch: 18 train loss: 0.8159139156341553 validation: auc: 0.5280808485741527 --- acc: 72.3 --- loss: 0.888387143611908\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07946524024009705\n",
            "epoch: 19 train loss: 0.8010822534561157 validation: auc: 0.5323424994943804 --- acc: 73.35000000000001 --- loss: 0.8651111125946045\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07774505019187927\n",
            "epoch: 20 train loss: 0.7403106093406677 validation: auc: 0.5365138612001965 --- acc: 74.0 --- loss: 0.8439126014709473\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07457202076911926\n",
            "epoch: 21 train loss: 0.7447264194488525 validation: auc: 0.5412540449568057 --- acc: 74.55000000000001 --- loss: 0.8246424198150635\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07195537090301514\n",
            "epoch: 22 train loss: 0.7381434440612793 validation: auc: 0.5463571913553494 --- acc: 75.1 --- loss: 0.8070111274719238\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06965571641921997\n",
            "epoch: 23 train loss: 0.7238057851791382 validation: auc: 0.5508770694287943 --- acc: 75.85 --- loss: 0.7907509803771973\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06873310208320618\n",
            "epoch: 24 train loss: 0.6608014702796936 validation: auc: 0.5555269639709919 --- acc: 76.2 --- loss: 0.7756112217903137\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06635710000991821\n",
            "epoch: 25 train loss: 0.6608291864395142 validation: auc: 0.5601714411603247 --- acc: 76.25 --- loss: 0.7614739537239075\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06381704211235047\n",
            "epoch: 26 train loss: 0.6706912517547607 validation: auc: 0.5647581332524342 --- acc: 76.35 --- loss: 0.7482336163520813\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06335884928703309\n",
            "epoch: 27 train loss: 0.6024883389472961 validation: auc: 0.5690432593684089 --- acc: 76.44999999999999 --- loss: 0.7358232736587524\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.061848288774490355\n",
            "epoch: 28 train loss: 0.5798957347869873 validation: auc: 0.5728841625494785 --- acc: 76.8 --- loss: 0.7243379950523376\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.059361815452575684\n",
            "epoch: 29 train loss: 0.599358320236206 validation: auc: 0.5765029542630955 --- acc: 76.75 --- loss: 0.7136166095733643\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05871439576148987\n",
            "epoch: 30 train loss: 0.5494856238365173 validation: auc: 0.5798978287249719 --- acc: 76.8 --- loss: 0.7035422325134277\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05625653266906738\n",
            "epoch: 31 train loss: 0.5751165151596069 validation: auc: 0.5829098769177429 --- acc: 76.85 --- loss: 0.693985641002655\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05605251789093017\n",
            "epoch: 32 train loss: 0.5129909515380859 validation: auc: 0.5856311938401086 --- acc: 77.2 --- loss: 0.6847819089889526\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05500935912132263\n",
            "epoch: 33 train loss: 0.4857732355594635 validation: auc: 0.5881899901765335 --- acc: 77.35 --- loss: 0.6758790016174316\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05168241858482361\n",
            "epoch: 34 train loss: 0.5501247644424438 validation: auc: 0.5902305264222356 --- acc: 77.3 --- loss: 0.6672224998474121\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.051805692911148074\n",
            "epoch: 35 train loss: 0.47864261269569397 validation: auc: 0.5920633974747912 --- acc: 77.60000000000001 --- loss: 0.6588256359100342\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04966085851192474\n",
            "epoch: 36 train loss: 0.4985491931438446 validation: auc: 0.5938348718615469 --- acc: 77.75 --- loss: 0.6506739854812622\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04869080483913422\n",
            "epoch: 37 train loss: 0.47318145632743835 validation: auc: 0.5951711522348386 --- acc: 77.9 --- loss: 0.6429411768913269\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04707769155502319\n",
            "epoch: 38 train loss: 0.4746784567832947 validation: auc: 0.5967042630955477 --- acc: 77.75 --- loss: 0.635611891746521\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04656410217285156\n",
            "epoch: 39 train loss: 0.4343922436237335 validation: auc: 0.5981976467019154 --- acc: 77.7 --- loss: 0.628642201423645\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.044612616300582886\n",
            "epoch: 40 train loss: 0.45260173082351685 validation: auc: 0.599532121290919 --- acc: 77.8 --- loss: 0.6220056414604187\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04364539384841919\n",
            "epoch: 41 train loss: 0.433342844247818 validation: auc: 0.6010056412701165 --- acc: 77.7 --- loss: 0.6157034635543823\n",
            "<Timer(Thread-639, started 139803936945920)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04239646196365356\n",
            "epoch: 42 train loss: 0.42591068148612976 validation: auc: 0.6029080350177689 --- acc: 77.8 --- loss: 0.6096963882446289\n",
            "time up, break\n",
            "test auc: 0.6145424563747182 test acc: 77.4 test loss 0.6176061034202576\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.2475682020187378\n",
            "epoch: 0 train loss: 2.3679208755493164 validation: auc: 0.5523588975898513 --- acc: 39.45 --- loss: 2.4419565200805664\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.24315166473388672\n",
            "epoch: 1 train loss: 2.3556783199310303 validation: auc: 0.5524138415560131 --- acc: 39.95 --- loss: 2.4031364917755127\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.23791649341583251\n",
            "epoch: 2 train loss: 2.3717153072357178 validation: auc: 0.5525165237222825 --- acc: 40.25 --- loss: 2.3618903160095215\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.2345548152923584\n",
            "epoch: 3 train loss: 2.3004002571105957 validation: auc: 0.55259758859039 --- acc: 40.949999999999996 --- loss: 2.317049503326416\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.22984607219696046\n",
            "epoch: 4 train loss: 2.265808343887329 validation: auc: 0.5527038736396865 --- acc: 41.65 --- loss: 2.2680604457855225\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.2248523235321045\n",
            "epoch: 5 train loss: 2.219642400741577 validation: auc: 0.5528678048174149 --- acc: 42.199999999999996 --- loss: 2.214364528656006\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.21939678192138673\n",
            "epoch: 6 train loss: 2.1702494621276855 validation: auc: 0.5530128208592516 --- acc: 43.0 --- loss: 2.155613899230957\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.21230297088623046\n",
            "epoch: 7 train loss: 2.1612792015075684 validation: auc: 0.5531821563615205 --- acc: 43.9 --- loss: 2.091831922531128\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.20752441883087158\n",
            "epoch: 8 train loss: 2.0359041690826416 validation: auc: 0.5534001307846539 --- acc: 44.7 --- loss: 2.023104667663574\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1972380042076111\n",
            "epoch: 9 train loss: 2.1033241748809814 validation: auc: 0.5536298145776251 --- acc: 45.85 --- loss: 1.9496291875839233\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.19300220012664795\n",
            "epoch: 10 train loss: 1.9088598489761353 validation: auc: 0.5538901228763256 --- acc: 47.0 --- loss: 1.871755838394165\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.18676702976226806\n",
            "epoch: 11 train loss: 1.7734670639038086 validation: auc: 0.5541558354995668 --- acc: 48.4 --- loss: 1.790160059928894\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.17790145874023439\n",
            "epoch: 12 train loss: 1.7244607210159302 validation: auc: 0.5544945065041045 --- acc: 49.85 --- loss: 1.7056149244308472\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1696905016899109\n",
            "epoch: 13 train loss: 1.6377280950546265 validation: auc: 0.5549412639994523 --- acc: 51.05 --- loss: 1.6190893650054932\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1621645212173462\n",
            "epoch: 14 train loss: 1.5139808654785156 validation: auc: 0.5554762921289615 --- acc: 52.349999999999994 --- loss: 1.5317524671554565\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.15258079767227173\n",
            "epoch: 15 train loss: 1.4698566198349 validation: auc: 0.5560329375566329 --- acc: 54.50000000000001 --- loss: 1.4448567628860474\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14476296901702881\n",
            "epoch: 16 train loss: 1.3584288358688354 validation: auc: 0.556575171452196 --- acc: 56.3 --- loss: 1.3596982955932617\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1346818208694458\n",
            "epoch: 17 train loss: 1.3483097553253174 validation: auc: 0.5572272932800827 --- acc: 58.25 --- loss: 1.2776082754135132\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1282606840133667\n",
            "epoch: 18 train loss: 1.2084711790084839 validation: auc: 0.5578956280815909 --- acc: 59.8 --- loss: 1.1998883485794067\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11960043907165527\n",
            "epoch: 19 train loss: 1.1829462051391602 validation: auc: 0.5586017931548826 --- acc: 61.6 --- loss: 1.1277868747711182\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11198968887329101\n",
            "epoch: 20 train loss: 1.1416279077529907 validation: auc: 0.5593656043566062 --- acc: 63.9 --- loss: 1.062327265739441\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10719610452651977\n",
            "epoch: 21 train loss: 1.0244290828704834 validation: auc: 0.5600411449241682 --- acc: 65.5 --- loss: 1.0041526556015015\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1005319595336914\n",
            "epoch: 22 train loss: 1.0136014223098755 validation: auc: 0.5612174862324832 --- acc: 67.4 --- loss: 0.953498899936676\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09706314206123352\n",
            "epoch: 23 train loss: 0.9171665906906128 validation: auc: 0.5622839396084747 --- acc: 69.0 --- loss: 0.9102178812026978\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09196518659591675\n",
            "epoch: 24 train loss: 0.9194750785827637 validation: auc: 0.5637719302986249 --- acc: 70.39999999999999 --- loss: 0.8740899562835693\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08882513642311096\n",
            "epoch: 25 train loss: 0.873359203338623 validation: auc: 0.5652743325208832 --- acc: 71.8 --- loss: 0.8441278338432312\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08583335876464844\n",
            "epoch: 26 train loss: 0.8514859080314636 validation: auc: 0.5672216907969758 --- acc: 72.6 --- loss: 0.8192580342292786\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08446272015571595\n",
            "epoch: 27 train loss: 0.7875927090644836 validation: auc: 0.5689384645593404 --- acc: 73.45 --- loss: 0.7985586524009705\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08275971412658692\n",
            "epoch: 28 train loss: 0.754626452922821 validation: auc: 0.5707218916577045 --- acc: 74.3 --- loss: 0.7810666561126709\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08040057420730591\n",
            "epoch: 29 train loss: 0.7627503871917725 validation: auc: 0.5727070802055805 --- acc: 75.1 --- loss: 0.7659268379211426\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07810941934585572\n",
            "epoch: 30 train loss: 0.777100682258606 validation: auc: 0.5747877451536719 --- acc: 75.8 --- loss: 0.7523982524871826\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07704868912696838\n",
            "epoch: 31 train loss: 0.748553991317749 validation: auc: 0.5769008360490064 --- acc: 76.14999999999999 --- loss: 0.7399058938026428\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07309256792068482\n",
            "epoch: 32 train loss: 0.839244544506073 validation: auc: 0.5789004361289904 --- acc: 76.7 --- loss: 0.7281166911125183\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07413289546966553\n",
            "epoch: 33 train loss: 0.7337216138839722 validation: auc: 0.5811972740587018 --- acc: 77.0 --- loss: 0.7168712615966797\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07207955718040467\n",
            "epoch: 34 train loss: 0.7531700134277344 validation: auc: 0.5833139678370631 --- acc: 77.3 --- loss: 0.7062379121780396\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07206777334213257\n",
            "epoch: 35 train loss: 0.6940075159072876 validation: auc: 0.5856711540574767 --- acc: 77.55 --- loss: 0.6963006854057312\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06941751837730407\n",
            "epoch: 36 train loss: 0.7419003844261169 validation: auc: 0.5876464346770286 --- acc: 77.64999999999999 --- loss: 0.6871010661125183\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06939486861228943\n",
            "epoch: 37 train loss: 0.6897016167640686 validation: auc: 0.589701879443931 --- acc: 77.64999999999999 --- loss: 0.6785898208618164\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0683969497680664\n",
            "epoch: 38 train loss: 0.6783090233802795 validation: auc: 0.5914961151913761 --- acc: 77.60000000000001 --- loss: 0.6708232760429382\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0676607370376587\n",
            "epoch: 39 train loss: 0.6605142951011658 validation: auc: 0.5933227768860643 --- acc: 77.60000000000001 --- loss: 0.6637007594108582\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06698458790779113\n",
            "epoch: 40 train loss: 0.6434733867645264 validation: auc: 0.5951782616449683 --- acc: 77.5 --- loss: 0.657157838344574\n",
            "<Timer(Thread-727, started 139803878790912)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06536540389060974\n",
            "epoch: 41 train loss: 0.6671933531761169 validation: auc: 0.5971112083889528 --- acc: 77.3 --- loss: 0.6511412858963013\n",
            "time up, break\n",
            "test auc: 0.5799035591274397 test acc: 76.2 test loss 0.6627119183540344\n",
            "0.001\n",
            "0.6598603819348501\n",
            "78.75\n",
            "0.5426446199417114\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FieldAwareFactorizationMachineModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FeaturesLinear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FieldAwareFactorizationMachine. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14918605089187623\n",
            "epoch: 0 train loss: 1.4904152154922485 validation: auc: 0.5205101073994836 --- acc: 63.849999999999994 --- loss: 1.3815295696258545\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14876947402954102\n",
            "epoch: 1 train loss: 1.4568352699279785 validation: auc: 0.5209044467561573 --- acc: 64.0 --- loss: 1.3724688291549683\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14697262048721313\n",
            "epoch: 2 train loss: 1.478671669960022 validation: auc: 0.5213041391357723 --- acc: 64.2 --- loss: 1.3633869886398315\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1460339307785034\n",
            "epoch: 3 train loss: 1.4663156270980835 validation: auc: 0.521791264223428 --- acc: 64.45 --- loss: 1.3541975021362305\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14370408058166503\n",
            "epoch: 4 train loss: 1.5087207555770874 validation: auc: 0.5221873879210821 --- acc: 64.45 --- loss: 1.344863772392273\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1441219687461853\n",
            "epoch: 5 train loss: 1.4405674934387207 validation: auc: 0.5226316888252078 --- acc: 64.55 --- loss: 1.335344672203064\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14210571050643922\n",
            "epoch: 6 train loss: 1.468278169631958 validation: auc: 0.5231937562340413 --- acc: 64.75 --- loss: 1.3256205320358276\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1414215087890625\n",
            "epoch: 7 train loss: 1.4416146278381348 validation: auc: 0.5236826656626774 --- acc: 65.05 --- loss: 1.3156731128692627\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1409091353416443\n",
            "epoch: 8 train loss: 1.4060744047164917 validation: auc: 0.5242090462519026 --- acc: 65.25 --- loss: 1.3054662942886353\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13822546005249023\n",
            "epoch: 9 train loss: 1.4563637971878052 validation: auc: 0.5247764666836774 --- acc: 65.60000000000001 --- loss: 1.2949711084365845\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13968619108200073\n",
            "epoch: 10 train loss: 1.3391841650009155 validation: auc: 0.5253724365711391 --- acc: 65.85 --- loss: 1.2841992378234863\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13743867874145507\n",
            "epoch: 11 train loss: 1.3681955337524414 validation: auc: 0.5260683295535044 --- acc: 65.95 --- loss: 1.2731637954711914\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13545299768447877\n",
            "epoch: 12 train loss: 1.3846793174743652 validation: auc: 0.5267392417621437 --- acc: 66.3 --- loss: 1.2618173360824585\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1353622555732727\n",
            "epoch: 13 train loss: 1.3238275051116943 validation: auc: 0.5276117845015711 --- acc: 66.64999999999999 --- loss: 1.250152349472046\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1351393222808838\n",
            "epoch: 14 train loss: 1.266282320022583 validation: auc: 0.5284307970115858 --- acc: 67.0 --- loss: 1.2381675243377686\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12982745170593263\n",
            "epoch: 15 train loss: 1.4100221395492554 validation: auc: 0.529244456498659 --- acc: 67.35 --- loss: 1.2258788347244263\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13040516376495362\n",
            "epoch: 16 train loss: 1.3167380094528198 validation: auc: 0.5301526860576948 --- acc: 67.60000000000001 --- loss: 1.2132920026779175\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12894634008407593\n",
            "epoch: 17 train loss: 1.302513837814331 validation: auc: 0.5311679760755561 --- acc: 67.9 --- loss: 1.2004375457763672\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12720617055892944\n",
            "epoch: 18 train loss: 1.2979211807250977 validation: auc: 0.5323010325981254 --- acc: 68.2 --- loss: 1.1873180866241455\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12689752578735353\n",
            "epoch: 19 train loss: 1.234166145324707 validation: auc: 0.5334430108255968 --- acc: 68.35 --- loss: 1.1739469766616821\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12602906227111815\n",
            "epoch: 20 train loss: 1.1914544105529785 validation: auc: 0.5344993406860077 --- acc: 68.60000000000001 --- loss: 1.160349726676941\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12240413427352906\n",
            "epoch: 21 train loss: 1.256659746170044 validation: auc: 0.5357091238707352 --- acc: 68.89999999999999 --- loss: 1.1465308666229248\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12246125936508179\n",
            "epoch: 22 train loss: 1.1735036373138428 validation: auc: 0.5369492408521299 --- acc: 69.1 --- loss: 1.1324927806854248\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11983696222305298\n",
            "epoch: 23 train loss: 1.196418046951294 validation: auc: 0.5383356737939193 --- acc: 69.3 --- loss: 1.1182842254638672\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11754227876663208\n",
            "epoch: 24 train loss: 1.2038483619689941 validation: auc: 0.5397881273519844 --- acc: 69.55 --- loss: 1.103914499282837\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11640443801879882\n",
            "epoch: 25 train loss: 1.1643691062927246 validation: auc: 0.5413565630737771 --- acc: 69.89999999999999 --- loss: 1.0893759727478027\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1134944200515747\n",
            "epoch: 26 train loss: 1.1940062046051025 validation: auc: 0.5430052941396889 --- acc: 69.8 --- loss: 1.074689507484436\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11280457973480225\n",
            "epoch: 27 train loss: 1.1350568532943726 validation: auc: 0.5444809441304996 --- acc: 70.1 --- loss: 1.0598982572555542\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11066954135894776\n",
            "epoch: 28 train loss: 1.131616473197937 validation: auc: 0.5463313057271992 --- acc: 70.39999999999999 --- loss: 1.0450701713562012\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10821766853332519\n",
            "epoch: 29 train loss: 1.140805721282959 validation: auc: 0.5480656851601714 --- acc: 70.89999999999999 --- loss: 1.030212163925171\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10790982246398925\n",
            "epoch: 30 train loss: 1.063486933708191 validation: auc: 0.5498750069143212 --- acc: 71.15 --- loss: 1.0153697729110718\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10579525232315064\n",
            "epoch: 31 train loss: 1.0579252243041992 validation: auc: 0.5518681157894549 --- acc: 71.3 --- loss: 1.0005419254302979\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10449550151824952\n",
            "epoch: 32 train loss: 1.0198442935943604 validation: auc: 0.5540039719430223 --- acc: 71.45 --- loss: 0.985755980014801\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10283430814743041\n",
            "epoch: 33 train loss: 0.9960649013519287 validation: auc: 0.5559399819067825 --- acc: 71.65 --- loss: 0.9710667133331299\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10034608840942383\n",
            "epoch: 34 train loss: 1.004569411277771 validation: auc: 0.5579616402376029 --- acc: 71.8 --- loss: 0.9564836025238037\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09918986558914185\n",
            "epoch: 35 train loss: 0.9610633850097656 validation: auc: 0.5601938508041132 --- acc: 72.0 --- loss: 0.9420120120048523\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09738196730613709\n",
            "epoch: 36 train loss: 0.9431588649749756 validation: auc: 0.5624706698951343 --- acc: 72.3 --- loss: 0.9277024865150452\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09624990820884705\n",
            "epoch: 37 train loss: 0.8984485864639282 validation: auc: 0.5648599024679221 --- acc: 72.6 --- loss: 0.9135469198226929\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09504144191741944\n",
            "epoch: 38 train loss: 0.8580864071846008 validation: auc: 0.5669886212575679 --- acc: 72.75 --- loss: 0.8995834589004517\n",
            "<Timer(Thread-813, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09100329875946045\n",
            "epoch: 39 train loss: 0.9301936626434326 validation: auc: 0.5692475969387846 --- acc: 72.85000000000001 --- loss: 0.8858503103256226\n",
            "time up, break\n",
            "test auc: 0.5563979477124879 test acc: 73.05 test loss 0.9477402567863464\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.168760347366333\n",
            "epoch: 0 train loss: 1.655631422996521 validation: auc: 0.4982700586518737 --- acc: 44.75 --- loss: 1.6851426362991333\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.16599270105361938\n",
            "epoch: 1 train loss: 1.6577526330947876 validation: auc: 0.49835312472913235 --- acc: 45.300000000000004 --- loss: 1.6648409366607666\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.16371859312057496\n",
            "epoch: 2 train loss: 1.6398684978485107 validation: auc: 0.4984614717864263 --- acc: 46.050000000000004 --- loss: 1.6442015171051025\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.16016175746917724\n",
            "epoch: 3 train loss: 1.6716538667678833 validation: auc: 0.49859509982375544 --- acc: 46.35 --- loss: 1.6230412721633911\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.16006213426589966\n",
            "epoch: 4 train loss: 1.5632437467575073 validation: auc: 0.4987323394296611 --- acc: 47.199999999999996 --- loss: 1.6012639999389648\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1584712505340576\n",
            "epoch: 5 train loss: 1.509968876838684 validation: auc: 0.4989075005056196 --- acc: 47.599999999999994 --- loss: 1.5788079500198364\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1533380389213562\n",
            "epoch: 6 train loss: 1.593946099281311 validation: auc: 0.4990555748172546 --- acc: 48.05 --- loss: 1.5555939674377441\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.15225095748901368\n",
            "epoch: 7 train loss: 1.5125819444656372 validation: auc: 0.49927768628470715 --- acc: 48.949999999999996 --- loss: 1.5315912961959839\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14995917081832885\n",
            "epoch: 8 train loss: 1.4745967388153076 validation: auc: 0.4994329837334951 --- acc: 49.35 --- loss: 1.5067998170852661\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14705461263656616\n",
            "epoch: 9 train loss: 1.4563102722167969 validation: auc: 0.49964967784808295 --- acc: 50.1 --- loss: 1.4812334775924683\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14397056102752687\n",
            "epoch: 10 train loss: 1.4408526420593262 validation: auc: 0.5000415330386293 --- acc: 50.9 --- loss: 1.4549157619476318\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.14156851768493653\n",
            "epoch: 11 train loss: 1.394029974937439 validation: auc: 0.500474921267805 --- acc: 51.4 --- loss: 1.4278838634490967\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1372031807899475\n",
            "epoch: 12 train loss: 1.4205963611602783 validation: auc: 0.5007819045968045 --- acc: 51.949999999999996 --- loss: 1.400189995765686\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13564318418502808\n",
            "epoch: 13 train loss: 1.3317326307296753 validation: auc: 0.5011575077287568 --- acc: 52.800000000000004 --- loss: 1.3718667030334473\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13256226778030394\n",
            "epoch: 14 train loss: 1.3003764152526855 validation: auc: 0.5015945075265089 --- acc: 53.300000000000004 --- loss: 1.3430237770080566\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12845315933227539\n",
            "epoch: 15 train loss: 1.3067407608032227 validation: auc: 0.5020838750686198 --- acc: 53.949999999999996 --- loss: 1.3138066530227661\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12555232048034667\n",
            "epoch: 16 train loss: 1.2618813514709473 validation: auc: 0.5025064285920661 --- acc: 54.85 --- loss: 1.2842967510223389\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12291737794876098\n",
            "epoch: 17 train loss: 1.2047444581985474 validation: auc: 0.503073444858571 --- acc: 55.35 --- loss: 1.2545944452285767\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11971707344055176\n",
            "epoch: 18 train loss: 1.1695553064346313 validation: auc: 0.5037108867123169 --- acc: 56.35 --- loss: 1.2248705625534058\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11586326360702515\n",
            "epoch: 19 train loss: 1.1601886749267578 validation: auc: 0.5043374938603334 --- acc: 57.550000000000004 --- loss: 1.1953296661376953\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11206409931182862\n",
            "epoch: 20 train loss: 1.1481971740722656 validation: auc: 0.505074253849932 --- acc: 58.35 --- loss: 1.1661176681518555\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10918667316436767\n",
            "epoch: 21 train loss: 1.1005769968032837 validation: auc: 0.5057207246251192 --- acc: 59.25 --- loss: 1.1373176574707031\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10792275667190551\n",
            "epoch: 22 train loss: 0.9932182431221008 validation: auc: 0.5064629019675826 --- acc: 60.199999999999996 --- loss: 1.1091512441635132\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10258679389953614\n",
            "epoch: 23 train loss: 1.0486973524093628 validation: auc: 0.5073188437202045 --- acc: 61.45 --- loss: 1.0818684101104736\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10053544044494629\n",
            "epoch: 24 train loss: 0.9791736006736755 validation: auc: 0.5082488226286441 --- acc: 62.74999999999999 --- loss: 1.0555528402328491\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09773380756378174\n",
            "epoch: 25 train loss: 0.9442746639251709 validation: auc: 0.5092727023200716 --- acc: 63.449999999999996 --- loss: 1.0303895473480225\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09539037942886353\n",
            "epoch: 26 train loss: 0.8972257971763611 validation: auc: 0.5103850654416227 --- acc: 64.45 --- loss: 1.006553292274475\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09237133860588073\n",
            "epoch: 27 train loss: 0.8818843364715576 validation: auc: 0.5114261000837884 --- acc: 65.4 --- loss: 0.9841330647468567\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08958109021186829\n",
            "epoch: 28 train loss: 0.8658302426338196 validation: auc: 0.5125050561960071 --- acc: 66.05 --- loss: 0.9631140232086182\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0869286060333252\n",
            "epoch: 29 train loss: 0.8500009775161743 validation: auc: 0.513671592846205 --- acc: 67.45 --- loss: 0.9435069561004639\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08526108264923096\n",
            "epoch: 30 train loss: 0.802981436252594 validation: auc: 0.5148814683193204 --- acc: 68.0 --- loss: 0.9252774715423584\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08388254046440125\n",
            "epoch: 31 train loss: 0.7512738704681396 validation: auc: 0.5161978850654416 --- acc: 69.25 --- loss: 0.9084413647651672\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07995039224624634\n",
            "epoch: 32 train loss: 0.8079996705055237 validation: auc: 0.5176082025945508 --- acc: 69.95 --- loss: 0.8929791450500488\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07895292639732361\n",
            "epoch: 33 train loss: 0.7549678087234497 validation: auc: 0.5191395076709716 --- acc: 70.75 --- loss: 0.8788130879402161\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0763134241104126\n",
            "epoch: 34 train loss: 0.773038387298584 validation: auc: 0.5204848169657046 --- acc: 71.39999999999999 --- loss: 0.8658531308174133\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07465260028839112\n",
            "epoch: 35 train loss: 0.7587139010429382 validation: auc: 0.5221316922365722 --- acc: 72.3 --- loss: 0.8540093302726746\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07255587577819825\n",
            "epoch: 36 train loss: 0.7672150135040283 validation: auc: 0.5237605096645576 --- acc: 72.6 --- loss: 0.8432082533836365\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07170841693878174\n",
            "epoch: 37 train loss: 0.7292007207870483 validation: auc: 0.5254868394441075 --- acc: 73.45 --- loss: 0.8333029747009277\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07182357907295227\n",
            "epoch: 38 train loss: 0.6577290892601013 validation: auc: 0.5271517725578574 --- acc: 74.05000000000001 --- loss: 0.8241056203842163\n",
            "<Timer(Thread-895, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07023770213127137\n",
            "epoch: 39 train loss: 0.6573987603187561 validation: auc: 0.5289088006703071 --- acc: 74.3 --- loss: 0.8155400156974792\n",
            "time up, break\n",
            "test auc: 0.5626180839033539 test acc: 73.6 test loss 0.8044653534889221\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10928367376327515\n",
            "epoch: 0 train loss: 1.0565603971481323 validation: auc: 0.5336336504253133 --- acc: 73.85000000000001 --- loss: 1.1034103631973267\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10736873149871826\n",
            "epoch: 1 train loss: 1.1045259237289429 validation: auc: 0.533928084657268 --- acc: 74.1 --- loss: 1.09870183467865\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10812673568725586\n",
            "epoch: 2 train loss: 1.0459250211715698 validation: auc: 0.534293287947942 --- acc: 74.15 --- loss: 1.093751311302185\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1069676160812378\n",
            "epoch: 3 train loss: 1.0620423555374146 validation: auc: 0.5345868484878138 --- acc: 74.2 --- loss: 1.0884642601013184\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1065904140472412\n",
            "epoch: 4 train loss: 1.044858455657959 validation: auc: 0.5349048724060081 --- acc: 74.3 --- loss: 1.082735300064087\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10598467588424683\n",
            "epoch: 5 train loss: 1.0341143608093262 validation: auc: 0.5353626870574749 --- acc: 74.45 --- loss: 1.0764909982681274\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10446597337722778\n",
            "epoch: 6 train loss: 1.056355595588684 validation: auc: 0.5358659336972552 --- acc: 74.5 --- loss: 1.0697027444839478\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10496345758438111\n",
            "epoch: 7 train loss: 0.9949273467063904 validation: auc: 0.536432086167008 --- acc: 74.6 --- loss: 1.0623235702514648\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10332025289535522\n",
            "epoch: 8 train loss: 1.015100359916687 validation: auc: 0.5369510592642813 --- acc: 74.7 --- loss: 1.0543348789215088\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10184087753295898\n",
            "epoch: 9 train loss: 1.0250353813171387 validation: auc: 0.5376587498514724 --- acc: 74.85000000000001 --- loss: 1.0457018613815308\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10155408382415772\n",
            "epoch: 10 train loss: 0.9833436012268066 validation: auc: 0.5383332401395111 --- acc: 74.8 --- loss: 1.036415696144104\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09904472231864929\n",
            "epoch: 11 train loss: 1.0262881517410278 validation: auc: 0.5389815196650614 --- acc: 74.9 --- loss: 1.026491641998291\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09812020063400269\n",
            "epoch: 12 train loss: 1.001490831375122 validation: auc: 0.5397660951555521 --- acc: 74.95 --- loss: 1.0159069299697876\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09543388485908508\n",
            "epoch: 13 train loss: 1.0432963371276855 validation: auc: 0.5407446302884582 --- acc: 75.1 --- loss: 1.0046602487564087\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09560633897781372\n",
            "epoch: 14 train loss: 0.9667953252792358 validation: auc: 0.541871693075466 --- acc: 75.35 --- loss: 0.992785632610321\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09405101537704467\n",
            "epoch: 15 train loss: 0.9545233845710754 validation: auc: 0.5428537229767039 --- acc: 75.5 --- loss: 0.9802923798561096\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0929530382156372\n",
            "epoch: 16 train loss: 0.920268177986145 validation: auc: 0.5441450398753067 --- acc: 75.8 --- loss: 0.9671987295150757\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09131646752357483\n",
            "epoch: 17 train loss: 0.9026369452476501 validation: auc: 0.5455062521405456 --- acc: 75.94999999999999 --- loss: 0.9535378813743591\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08959813117980957\n",
            "epoch: 18 train loss: 0.8847509026527405 validation: auc: 0.5468604748691209 --- acc: 76.05 --- loss: 0.9392884969711304\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08692924976348877\n",
            "epoch: 19 train loss: 0.9007225036621094 validation: auc: 0.5482950772693278 --- acc: 76.2 --- loss: 0.9244906902313232\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08612766861915588\n",
            "epoch: 20 train loss: 0.8386438488960266 validation: auc: 0.5499341236169455 --- acc: 76.4 --- loss: 0.9092071652412415\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08402383327484131\n",
            "epoch: 21 train loss: 0.8245118856430054 validation: auc: 0.5516343284103696 --- acc: 76.75 --- loss: 0.8935117125511169\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08238809704780578\n",
            "epoch: 22 train loss: 0.7880054712295532 validation: auc: 0.553296090752144 --- acc: 76.8 --- loss: 0.8774681687355042\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07962753176689148\n",
            "epoch: 23 train loss: 0.7933380603790283 validation: auc: 0.5552636453229516 --- acc: 76.85 --- loss: 0.8610844612121582\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07764526605606079\n",
            "epoch: 24 train loss: 0.7650176882743835 validation: auc: 0.5573185691020542 --- acc: 76.75 --- loss: 0.8444104194641113\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07523059248924255\n",
            "epoch: 25 train loss: 0.751756489276886 validation: auc: 0.559588421133563 --- acc: 76.64999999999999 --- loss: 0.8275976181030273\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07229129076004029\n",
            "epoch: 26 train loss: 0.7559325695037842 validation: auc: 0.562307350895709 --- acc: 76.95 --- loss: 0.8107773661613464\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0707029402256012\n",
            "epoch: 27 train loss: 0.7058282494544983 validation: auc: 0.5649074585345737 --- acc: 76.9 --- loss: 0.7940458655357361\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0682574987411499\n",
            "epoch: 28 train loss: 0.6891975402832031 validation: auc: 0.5677242418100105 --- acc: 76.44999999999999 --- loss: 0.7775758504867554\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06696180701255798\n",
            "epoch: 29 train loss: 0.6271296739578247 validation: auc: 0.5705882044579266 --- acc: 76.35 --- loss: 0.7615815997123718\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06406121850013732\n",
            "epoch: 30 train loss: 0.6283468008041382 validation: auc: 0.5733281028300634 --- acc: 76.1 --- loss: 0.7461867928504944\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06165292263031006\n",
            "epoch: 31 train loss: 0.6118311882019043 validation: auc: 0.5763685512787358 --- acc: 75.94999999999999 --- loss: 0.7313988208770752\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05961969494819641\n",
            "epoch: 32 train loss: 0.5827217102050781 validation: auc: 0.5796501387423028 --- acc: 75.85 --- loss: 0.7172428965568542\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.057914310693740846\n",
            "epoch: 33 train loss: 0.5433873534202576 validation: auc: 0.5827237874901273 --- acc: 76.3 --- loss: 0.7038559913635254\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05502023696899414\n",
            "epoch: 34 train loss: 0.551728367805481 validation: auc: 0.586120702308644 --- acc: 76.64999999999999 --- loss: 0.6912938356399536\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05215709209442139\n",
            "epoch: 35 train loss: 0.5634484887123108 validation: auc: 0.5895036380538334 --- acc: 76.75 --- loss: 0.6795235276222229\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.051264864206314084\n",
            "epoch: 36 train loss: 0.4993996322154999 validation: auc: 0.5930700491364427 --- acc: 77.05 --- loss: 0.6685296297073364\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04860405623912811\n",
            "epoch: 37 train loss: 0.5087645649909973 validation: auc: 0.596311446764194 --- acc: 76.7 --- loss: 0.6582619547843933\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04747343361377716\n",
            "epoch: 38 train loss: 0.46114757657051086 validation: auc: 0.599701372046047 --- acc: 76.9 --- loss: 0.6486881375312805\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.045718726515769956\n",
            "epoch: 39 train loss: 0.44138243794441223 validation: auc: 0.6029427696737983 --- acc: 77.25 --- loss: 0.6398077607154846\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04437502920627594\n",
            "epoch: 40 train loss: 0.40837788581848145 validation: auc: 0.6062051359115405 --- acc: 77.25 --- loss: 0.6315904259681702\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.042163169384002684\n",
            "epoch: 41 train loss: 0.41371390223503113 validation: auc: 0.6093941120143145 --- acc: 77.35 --- loss: 0.6239708065986633\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04079020023345947\n",
            "epoch: 42 train loss: 0.3887416124343872 validation: auc: 0.6125096979821208 --- acc: 77.3 --- loss: 0.6169183850288391\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.039029350876808165\n",
            "epoch: 43 train loss: 0.3822638988494873 validation: auc: 0.6156479999440837 --- acc: 77.4 --- loss: 0.6103338599205017\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.03748142123222351\n",
            "epoch: 44 train loss: 0.37008923292160034 validation: auc: 0.6186063213369586 --- acc: 77.5 --- loss: 0.6041371822357178\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.036321434378623965\n",
            "epoch: 45 train loss: 0.3452397584915161 validation: auc: 0.6214335889173906 --- acc: 77.75 --- loss: 0.5983681082725525\n",
            "<Timer(Thread-977, started 139802628323072)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.034673625230789186\n",
            "epoch: 46 train loss: 0.3417590260505676 validation: auc: 0.6241000971545596 --- acc: 77.75 --- loss: 0.593090832233429\n",
            "time up, break\n",
            "test auc: 0.6305610058167042 test acc: 77.75 test loss 0.5868318676948547\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.17965167760849\n",
            "epoch: 0 train loss: 1.7594729661941528 validation: auc: 0.5029982454711688 --- acc: 42.4 --- loss: 1.8440029621124268\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.17511869668960572\n",
            "epoch: 1 train loss: 1.7630327939987183 validation: auc: 0.5030537685354496 --- acc: 42.8 --- loss: 1.8092552423477173\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.17063734531402588\n",
            "epoch: 2 train loss: 1.7588216066360474 validation: auc: 0.5031389039006804 --- acc: 43.4 --- loss: 1.7723489999771118\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.16717513799667358\n",
            "epoch: 3 train loss: 1.7026114463806152 validation: auc: 0.5032221884971018 --- acc: 43.6 --- loss: 1.7324622869491577\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1621803641319275\n",
            "epoch: 4 train loss: 1.690685749053955 validation: auc: 0.5032906669430481 --- acc: 44.55 --- loss: 1.68914794921875\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.15819697380065917\n",
            "epoch: 5 train loss: 1.6198797225952148 validation: auc: 0.5035016545873156 --- acc: 44.95 --- loss: 1.642225980758667\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1537173867225647\n",
            "epoch: 6 train loss: 1.5510046482086182 validation: auc: 0.5036127007158774 --- acc: 46.050000000000004 --- loss: 1.5916815996170044\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1490810751914978\n",
            "epoch: 7 train loss: 1.4678558111190796 validation: auc: 0.5038384945106197 --- acc: 47.349999999999994 --- loss: 1.5377542972564697\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1433061957359314\n",
            "epoch: 8 train loss: 1.4134325981140137 validation: auc: 0.5040309744667935 --- acc: 48.449999999999996 --- loss: 1.48075532913208\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13746132850646972\n",
            "epoch: 9 train loss: 1.3453487157821655 validation: auc: 0.5044039043818802 --- acc: 50.55 --- loss: 1.421241044998169\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.13015888929367064\n",
            "epoch: 10 train loss: 1.3229097127914429 validation: auc: 0.5047786850657763 --- acc: 52.0 --- loss: 1.3599101305007935\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.12489912509918213\n",
            "epoch: 11 train loss: 1.2077957391738892 validation: auc: 0.5050840619193213 --- acc: 54.300000000000004 --- loss: 1.2975645065307617\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11908612251281739\n",
            "epoch: 12 train loss: 1.1113307476043701 validation: auc: 0.5053690803159632 --- acc: 56.05 --- loss: 1.2350995540618896\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.1118855595588684\n",
            "epoch: 13 train loss: 1.0718685388565063 validation: auc: 0.5058317725183041 --- acc: 57.45 --- loss: 1.173714518547058\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.10595908164978027\n",
            "epoch: 14 train loss: 0.9883188009262085 validation: auc: 0.5064915715988422 --- acc: 59.099999999999994 --- loss: 1.1146951913833618\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09923684000968933\n",
            "epoch: 15 train loss: 0.9492653608322144 validation: auc: 0.5071310122224773 --- acc: 60.699999999999996 --- loss: 1.0592929124832153\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.09318284392356872\n",
            "epoch: 16 train loss: 0.9016064405441284 validation: auc: 0.5079074097380052 --- acc: 62.64999999999999 --- loss: 1.0085279941558838\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08843435645103455\n",
            "epoch: 17 train loss: 0.8273383378982544 validation: auc: 0.5087633903123358 --- acc: 64.64999999999999 --- loss: 0.9632033109664917\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.08329983353614807\n",
            "epoch: 18 train loss: 0.7961990833282471 validation: auc: 0.5100404207907965 --- acc: 66.4 --- loss: 0.9238496422767639\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07824827432632446\n",
            "epoch: 19 train loss: 0.7899976372718811 validation: auc: 0.5115210358382871 --- acc: 68.65 --- loss: 0.890501081943512\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07502630352973938\n",
            "epoch: 20 train loss: 0.7409412264823914 validation: auc: 0.5133347892714634 --- acc: 70.55 --- loss: 0.8627930879592896\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.07209920287132263\n",
            "epoch: 21 train loss: 0.7080478072166443 validation: auc: 0.515318813435101 --- acc: 72.05 --- loss: 0.8400982022285461\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0698824405670166\n",
            "epoch: 22 train loss: 0.6679207682609558 validation: auc: 0.5176119159899022 --- acc: 73.6 --- loss: 0.8215230107307434\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.0670267641544342\n",
            "epoch: 23 train loss: 0.6742581725120544 validation: auc: 0.5200567815870714 --- acc: 74.9 --- loss: 0.8060322999954224\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06598623394966126\n",
            "epoch: 24 train loss: 0.6164498329162598 validation: auc: 0.5228421886451633 --- acc: 75.25 --- loss: 0.7926398515701294\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06321372985839843\n",
            "epoch: 25 train loss: 0.6371053457260132 validation: auc: 0.5257071787620577 --- acc: 75.7 --- loss: 0.7804897427558899\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.06192843914031983\n",
            "epoch: 26 train loss: 0.6002129912376404 validation: auc: 0.5289534272536812 --- acc: 76.1 --- loss: 0.7690129280090332\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.059671598672866824\n",
            "epoch: 27 train loss: 0.5998031497001648 validation: auc: 0.5325420679750368 --- acc: 76.4 --- loss: 0.7578131556510925\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.057885104417800905\n",
            "epoch: 28 train loss: 0.5798043608665466 validation: auc: 0.5359530348906936 --- acc: 76.85 --- loss: 0.7467679977416992\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05614174008369446\n",
            "epoch: 29 train loss: 0.5546411871910095 validation: auc: 0.5397489617186979 --- acc: 77.3 --- loss: 0.735920250415802\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05483608841896057\n",
            "epoch: 30 train loss: 0.5100705623626709 validation: auc: 0.5431451224838798 --- acc: 77.25 --- loss: 0.7253801226615906\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05232260227203369\n",
            "epoch: 31 train loss: 0.5127487778663635 validation: auc: 0.5467707785814226 --- acc: 77.05 --- loss: 0.7152813673019409\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.05103248357772827\n",
            "epoch: 32 train loss: 0.4680226147174835 validation: auc: 0.5502594777870727 --- acc: 76.75 --- loss: 0.7057675123214722\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.048805725574493405\n",
            "epoch: 33 train loss: 0.46141448616981506 validation: auc: 0.5535038755098868 --- acc: 76.7 --- loss: 0.6969794034957886\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.047244518995285034\n",
            "epoch: 34 train loss: 0.4308430850505829 validation: auc: 0.5567205117005604 --- acc: 76.7 --- loss: 0.6888665556907654\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04443233609199524\n",
            "epoch: 35 train loss: 0.45216643810272217 validation: auc: 0.5597076525588729 --- acc: 76.55 --- loss: 0.6813727021217346\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.04333234429359436\n",
            "epoch: 36 train loss: 0.40863001346588135 validation: auc: 0.5627133011052792 --- acc: 76.6 --- loss: 0.6744391918182373\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.041577816009521484\n",
            "epoch: 37 train loss: 0.39400145411491394 validation: auc: 0.5658725634628625 --- acc: 76.55 --- loss: 0.6679553389549255\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.03908810913562775\n",
            "epoch: 38 train loss: 0.41068658232688904 validation: auc: 0.5688948689285529 --- acc: 76.35 --- loss: 0.6618136167526245\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.03820480108261108\n",
            "epoch: 39 train loss: 0.3665381968021393 validation: auc: 0.5717432021261633 --- acc: 76.55 --- loss: 0.6559361815452576\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.03643516600131989\n",
            "epoch: 40 train loss: 0.3593018651008606 validation: auc: 0.5742343369435664 --- acc: 76.55 --- loss: 0.6502431035041809\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.035135510563850406\n",
            "epoch: 41 train loss: 0.33544236421585083 validation: auc: 0.5768883394161934 --- acc: 76.55 --- loss: 0.6446624994277954\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.03339184820652008\n",
            "epoch: 42 train loss: 0.33131805062294006 validation: auc: 0.5794312957602588 --- acc: 76.5 --- loss: 0.6392160654067993\n",
            "<Timer(Thread-1073, started 139803928553216)>\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.031698590517044066\n",
            "epoch: 43 train loss: 0.32674771547317505 validation: auc: 0.5818909675079027 --- acc: 76.64999999999999 --- loss: 0.633952260017395\n",
            "time up, break\n",
            "test auc: 0.6009018939040819 test acc: 75.44999999999999 test loss 0.6359676718711853\n",
            "Tesla P100-PCIE-16GB\n",
            "Reading large data\n",
            "Cut by chunk\n",
            "chunk:  0\n",
            "chunk:  1\n",
            "Iteration is stopped.\n",
            "Start concatenation\n",
            "Data imported\n",
            "one hot encoding: feature hour\n",
            "one hot encoding: feature C1\n",
            "one hot encoding: feature banner_pos\n",
            "one hot encoding: feature site_id\n",
            "one hot encoding: feature site_domain\n",
            "one hot encoding: feature site_category\n",
            "one hot encoding: feature app_id\n",
            "one hot encoding: feature app_domain\n",
            "one hot encoding: feature app_category\n",
            "one hot encoding: feature device_id\n",
            "one hot encoding: feature device_ip\n",
            "one hot encoding: feature device_model\n",
            "one hot encoding: feature device_type\n",
            "one hot encoding: feature device_conn_type\n",
            "one hot encoding: feature C14\n",
            "one hot encoding: feature C15\n",
            "one hot encoding: feature C16\n",
            "one hot encoding: feature C17\n",
            "one hot encoding: feature C18\n",
            "one hot encoding: feature C19\n",
            "one hot encoding: feature C20\n",
            "one hot encoding: feature C21\n",
            "Data set initiated from /content/drive/My Drive/train20k.csv.\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    0.7 GB\n",
            "    - loss: 0.11527248620986938\n",
            "epoch: 0 train loss: 1.1159204244613647 validation: auc: 0.4311562000510464 --- acc: 69.6 --- loss: 1.1679397821426392\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.2 GB\n",
            "    - loss: 0.11441776752471924\n",
            "epoch: 1 train loss: 1.0760068893432617 validation: auc: 0.43286860630766477 --- acc: 69.89999999999999 --- loss: 1.1558114290237427\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.11185332536697387\n",
            "epoch: 2 train loss: 1.1025997400283813 validation: auc: 0.4347783194162613 --- acc: 70.19999999999999 --- loss: 1.1425819396972656\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.10929645299911499\n",
            "epoch: 3 train loss: 1.1196218729019165 validation: auc: 0.43700480958078625 --- acc: 70.89999999999999 --- loss: 1.127819538116455\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.10732262134552002\n",
            "epoch: 4 train loss: 1.1040080785751343 validation: auc: 0.4397091805611117 --- acc: 71.2 --- loss: 1.111311674118042\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.1053278923034668\n",
            "epoch: 5 train loss: 1.0766093730926514 validation: auc: 0.4430724478177681 --- acc: 71.7 --- loss: 1.092997431755066\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.10377470254898072\n",
            "epoch: 6 train loss: 1.0182608366012573 validation: auc: 0.44713262459746694 --- acc: 72.3 --- loss: 1.0728617906570435\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.10015826225280762\n",
            "epoch: 7 train loss: 1.030440330505371 validation: auc: 0.45191505306468227 --- acc: 72.8 --- loss: 1.050942301750183\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.097561514377594\n",
            "epoch: 8 train loss: 0.9897764325141907 validation: auc: 0.45730388332467475 --- acc: 73.0 --- loss: 1.0273833274841309\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.09473102688789367\n",
            "epoch: 9 train loss: 0.9483791589736938 validation: auc: 0.4632629122853383 --- acc: 73.65 --- loss: 1.002481460571289\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.09081192016601562\n",
            "epoch: 10 train loss: 0.9389939904212952 validation: auc: 0.47034785741050145 --- acc: 73.95 --- loss: 0.9764673709869385\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.08740301728248596\n",
            "epoch: 11 train loss: 0.899979829788208 validation: auc: 0.47820935886134036 --- acc: 74.15 --- loss: 0.9495262503623962\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.08503952622413635\n",
            "epoch: 12 train loss: 0.8142686486244202 validation: auc: 0.4865958051477176 --- acc: 74.8 --- loss: 0.9219804406166077\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.08047974109649658\n",
            "epoch: 13 train loss: 0.8108000159263611 validation: auc: 0.496122648835437 --- acc: 74.8 --- loss: 0.8942266702651978\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.07839655876159668\n",
            "epoch: 14 train loss: 0.7054383754730225 validation: auc: 0.5057635322632906 --- acc: 74.95 --- loss: 0.8666837811470032\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.07326218485832214\n",
            "epoch: 15 train loss: 0.7214009165763855 validation: auc: 0.5161013252141865 --- acc: 75.35 --- loss: 0.8395735621452332\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.07074006795883178\n",
            "epoch: 16 train loss: 0.6337825655937195 validation: auc: 0.5269894051650952 --- acc: 75.44999999999999 --- loss: 0.8130080103874207\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.06637384295463562\n",
            "epoch: 17 train loss: 0.6218937039375305 validation: auc: 0.5380512599581131 --- acc: 75.7 --- loss: 0.7870845198631287\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.06197547912597656\n",
            "epoch: 18 train loss: 0.6150106191635132 validation: auc: 0.5489918343925755 --- acc: 76.05 --- loss: 0.7617761492729187\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.05887263417243958\n",
            "epoch: 19 train loss: 0.5611258149147034 validation: auc: 0.5601098039783579 --- acc: 76.14999999999999 --- loss: 0.7371439337730408\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.05537535548210144\n",
            "epoch: 20 train loss: 0.5273034572601318 validation: auc: 0.5705037117220182 --- acc: 76.6 --- loss: 0.7132260799407959\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.05151339173316956\n",
            "epoch: 21 train loss: 0.5107397437095642 validation: auc: 0.5812216371400281 --- acc: 77.2 --- loss: 0.6900429725646973\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.04945401847362518\n",
            "epoch: 22 train loss: 0.4305775761604309 validation: auc: 0.5907919245382748 --- acc: 77.5 --- loss: 0.6680693626403809\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.045207473635673526\n",
            "epoch: 23 train loss: 0.44281071424484253 validation: auc: 0.5999603576141439 --- acc: 77.95 --- loss: 0.6477140784263611\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.042194205522537234\n",
            "epoch: 24 train loss: 0.41422757506370544 validation: auc: 0.6088427862623746 --- acc: 78.35 --- loss: 0.629227876663208\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.03940775990486145\n",
            "epoch: 25 train loss: 0.3847166895866394 validation: auc: 0.6169776210586146 --- acc: 78.5 --- loss: 0.612794041633606\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.03699553608894348\n",
            "epoch: 26 train loss: 0.34805965423583984 validation: auc: 0.6241548840686482 --- acc: 78.9 --- loss: 0.5985430479049683\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.03415125608444214\n",
            "epoch: 27 train loss: 0.3368772566318512 validation: auc: 0.6306261867826132 --- acc: 79.05 --- loss: 0.5863425731658936\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.03178431689739227\n",
            "epoch: 28 train loss: 0.31564608216285706 validation: auc: 0.6356149728748333 --- acc: 78.75 --- loss: 0.5760534405708313\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.029379242658615114\n",
            "epoch: 29 train loss: 0.30250367522239685 validation: auc: 0.6398724565065103 --- acc: 79.0 --- loss: 0.5673314929008484\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.027353784441947936\n",
            "epoch: 30 train loss: 0.2826664447784424 validation: auc: 0.6429786818092134 --- acc: 78.95 --- loss: 0.5600788593292236\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.025826981663703917\n",
            "epoch: 31 train loss: 0.24928459525108337 validation: auc: 0.6455979755230894 --- acc: 79.10000000000001 --- loss: 0.553931474685669\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.02389051467180252\n",
            "epoch: 32 train loss: 0.23720300197601318 validation: auc: 0.6472524568323381 --- acc: 79.25 --- loss: 0.5485325455665588\n",
            "<Timer(Thread-1163, started 139803986155264)>\n",
            "Memory Usage:\n",
            "Allocated: 0.2 GB\n",
            "Cached:    1.4 GB\n",
            "    - loss: 0.022188535332679747\n",
            "epoch: 33 train loss: 0.22071261703968048 validation: auc: 0.6485992118586849 --- acc: 79.0 --- loss: 0.5438533425331116\n",
            "time up, break\n",
            "test auc: 0.591663527087539 test acc: 76.5 test loss 0.5851853489875793\n",
            "0.001\n",
            "0.6598603819348501\n",
            "78.75\n",
            "0.5426446199417114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FieldAwareFactorizationMachineModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FeaturesLinear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FieldAwareFactorizationMachine. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YV9Nw507VsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "6b0a9450-0b0a-4bd4-9c5a-c457308009a5"
      },
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def plot_learning_rate():\n",
        "    with open(\"/content/learning_rate.json\",\"r\") as dump_f:\n",
        "        load_dict = json.load(dump_f)\n",
        "\n",
        "    for i,(k,v) in enumerate(load_dict.items()):\n",
        "        print((k,v))\n",
        "    keys = list(load_dict.keys())\n",
        "\n",
        "    markers = ',v^8sph'\n",
        "    i = 0\n",
        "    for key in keys:\n",
        "        plt.plot(load_dict[key]['EPOCH'],load_dict[key]['val_loss_list'],marker=markers[i])\n",
        "        i += 1\n",
        "\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Logloss')\n",
        "\n",
        "    my_x_ticks = np.arange(0, len(load_dict[key]['EPOCH']), 1)\n",
        "    plt.xticks(my_x_ticks)\n",
        "\n",
        "    plt.legend(keys, loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_one_learning_rate():\n",
        "    with open(\"/content/learning_rate.json\",\"r\") as dump_f:\n",
        "        load_dict = json.load(dump_f)\n",
        "\n",
        "    for i,(k,v) in enumerate(load_dict.items()):\n",
        "        print((k,v))\n",
        "    keys = list(load_dict.keys())\n",
        "\n",
        "    key = keys[0]\n",
        "    epoch = load_dict[key]['EPOCH']\n",
        "    train_loss = load_dict[key]['train_loss_list']\n",
        "    val_loss = load_dict[key]['val_loss_list']\n",
        "    val_auc = [i for i in load_dict[key]['val_auc_list']]\n",
        "    val_acc = [i/100 for i in load_dict[key]['val_acc_list']]\n",
        "\n",
        "\n",
        "    plt.plot(epoch,train_loss)\n",
        "    plt.plot(epoch, val_loss)\n",
        "    plt.plot(epoch, val_auc)\n",
        "    plt.plot(epoch, val_acc)\n",
        "\n",
        "    plt.legend(['train_loss', 'val_loss','val_auc','val_acc'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_rate()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('0.01', {'EPOCH': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], 'train_loss_list': [1.782700777053833, 1.2398271560668945, 0.7946409583091736, 0.7347180247306824, 0.688002347946167, 0.5351648926734924, 0.3571745753288269, 0.2476952224969864, 0.17860347032546997, 0.1324910968542099, 0.08477510511875153, 0.0689530298113823, 0.04439324513077736, 0.04569431394338608, 0.042080383747816086, 0.04017915576696396, 0.03678508847951889, 0.022154971957206726, 0.023174993693828583, 0.024033233523368835, 0.018267350271344185, 0.019317472353577614, 0.01682749204337597, 0.014917070977389812, 0.011632357724010944, 0.014983396977186203, 0.01484565157443285, 0.010213133879005909], 'val_auc_list': [0.5444786557349659, 0.5493094377130037, 0.5612384941803867, 0.5873265922315365, 0.6141818869970386, 0.6347376442969154, 0.6476606467297814, 0.6558065709546144, 0.6597533718295595, 0.6587867039694758, 0.6526013935702095, 0.6445995318395161, 0.6377510225027321, 0.6338204180028677, 0.6330123041304166, 0.6346217123489688, 0.6381985539194375, 0.6421606987286699, 0.6463359537363331, 0.649457591922953, 0.6519705873828534, 0.653411212324248, 0.6539294963268326, 0.6540846405512906, 0.6537385495890384, 0.6531367263886687, 0.6528835514729324, 0.6526985718206941], 'val_acc_list': [45.9, 60.5, 75.7, 80.55, 81.2, 80.30000000000001, 78.05, 74.3, 69.5, 68.8, 70.19999999999999, 71.45, 74.05000000000001, 75.5, 76.75, 77.9, 77.95, 77.9, 78.0, 78.14999999999999, 78.2, 78.3, 78.3, 78.3, 78.60000000000001, 78.7, 78.8, 78.85], 'val_loss_list': [1.553656816482544, 1.0503523349761963, 0.7993385791778564, 0.8761565685272217, 0.8722352981567383, 0.7628569602966309, 0.6720430850982666, 0.6694808602333069, 0.7032121419906616, 0.7018393278121948, 0.6752361059188843, 0.6510618925094604, 0.6392855644226074, 0.6365150213241577, 0.6369374990463257, 0.637225329875946, 0.6361315846443176, 0.6342325210571289, 0.6324914693832397, 0.6318031549453735, 0.6320507526397705, 0.6327243447303772, 0.6334663033485413, 0.6342449188232422, 0.6352105736732483, 0.6364847421646118, 0.6379624009132385, 0.639369785785675], 'test_auc': 0.6634419315755002, 'test_acc': 80.0, 'test_loss': 0.5667077302932739, 'best_val_auc': 0.649457591922953, 'best_val_acc': 78.14999999999999, 'best_val_loss': 0.6318031549453735})\n",
            "('0.02', {'EPOCH': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], 'train_loss_list': [1.1717290878295898, 0.7693663239479065, 0.6033385992050171, 0.31964850425720215, 0.24133792519569397, 0.0992686003446579, 0.055037856101989746, 0.04607614502310753, 0.03543291240930557, 0.03343134745955467, 0.0278167724609375, 0.018320567905902863, 0.019193343818187714, 0.01689729653298855, 0.010744781233370304, 0.013125195167958736, 0.010866894386708736, 0.008604947477579117, 0.007761501241475344, 0.010844635777175426, 0.005626058205962181, 0.0065918187610805035, 0.006870920769870281, 0.004569181706756353, 0.008233127184212208, 0.005035109352320433, 0.004256806802004576, 0.005132990889251232, 0.004336259793490171, 0.0035431431606411934, 0.004267165437340736, 0.0028814610559493303, 0.0050261737778782845, 0.0035914843901991844, 0.0047374265268445015, 0.0021107117645442486, 0.003126916941255331, 0.00363869103603065, 0.002943743485957384, 0.004340152721852064, 0.002620731946080923, 0.00240553030744195, 0.0028627344872802496, 0.0034852446988224983], 'val_auc_list': [0.49857839231486223, 0.5568821597161671, 0.6300991836796055, 0.6663374951141044, 0.662632670856009, 0.6394350025556992, 0.6187949126552211, 0.610933318800926, 0.6139249902282089, 0.6210696728705012, 0.6289979779909197, 0.6349625289395351, 0.6390027887188431, 0.641160099521934, 0.6426164722330797, 0.643604926486064, 0.6446685483628491, 0.6457171367148741, 0.6469865299618149, 0.6485847815628852, 0.6500674629423615, 0.6518263853393066, 0.6536792672660032, 0.6557501353017229, 0.6582438212213235, 0.6609122718662618, 0.6629042138969903, 0.6645315929522837, 0.6655632685889534, 0.6666813869929944, 0.6680362834120088, 0.6699154740070358, 0.6718717114164587, 0.6738918413061127, 0.6758518370967257, 0.6776257930184311, 0.679503104422863, 0.6812789395351634, 0.6826582654319132, 0.6838684641751105, 0.6849940993415315, 0.6862531570401995, 0.6870198668029706, 0.687683221083015], 'val_acc_list': [67.10000000000001, 81.75, 81.65, 73.35000000000001, 68.15, 74.9, 79.14999999999999, 81.05, 81.15, 80.95, 80.4, 80.35, 81.05, 81.39999999999999, 81.65, 81.85, 81.95, 81.89999999999999, 81.95, 82.0, 81.89999999999999, 82.0, 82.15, 82.3, 82.45, 82.45, 82.65, 82.65, 82.69999999999999, 82.85, 82.8, 82.8, 82.85, 83.0, 83.05, 83.05, 83.05, 82.95, 83.1, 83.1, 83.1, 83.05, 83.05, 83.2], 'val_loss_list': [0.9015448689460754, 0.7730445265769958, 0.619220495223999, 0.6204932928085327, 0.6848241686820984, 0.588443398475647, 0.6049114465713501, 0.6456984877586365, 0.6687418222427368, 0.6759853959083557, 0.6772676110267639, 0.6802018284797668, 0.6864980459213257, 0.6942592859268188, 0.7036115527153015, 0.7137330770492554, 0.7220214009284973, 0.726432740688324, 0.7280662655830383, 0.7276124954223633, 0.7261372208595276, 0.7253462076187134, 0.7259452939033508, 0.7278664708137512, 0.7300279140472412, 0.7324895262718201, 0.7349075675010681, 0.7365896701812744, 0.7375426888465881, 0.7378485202789307, 0.737945020198822, 0.7378830909729004, 0.7372223138809204, 0.7365508079528809, 0.7358149886131287, 0.7349740266799927, 0.7338050603866577, 0.7322516441345215, 0.7313937544822693, 0.7314684987068176, 0.7323703765869141, 0.7328137755393982, 0.7322847247123718, 0.7309486269950867], 'test_auc': 0.6688183696900115, 'test_acc': 82.45, 'test_loss': 0.7696765065193176, 'best_val_auc': 0.6394350025556992, 'best_val_acc': 74.9, 'best_val_loss': 0.588443398475647})\n",
            "('0.05', {'EPOCH': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37], 'train_loss_list': [0.9915401935577393, 0.5626401305198669, 0.15820816159248352, 0.16255700588226318, 0.06935492157936096, 0.04528403282165527, 0.05138495936989784, 0.042766667902469635, 0.020811231806874275, 0.019352516159415245, 0.019162341952323914, 0.012774383649230003, 0.005895822774618864, 0.013572542928159237, 0.009912044741213322, 0.016047224402427673, 0.011836848221719265, 0.005778156686574221, 0.002999132964760065, 0.005499597173184156, 0.007624202873557806, 0.005482382141053677, 0.00522718857973814, 0.0070600565522909164, 0.009744329378008842, 0.0026706524658948183, 0.005105303134769201, 0.005405084695667028, 0.008700275793671608, 0.0036424642894417048, 0.0019617206417024136, 0.007402356714010239, 0.004393511917442083, 0.0030203047208487988, 0.002847778843715787, 0.006205444224178791, 0.0030159172601997852, 0.004258968401700258], 'val_auc_list': [0.5881482489566322, 0.645364725095264, 0.59317637452368, 0.537456904373072, 0.53983215387407, 0.5520277626565051, 0.5602349845763018, 0.5639693340591544, 0.5661903465795681, 0.5680820177826167, 0.5702367991290147, 0.5718626383596443, 0.5751034295046271, 0.580048085646888, 0.5855153329704228, 0.590652331700236, 0.5951760116131374, 0.5986626746506987, 0.6015541643984758, 0.6041389947377973, 0.6065750317546724, 0.6094783160950825, 0.6134267827980403, 0.6169179822173835, 0.6199972781709309, 0.6232144801306477, 0.6264189802213755, 0.6287597532208311, 0.629287788060243, 0.6288250771184902, 0.6284204318635457, 0.630405552531301, 0.6348548357829795, 0.6398140083469426, 0.6429549990927237, 0.6443013972055889, 0.644054618036654, 0.6427862456904373], 'val_acc_list': [82.8, 64.7, 81.3, 77.5, 75.0, 73.45, 75.1, 76.2, 77.55, 77.60000000000001, 77.10000000000001, 76.7, 76.8, 77.0, 77.2, 78.05, 78.9, 79.14999999999999, 79.4, 79.60000000000001, 79.65, 80.0, 80.30000000000001, 80.35, 80.45, 80.55, 80.7, 80.9, 81.15, 81.10000000000001, 81.15, 81.15, 81.15, 81.45, 81.55, 81.45, 81.45, 81.5], 'val_loss_list': [0.9730334877967834, 1.049331545829773, 0.717755138874054, 0.8758962750434875, 0.9174370169639587, 0.9802625179290771, 1.0319095849990845, 1.0725685358047485, 1.113922357559204, 1.1332162618637085, 1.1799241304397583, 1.1944994926452637, 1.2118124961853027, 1.2254459857940674, 1.2330117225646973, 1.2363821268081665, 1.2245948314666748, 1.2189900875091553, 1.2045565843582153, 1.1975364685058594, 1.191580891609192, 1.1837717294692993, 1.1726702451705933, 1.1550817489624023, 1.1353724002838135, 1.1143622398376465, 1.0956087112426758, 1.0862464904785156, 1.080984354019165, 1.0734097957611084, 1.0707529783248901, 1.0624027252197266, 1.0494226217269897, 1.0279186964035034, 1.0158195495605469, 1.0086660385131836, 1.0041539669036865, 1.0006550550460815], 'test_auc': 0.6565323734284133, 'test_acc': 82.1, 'test_loss': 0.9299958944320679, 'best_val_auc': 0.59317637452368, 'best_val_acc': 81.3, 'best_val_loss': 0.717755138874054})\n",
            "('0.1', {'EPOCH': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37], 'train_loss_list': [0.8225882649421692, 1.95158052444458, 0.968442440032959, 0.40812405943870544, 0.16834869980812073, 0.27615872025489807, 0.18043577671051025, 0.145013689994812, 0.08342701196670532, 0.1136775091290474, 0.05115486681461334, 0.04408286511898041, 0.11861995607614517, 0.06323689222335815, 0.022723782807588577, 0.07874172180891037, 0.03757276386022568, 0.07333732396364212, 0.03226019814610481, 0.06262124329805374, 0.11730998754501343, 0.0732806921005249, 0.049264803528785706, 0.027303041890263557, 0.1300906240940094, 0.07110851258039474, 0.11460034549236298, 0.06378123164176941, 0.03862696513533592, 0.13520346581935883, 0.03695765510201454, 0.039912883192300797, 0.054951876401901245, 0.03461664170026779, 0.04234931617975235, 0.07301706820726395, 0.056371621787548065, 0.10672131180763245], 'val_auc_list': [0.654830667456556, 0.6669571788795723, 0.6396775124559484, 0.6682768258597642, 0.5616427041560336, 0.5467487316198809, 0.555663469133552, 0.5764521813100012, 0.5904926555474541, 0.5950611025033419, 0.5954541484384493, 0.5942958971320937, 0.5930161243772026, 0.5942550735204764, 0.5964329657309515, 0.6011770491554258, 0.607651863835217, 0.612297211082756, 0.6154472748815165, 0.6174941517802892, 0.6181805580872524, 0.618166317292502, 0.6173678834001701, 0.616864708652327, 0.6179023878964638, 0.6191527296755377, 0.6202796512334428, 0.6212461265038279, 0.6223910864017499, 0.6235037671649046, 0.6245651810669584, 0.6251063312674687, 0.625012342022117, 0.6247094877870945, 0.6249392392757321, 0.625036076680034, 0.6259569814072183, 0.6280741128934256], 'val_acc_list': [54.1, 84.5, 73.75, 75.05, 71.15, 77.55, 81.39999999999999, 82.19999999999999, 81.95, 82.0, 82.69999999999999, 82.8, 82.95, 82.85, 82.89999999999999, 83.0, 83.25, 83.2, 82.89999999999999, 83.2, 83.3, 83.35000000000001, 83.15, 83.0, 82.8, 82.8, 82.69999999999999, 82.75, 82.8, 82.8, 82.69999999999999, 82.5, 82.5, 82.5, 82.39999999999999, 82.3, 82.3, 82.35], 'val_loss_list': [4.316534042358398, 2.5572104454040527, 1.6934340000152588, 1.2208783626556396, 2.034986972808838, 2.2466094493865967, 2.401121139526367, 2.491041421890259, 2.600153923034668, 2.7984538078308105, 3.030303716659546, 3.2562999725341797, 3.3913941383361816, 3.4500904083251953, 3.478484869003296, 3.4552862644195557, 3.453481912612915, 3.454916477203369, 3.471222400665283, 3.4600274562835693, 3.447730302810669, 3.415632724761963, 3.3754403591156006, 3.3435447216033936, 3.3099093437194824, 3.259145975112915, 3.203707695007324, 3.1503822803497314, 3.095324993133545, 3.0434014797210693, 2.9806697368621826, 2.9354000091552734, 2.8800220489501953, 2.8155784606933594, 2.7446343898773193, 2.675938129425049, 2.626779317855835, 2.5904953479766846], 'test_auc': 0.6066909614960282, 'test_acc': 80.9, 'test_loss': 3.0214807987213135, 'best_val_auc': 0.6682768258597642, 'best_val_acc': 75.05, 'best_val_loss': 1.2208783626556396})\n",
            "('0.2', {'EPOCH': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], 'train_loss_list': [0.870379626750946, 13.2079496383667, 8.354276657104492, 5.751840114593506, 4.421696186065674, 4.311750411987305, 4.011533737182617, 4.044730186462402, 4.078146457672119, 4.187800407409668, 3.82865047454834, 3.4202680587768555, 3.62570858001709, 3.687993049621582, 3.6777617931365967, 3.462636947631836, 3.252500295639038, 3.4945504665374756, 3.279083490371704, 3.480355739593506, 2.9507639408111572, 3.199646234512329, 3.1836066246032715, 3.2106311321258545, 3.1672213077545166, 3.002063512802124, 3.1394872665405273, 3.1085400581359863, 2.870527982711792, 3.524653434753418, 3.0301756858825684, 3.0252935886383057, 3.2954769134521484, 3.0968902111053467, 3.4567275047302246, 3.0913281440734863, 3.1060402393341064, 3.119830369949341, 3.299064874649048, 3.2435054779052734, 3.254351854324341, 3.014636278152466, 3.057360887527466], 'val_auc_list': [0.5271477017256045, 0.6527553089682829, 0.6281766466156277, 0.5869552421314861, 0.5715979690727913, 0.5830456692793778, 0.5863628250698749, 0.5894730146433346, 0.5858786380483655, 0.5934594877870945, 0.5989032689269655, 0.5950050887106574, 0.5855738850407097, 0.5799563662048852, 0.5753964637258476, 0.5786034907036093, 0.5749141754769717, 0.5736571879936808, 0.5594581662413416, 0.5575707862437721, 0.5587119485964273, 0.5637398985295905, 0.5618525185320209, 0.5622303742860615, 0.5602651446105238, 0.5622816411471625, 0.557396099161502, 0.5632072928059303, 0.5678849191882368, 0.567721624741767, 0.5608224343784177, 0.5597581723174141, 0.5571502081054807, 0.5630164661562767, 0.5678279560092356, 0.571038780532264, 0.5716283494349252, 0.5721087389111678, 0.5720565226637501, 0.5714584092842386, 0.5634854629967189, 0.5553767544659132, 0.554636233138899], 'val_acc_list': [18.0, 66.10000000000001, 74.8, 84.3, 84.25, 83.85000000000001, 83.89999999999999, 83.75, 83.25, 83.5, 83.1, 83.35000000000001, 83.7, 83.7, 83.55, 83.75, 83.7, 83.55, 83.95, 83.85000000000001, 83.89999999999999, 83.95, 83.85000000000001, 83.75, 83.89999999999999, 83.95, 84.25, 84.3, 84.25, 83.95, 83.89999999999999, 83.89999999999999, 83.8, 83.8, 83.8, 83.85000000000001, 83.65, 83.75, 83.7, 83.5, 83.85000000000001, 83.95, 84.1], 'val_loss_list': [21.233848571777344, 9.674544334411621, 7.507934093475342, 5.296963214874268, 4.528799533843994, 4.551650047302246, 4.776085376739502, 4.827871322631836, 4.756255626678467, 4.77958869934082, 4.811314105987549, 4.776134490966797, 4.671504020690918, 4.7004547119140625, 4.599708557128906, 4.688370227813721, 4.602414131164551, 4.659353256225586, 4.438632965087891, 4.538754940032959, 4.59388542175293, 4.700619220733643, 4.6245880126953125, 4.6025614738464355, 4.593564510345459, 4.637631416320801, 4.47832727432251, 4.457827091217041, 4.487340450286865, 4.536346912384033, 4.575974464416504, 4.609523296356201, 4.5666303634643555, 4.656867027282715, 4.675882816314697, 4.62631893157959, 4.607324600219727, 4.758053779602051, 4.713614463806152, 4.71875, 4.68999719619751, 4.5878682136535645, 4.609743595123291], 'test_auc': 0.5577018037655457, 'test_acc': 83.05, 'test_loss': 4.840654373168945, 'best_val_auc': 0.5594581662413416, 'best_val_acc': 83.95, 'best_val_loss': 4.438632965087891})\n",
            "('0.5', {'EPOCH': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], 'train_loss_list': [2.9373395442962646, 23.020095825195312, 23.330944061279297, 22.778322219848633, 23.097806930541992, 22.838768005371094, 23.279138565063477, 22.726516723632812, 22.597496032714844, 23.037364959716797, 22.76968765258789, 22.994192123413086, 22.92511558532715, 22.994192123413086, 22.717880249023438, 23.235963821411133, 23.21869468688965, 22.93375015258789, 23.080537796020508, 23.503637313842773, 23.154165267944336, 23.210060119628906, 22.985557556152344, 23.380002975463867, 23.0719051361084, 23.4000244140625, 22.856037139892578, 22.96363067626953, 23.253244400024414, 22.902366638183594, 22.58759307861328, 22.752464294433594, 22.723159790039062, 22.57837677001953, 22.463088989257812, 21.6040096282959, 21.7183895111084, 20.896133422851562, 20.149221420288086, 18.025850296020508, 11.934819221496582, 5.272042274475098, 4.728691101074219, 4.6320881843566895], 'val_auc_list': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5002988643156008, 0.5005977286312014, 0.5008965929468021, 0.49903211831736644, 0.49894986208371495, 0.4963587907236904, 0.4934770806714302, 0.4900844680123786, 0.48670373680929896, 0.4927843003924536, 0.49923593098519203, 0.5029685360766701, 0.509655967872543, 0.5123631119178316, 0.5349068036872728, 0.5382820511414423, 0.5323468069044054, 0.5157228220834226, 0.5119719378289107, 0.5101120329902334], 'val_acc_list': [16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.35, 16.400000000000002, 16.45, 16.5, 16.6, 16.950000000000003, 17.599999999999998, 18.75, 18.8, 18.6, 19.25, 20.0, 20.9, 22.1, 23.9, 29.25, 41.65, 73.75, 83.39999999999999, 83.8, 83.95], 'val_loss_list': [23.11334991455078, 23.11334991455078, 23.11334991455078, 23.113351821899414, 23.113351821899414, 23.113351821899414, 23.11334991455078, 23.113351821899414, 23.11334991455078, 23.113351821899414, 23.113351821899414, 23.113353729248047, 23.113351821899414, 23.113351821899414, 23.11334991455078, 23.11334991455078, 23.11334991455078, 23.113351821899414, 23.11334991455078, 23.113351821899414, 23.11334800720215, 23.11334991455078, 23.113351821899414, 23.11334991455078, 23.099533081054688, 23.085742950439453, 23.07190704345703, 23.04427146911621, 22.94171905517578, 22.767963409423828, 22.47176742553711, 22.46657371520996, 22.489944458007812, 22.305870056152344, 22.07337760925293, 21.87240982055664, 21.524883270263672, 21.00755500793457, 19.513078689575195, 16.135671615600586, 7.266656398773193, 4.615654468536377, 4.469289779663086, 4.434779167175293], 'test_auc': 0.49879227053140096, 'test_acc': 82.65, 'test_loss': 4.793982028961182, 'best_val_auc': 0.5101120329902334, 'best_val_acc': 83.95, 'best_val_loss': 4.434779167175293})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd3wcxfn/33NFp+Yud7mAbdxtGRvb\nhN67aQZCCwESMD0koSX8CCEhkPAFAoFgmjEdgik2EByKAVNdcW8YW7blJlkustqddDu/P3bvvHe6\nk04nnU53et6v173ubj87O8/Ozj47Ozv7jNJaIwiCILQdHMk2QBAEQWhZxPELgiC0McTxC4IgtDHE\n8QuCILQxxPELgiC0MVzJNiAW8vLydP/+/ZNthiAIQkqxaNGiXVrrruHLU8Lx9+/fn4ULFybbDEEQ\nhJRCKbUp0nLp6hEEQWhjiOMXBEFoY4jjFwRBaGOkRB9/JGpqaigqKqK6ujrZpiSMzMxM8vPzcbvd\nyTZFEIQ0ImUdf1FREe3ataN///4opZJtTrOjtaa0tJSioiIOOuigZJsjCEIakbJdPdXV1XTp0iWq\n09daU7F3D8WFG6jYuwd7MLqW1uJJq5SiS5cuVFdXs+D9d3jy6otZ8P47GIY/mM4w/KJF0FqbPYna\nR0GIF5UK0TnHjRunw4dzrl69mqFDh0Zcv9bnY2/xDvw1PrShUQ6Fy51Bh249AFpUc2VkNMmeHxYu\n4Nupj1Dr9eLyeOjcszdn/uYOAN7/59/Zs32raDatU8/e7Nm+tdXYk6h9NAw/iz6cyfz33mL8ORcw\n9oyzcTicAPVqQttCKbVIaz2uzvJ0dPzFhRsw/HVbR4G7g0j7nCgtp2OniHcAsW63sGgrXz/5kF3B\nlZEBmBc40KLZtHFnncvC999tNfZE1JTCneEBBTVeL+hQLSMzCwBfdVWIppQiIzuHU667ha9ee5H9\nu4qp9flwZXjo2KMnp9/0e5wuNx88Ft8FQ0g/2pTj372tCF9VVUuYxpwv53LPX+/H7/dzyYUXcNOU\na0N0r9fHzbfdxrIVK+nUqSNPP/ZP+uTns3vPHn59480sWb6ci847l7/d+6eI29+0dVuY4xfqRalQ\nRyoA4PJ4OPz8i1k+53+U7y41LxhyUUh7ojn+lH24Wx9Z7dpT4/WiDSO4TDkctM8z31wu21XSLJqh\nNXf/5a98MPM92nkyOPWcczn5hBMYPGhgMN0LL79C1x49+P6Jf/HurFn89R8P8fTjj5GZlcV99/2Z\nlatWsWTx4hD77XmybXuI5s7M4sRfXQ/Ap8/9m5rqKtFs2rCjjmPVV5+3Gnsia5kc+4tfYRgGc1+e\nRo33wMg0V4aHieddhNaaee/+h1qfN6g5MzIoOPkMCpcupnRL3RcyO3TrgWEY7N9VXEer9Xr56rXp\ndZYVF27glbtu5ezf380XLz3Lnh3bqPV6+fatV1nz9RfBi4KQXqTsw9368GTnEP7IV1nLm1P7YelS\nBg4axJDhI/BkZHD2GWfwv08/DUk3c+ZMrrzyKhRw5qmn8tV336G1Jjc7m+NOOJHc9h0alafD4WDA\n2PEMGDseh8MhWpgGtCp7ImtOBh9+FEOPOAaHM7RF7XS5KDjlDMaceiZOV2i7zOVyc/j5P2f82ZNx\nW91BAdyZWfzswks58ueXR9ROmXILPQYeQiR8VZW89Zc/ULJpI7Ve80JT6/VSsqmQ1++5PWIaIbVJ\ni66eP7+/klXbymLa1ryNu5lwUOcG1xvWqz1/Omt4vevMmDGD2bNn89xzzwHw8ssvM2/ePJ544ong\nOiNGjGD27Nnk5+cDMGDAAObNm0deXh4A06dPZ+HChSFp7NTXpSW0TbyVFTx7w1V4KyuCyzzZOfz6\nyWkAUbWfFs2PePdx2NmTWfXlHPbu2FYnr049e3PJXx8mMzc37gfK0oWUPNpUV099xOL0BaE148nO\n4cYX3oyqR9MGjB3PnGlTQ5Y5HE4OPfUsOnTtXueigFLs2b6VqddeRp/ho9i9fSuV+/bW6QqC0BFI\ndbRHH4zahSQXheSQFo6/oZZ5oujduzdbtmwJ/i8qKqJ3794R18nPz6e2tpZ9+/bRpUuXljZVEOq9\nYES6KHiysjn7trv5cf63/DD7g5CH5oHnAy/89jqAkGdfAW3ab0IHOgS1TRt59Y+/4+K/PMSHjz8U\n8YIhzxUSS1o4/mRx2GGH8eOPP7Jx40Z69+7NG2+8wWuvvRayzqRJk3jxxRc5/PDDmTFjBscff3xa\nvmkspDb1XRT6DBtJSeFGilavqKNltWuP1pqqsn11tNwueShgf+muUEFrvBXlTLcuGgHszxWuf/ZV\nuRtIIOL4m4DL5eKJJ57glFNOwe/3c9VVVzF8+HDuuecexo0bx6RJk7j66qu5/PLLGThwIJ07d+aN\nN94Ipu/fvz9lZWX4fD7ee+89Pv74Y4YNG5bEPRKEyIw84RR2bvypzsilYy6/Gog8qumoi6+IqLk8\nHoYffTzrF86jYs/ukHy0Nshq146ta1fz2bSn5G4gQaTFw910pq3sp9C6ifeBcn1apIfN9aGUg8x2\n7eRuoBG0qRe40om2sp9C2yPaxeSc2+/ho38/Qlnxzjpp2nftzpEXXc6C998OPjAOfxFNOIA4/hSl\nreynINiJ9BJefW9l2+8GhANEc/xp+QKXIAipTaQX3zxZ2fzqX9Po0qdfnfW1NoKBDSWqacNIi7+V\n01b2UxBiJeLdgEWfYSMpKy2hYu8e6QZCWvyCIKQJke4GMrKyOezs89myegX7du6Q0BMNkJbDOXcV\n7cfw172TcTgVefntkmCRIAjNRX3vHGxbt5atYe8baG2QF6F7qC2Tli3+SE6/vuVNYfbs2QwePJiB\nAwfy4IMP1tG9Xi8XXXQRAwcOZMKECRQWFgLwySefMHbsWEaOHMnYsWOZM2dOs9smCG2NUSecUidI\nHUB2h44R5+hoq6Rliz+cTjNPwb17VV2hx0iY8nXc2/X7/dxwww188skn5Ofnc9hhhzFp0qSQl7Ce\nf/55OnXqxPr163njjTe44447ePPNN8nLy+P999+nV69erFixglNOOYWtW7fGbYsgCFHiETmdrP12\nLnu2b+Wka25iy8plbX78f5tw/DVdx+Laux5l+A4sdGZA/vgmbXf+/PkMHDiQgw8+GICf//znzJw5\nM8Txz5w5k3vvvReAyZMnc+ONN6K1ZsyYMcF1hg8fTlVVFV6vF4/H0ySbBKEtE6kbSGvNj/O+4ZNn\nn+TVu36Dw+nE8Pvb9NvA6eH4P7oTdiwP/u3orQ3V/T4wakKXGbVmmhfOiLzNHiPhtLpdN3a2bt1K\nnz59gv/z8/OZN29e1HVcLhcdOnSgtLQ0GJYZ4O233+bQQw8Vpy8ICUApxSETj+TT5/4NEOzyCY8N\n1JZIyz7+OjgzMLK6ooPTmijI6Wa2+pPMypUrueOOO3j66aeTbYogpDXRxv+3xQe/6dHiD2uZl0UY\n1eOo3EmXGUeA3wsuD1w7F9p1b1K2TQ3LXFRUxLnnnstLL73EgAEDmmSLIAj1M/L4k9m5YX2diWhG\nHHdSEq1KDmnZ4s/Lb0e3fu3p2D0bgI7ds8kbOgg15jJQDii4tMlOH0LDMvt8Pt544w0mTZoUsk4g\nLDMQEpZ57969nHHGGTz44IMcccQRTbZFEIT6iTT+XxtGcMrOtkR6tPijoBxm145hWK3/Y26HktVw\nzB3Nsv2mhGV+4oknWL9+Pffddx/33XcfAB9//DHdunVrFtsEQQjF/uBXa81//nwXu7cVoRxp2f6t\nl7QO2eCvNSjdWk67zplktUt+f348SMgGQUgM29at4fX/93t+dsGlHD754mSbkxBaPGSDUqqPUupz\npdQqpdRKpdQt1vLOSqlPlFI/Wt+dEmZDeItfEATBotchQxg04WcseP8dKvftTbY5LUoi73Fqgd9p\nrYcBE4EblFLDgDuBz7TWg4DPrP8JITDDoRbHLwhCBI78+S+o9Xn5/p3ok9enIwlz/Frr7Vrrxdbv\n/cBqoDdwNvCitdqLwDmJskEphcOppMUvCEJEOvfKZ+TxJ7P0k4/Yu2N7ss1pMVrkqYZSqj8wBpgH\ndNdaB0p4B9D04TX15e1Q0uIXBCEqh0++BIfLyTf/eSXZprQYCXf8Sqlc4G3gN1rrMrumzSfLEb2y\nUuoapdRCpdTCkpKSuPN3OBSGEXdyQRDSnNxOnRl7+jms+eZLdm5Yn2xzWoSEOn6llBvT6b+qtX7H\nWrxTKdXT0nsCxZHSaq2f0VqP01qP69q1a/w2SItfEIQGOGzSeXhy2/HB4/9oEzN3JXJUjwKeB1Zr\nrR+xSbOAK6zfVwAzE2UDWC3+BIRjDhBvWObCwkKysrIoKCigoKCAKVOmJMxGQRDqp3LfXlzuDPZu\n30Z1+X6+fetVXr3rVvZsT8+IuYls8R8BXA4cr5RaYn1OBx4ETlJK/QicaP1PGPYWf0llCb+c/Ut2\nVe1qlm0HwjJ/9NFHrFq1itdff51Vq0LDP9vDMt96663ccceBl8cGDBjAkiVLWLJkCVOnTg3fvCAI\nLcTr99xO5d49wf/pPnNXIkf1fK21VlrrUVrrAuvzX611qdb6BK31IK31iVrr3YmyAcxZt7TWaK2Z\numwqi3cuZurS5nGy9rDMGRkZwbDMdmbOnMkVV5g3OJMnT+azzz4jFV6aE4S2RJf8vmgd+jAwnQO4\npUXIhr/P/ztrdq+JqBl+jb/GQC/3s7x0ORrNf9b+hzWla3A73VG3OaTzEO4YX39oh6aEZQbYuHEj\nY8aMoX379vz1r3/lqKOOiml/BUFoXiIHcMtK2wBubSZIxbaKbfX+b2l69uzJ5s2b+eGHH3jkkUe4\n5JJLKCsrazihIAjNTqQAbg6HI20DuKVFi7++lrm3qpYNWzZz+fwL0dbIUY2mzFfGQ8c8RF5WXtS0\nDdGUsMxKqeDEK2PHjmXAgAGsW7eOcePqhNUQBCHB2AO4vfGn2/HX1nLp/Y80kCp1SfsWv8OheLlw\nOkZY/52hjSb39TclLHNJSQl+ayagDRs28OOPPwancBQEIXn0HjKcnRvW47N1+6Qbae/4lQNWla2g\nJmzqxRqjhiXFS5q0bXtY5qFDh3LhhRcGwzLPmjULgKuvvprS0lIGDhzII488EhzyOXfuXEaNGkVB\nQQGTJ09m6tSpdO7cuUn2CILQdPKHjkAbBtvXrU22KQkjrcMyAxh+g11F5eR2yiS7feqFZpawzILQ\nsngrK3nyqp8z4byLOOLCS5NtTpNo8bDMrQUJzSwIQmPwZGfTtd9BbF2zMtmmJIz0d/xKSdgGQRAa\nRe+hw9j+41r8tTUNr5yCpL3jh8SHbRAEIb3IHzKcWp+XnRt+SrYpCaFNOH5p8QuC0Bh6DxkOkLbd\nPW3C8ZuhmcXxC4IQGzkdO9GpZy+KxPGnLtLiFwShsfQeMoJta1ah03BCjzbh+BPZ4m8oLPPcuXM5\n9NBDcblczJgxIyE2CILQ/OQPHU51RTm7ijYn25Rmp004fuVU+BYvYM3oAlYPGcqa0QVUfD+v4YQN\nEEtY5r59+zJ9+nQuueSSJucnCELLEeznX51+3T1twvH7Fi+g7J7fob1eALTXy5YpU5rs/GMJy9y/\nf39GjRpVJwCUIAitmw7dupPbqXNa9vOnRZC2HX/7G97VkcMyA1QuXAhhbyjr6mo2X3kl2VGConmG\nDqHHH/5Qb76xhGUWBCE1UUrRe8hwtq5ZidYac1LB9KBtNEOjhaVIgXAVgiAkj95Dh1O+u5Sykp3J\nNqVZSYsWf0Mt8zWjC4LdPHaUx0O/l1+KO99YwjILgpC65Fv9/EWrV9KhW48kW9N8tIkWf68nnwJP\nZsgylZlJn6efbtJ2YwnLLAhC6pLXpx+enByK0uwBb5tw/DmHT6D9fQ+jMsyJT5THQ5+pU8mZOKFJ\n240lLPOCBQvIz8/nrbfe4tprr2X48OFN3h9BEFoG5XDQe/CwtHuDNy26ehrC4VC4C8bR56t55HTw\nNOu2Tz/9dE4//fSQZffdd1/w92GHHUZRUVGz5ikIQsvRe8hwNixeQMXePeR07JRsc5qFNtHiV0qh\nlARqEwSh8eQPtcbzr13VwJqpQ5tw/CBhGwRBiI/uBw/EleFJqxe52ozjl0BtgiDEg9PlpufAQ9Lq\nRa424/iVE2nxC4IQF72HDqekcCPeyspkm9IstBnHLy1+QRDipdchQ9Ha4Jnrr2DB++9gGP5km9Qk\n2ozjlz5+QRDiYc/2rcx99QUAfFVVfPvWq7x6163s2b41yZbFT5tx/IEWv27mMA0NhWV+5JFHGDZs\nGKNGjeKEE05g06ZNzZq/IAiJ5fV7bqd0y4HQzLVeLyWbCnn9ntuTaFXTaBPj+Kfd/jVVZb46y7Pa\nZ3DVP46Me7uBsMyffPIJ+fn5HHbYYUyaNIlhw4YF1xkzZgwLFy4kOzubp556ittvv50333wz7jwF\nQWhZuuT3pWjV8pBlWhvk9emXJIuaTpto8Udy+vUtj5VYwjIfd9xxZGdnAzBx4kR5mUsQUoyRx5+M\nOzMrZJk7M4sRx52UJIuaTlq0+L/6zzp2bSmPK+27Dy+OuDyvTy5HXXhIvWkbG5b5+eef57TTTovL\nTkEQksOAseOZM21qyDKHw8GAseOTZFHTSQvHnwq88sorLFy4kC+//DLZpgiC0Ag82Tnc+MKbbFq+\nhBl/vZsL//QAfYaNTLZZTSItHH9DLfMnp8yJqp37u0PjzjfWsMyffvop999/P19++SUeT/PGChIE\noWXI6dARgMp9e5NsSdNpE338iSKWsMw//PAD1157LbNmzaJbt25JslQQhKaSbQVoq9grjj8lyGqf\n0ajlsRJLWObbbruN8vJyLrjgAgoKCiRevyCkKFm57VAOB5X79iTblCaTsK4epdQ04EygWGs9wlp2\nL/BroMRa7Q9a6/8myoYAV/3jSLTWlGzZT3a7DHI7ZTacKEYaCsv86aefNltegiAkD+VwkN2ho7T4\nG2A6cGqE5Y9qrQusT8KdfgCllIRtEAShSWR36JgWLf6EOX6t9Vxgd6K2Hw8StkEQhKaQ06GjPNyN\nkxuVUsuUUtOUUlGns1FKXaOUWqiUWlhSUhJttUZhtvibZVOCILRBcjp2kq6eOHgKGAAUANuBh6Ot\nqLV+Rms9Tms9rmvXrs2SubT4BUFoCoGunuaO+dXStKjj11rv1Fr7tdYG8CzQoq++ORwy/aIgCPGT\n3aEj/tpavJUVyTalSbSo41dK9bT9PRdY0aL5S4tfEIQmEHiJq2Jvaj/gTZjjV0q9DnwHDFZKFSml\nrgb+oZRarpRaBhwH3Jqo/CPhcCq0bt7QzA2FZZ4+fTpdu3aloKCAgoICnnvuuWbLWxCEliXwEleq\nP+BN2Dh+rfXFERY/n6j8GsIw/Cz5eCaL//sOE865gHFnnYPD4WzSNmMJywxw0UUX8cQTTzQpL0EQ\nkk+6hG1oE2/u7tm+lVfuupWFs97EV1nOd2+/1iwz6MQSllkQhPQhXcI2pEWQts+nP0Pxpg1R9W1r\nV2P4D8yRWev1Uly4gem/u55eg4dGTNOt38Ec98tr6s031rDMb7/9NnPnzuWQQw7h0UcfDUkjCELq\nkC5hG9pEi98VJSKm29N8oRuicdZZZ1FYWMiyZcs46aSTuOKKKxKepyAIiSFdwjakRYu/oZb5qq8+\n59Pn/k1NdVVwmTszi+OvmsKwo46LO99YwjJ36dIl+PtXv/oVt9+euvN0CoKQHmEb2kSLf8DY8Tgc\nobvaHDPoxBKWefv27cHfs2bNYujQyF1LgiCkBjnS4k8NAjPoaK0p2byf7A4ecjs2fUIUe1hmv9/P\nVVddFQzLPG7cOCZNmsTjjz/OrFmzcLlcdO7cmenTpzd9hwRBSBo5HTtRWrSl4RVbMW3C8QdQSpkv\ncTXj27sNhWV+4IEHeOCBB5otP0EQkos9bINSKtnmxEVMXT1KqQuUUu2s33crpd5RSsU/Z2ESkdDM\ngiA0hXQI2xBrH///01rvV0odCZyI+SLWU4kzK3FI2AZBEJpCTnAsf+o+4I3V8QcGwZ8BPKO1/hBo\n2ryFzUA8oRdSqcWf6hEABSEdyU6Dt3djdfxblVJPAxcB/1VKeRqRNiFkZmZSWlraaOeYKi1+rTWl\npaVkZib+XQNBEGInHcI2xPpw90LMaRT/T2u914qyeVvizGqY/Px8ioqKaOwkLdUVNdT4/BSXtX6H\nmpmZSX5+frLNEATBRjqEbYjV8fcEPtRae5VSxwKjgJcSZlUMuN1uDjrooEanmzdrAws/KuT6J49D\nOVLzibwgCMkjHcI2xNpd8zbgV0oNBJ4B+gCvJcyqBJKZ4wYN3qraZJsiCEIKkg5hG2J1/IbWuhY4\nD/iX1vo2zLuAlMOTY97keCtrkmyJIAipSqqHbYjV8dcopS4GfgF8YC1zJ8akxJKZbZpdXSEtfkEQ\n4iPVJ12P1fFfCRwO3K+13qiUOgh4OXFmJQ5Pjun4pcUvCEK85HTomNKjemJy/FrrVcDvgeVKqRFA\nkdb67wm1LEF4sq2uHmnxC4IQJ/awDalITKN6rJE8LwKFgAL6KKWu0FrPTZxpiSEzJ9DVIy1+QRDi\nwx62ITMnN9nmNJpYh3M+DJystV4LoJQ6BHgdGJsowxJFsMUvXT2CIMSJPWxDKjr+WPv43QGnD6C1\nXkeKPtx1uhy4PU55uCsIQtyketiGWFv8C5VSzwGvWP8vBRYmxqTE48lx4ZWuHkEQ4iTVwzbE6viv\nA24Abrb+fwX8OyEWtQCZOW6qK6XFLwhCfGSneITOmBy/1toLPGJ9Uh5Ptlta/IIgxM2BsA1p2OJX\nSi0Hoo5X0lqPanaLWoDMbBe7d1Qm2wxBEFKUVA/b0FCL/8wWsaKF8eRIi18QhKaRymEb6nX8WutN\nLWVIS5KZ46K6sial58wUBCG5pHLYhljn3N2vlCoL+2xRSr2rlDo40UY2N55sN0atptZnJNsUQRBS\nlFQO2xDrqJ5/AkWYoZgV8HNgALAYmAYcmwjjEoX97V23x5lkawRBSEXsYRtSrecg1he4Jmmtn9Za\n79dal2mtnwFO0Vq/CXRKoH0JQUIzC4LQVHI6dgqGbUg1YnX8lUqpC5VSDutzIVBtaSkXpUhCMwuC\n0FQCb++m4lj+WB3/pcDlQLH1uRy4TCmVBdyYINsShoRmFgShqaRy2IZYX+DaAJwVRf66+cxpGSQ0\nsyAITSWVwzbEOqon3xrBU2x93lZK5SfauEQhoZkFQWgqqRy2IdaunheAWUAv6/O+tSwlcWU4cLiU\ndPUIghA3qRy2IVbH31Vr/YLWutb6TAe61pdAKTXNujtYYVvWWSn1iVLqR+s7KSOClFJkZrvl4a4g\nCHGTymEbYnX8pUqpy5RSTutzGVDaQJrpwKlhy+4EPtNaDwI+s/4nBQnbIAhCU8np0CklwzbE6viv\nAi4EdgDbgcnAL+tLYE3LuDts8dmYUzhifZ8Tq6HNTSBsgyAIQrxkd0zNFn+so3o2AZPsy5RSv8F8\no7cxdNdab7d+7wC6R1tRKXUNcA1A3759G5lNdKbd/jVVZb7g/yenzAEgq30GV/3jyGbLRxCE9Cen\nQ0dKt2xOthmNJtYWfyR+25SMtTk9fX0hn5/RWo/TWo/r2rXexwmNwu70Y1kuCIIQDXvYhlSiKY4/\nnuAUO5VSPQGs7+Im5C8IgpBUgmEbKlIrbENTHH88l7hZwBXW7yuAmU3IXxAEIakEwzak2APehmbg\n2k9kB6+ArAbSvo4ZtTNPKVUE/Al4EPiPUupqYBPmA2NBEISUxB62oUvvPkm2JnYamoilXbwb1lpf\nHEU6Id5tCoIgtCZyrLd3U+0lrqZ09aQkWe0zGrVcEAQhGqkaoTPWiVjSBvuQTX+NwQt3fk2foZ05\n5VcjkmiVIAipSKqGbWhzLX47TreDQ8Z1Z+OSXRK3RxCERpOqYRvatOMHGPKznvhrDdYvkpGlgiA0\nnlQM29DmHX/Xvu3o1DOHNd9tb3hlQRCEMFIxbEObd/xKKYZM7MGODWXs3VmZbHMEQUgxcjp0lD7+\nVGTwhB4oBWu+l1a/IAiNI7tjp5QL2yCOH8jp6KHPsM6s/X4H2kidgycIQvLJ6dAx5cI2iOO3GDKx\nJ+V7vBStS62HNIIgJJdUDNsgjt/ioNF5ZGS5WPvdjmSbIghCCpGdgpOui+O3cGU4GTiuGz/9UIyv\nWqZkFAQhNlIxbIM4fhtDJvak1mfw0+KSZJsiCEKKkIphG8Tx2+hxcHs6dMuSMf2CIMRMKoZtaHOx\neurjhTu+oarMx77iquCUjCDTMgqCEB3lcJCTYmEbpMVvQ6ZlFAQhHrJTLGyDOH5BEIQmYBh+anzV\nbFyyiAXvv4Nh+JNtUoOI4xcEQYiTPdu38spdt7J3x3a0YfDtW6/y6l23smf71mSbVi/i+AVBEOLk\n9XtuZ9emQrRhAFDr9VKyqZDX77k9yZbVjzh+QRCEOOmS3xetjZBlWhvk9emXJItiQxy/DZmWURCE\nxjDy+JNxZ2aFLHNnZjHiuJOSZFFsyHBOG/Yhm4aheemub+jarz1nXD8qiVYJgtBaGTB2PHOmTQ1Z\n5nA4GDB2fJIsig1p8UfB4VAcMr4Hm1eUUrVfhnMKglAXT3YON77wJr978wMmnHshyuHgV/96Hk92\nTrJNqxdx/PUweGIPDEPz40KZllEQhPoZMHYC2jDYuGRhsk1pEHH89dCldy5d8nNZKxO0CILQAD0G\nDCK7Q0d+Wjgv2aY0iDj+BhgysQfFm/azZ0fqTLIgCELLo6y+/Y1LFuGvrUm2OfUijr8BBh3WHaVg\n7TyJ0y8IQv0cPHYCvqpKilatTLYp9SKOvwFyOljTMs6TaRkFQaiffiNH43Jn8NOi1t3dI44/BgZP\n6EH5bi/b1qdO9D1BEFoetyeTvqMK+GnRvFY9+bo4/hg4qKArbo+Ttd9Ld48gCPUzYOwEykqK2bW5\nMNmmREUcfwy4M5wMOLQrPy0uptbX+iPvCYKQPAIvb7Xm0T3i+GNk8IQe+Kr9bFy2K9mmCILQisnp\n2ImeAwe36n5+cfwx0vuQTuR28kh3jyAIDTJg3AR2/PQj5btLk21KRMTxx4gKhHBYtZtKmZFLEIR6\nCHT3bFi8IMmWREaCtMXItNBTukoAACAASURBVNu/Dk7B+MLtXweXy3y8giCE06VPPzp0685Pi+Yx\n6sRTk21OHaTFHyMyH68gCLGilOLgsePZvHwpNdXVyTanDklx/EqpQqXUcqXUEqVU649oJAiC0EgG\njJ1AbY2PTcuXJNuUOiSzxX+c1rpAaz0uiTYIgiAkhPyhI/Bk57TK0T3Sx98MaK1RSsWV1v7swE5g\n1q/WoslzDCHVqe9cS0T9drpc9C8Yy0+L5mMYfhwOZ7PnES/Jcvwa+FgppYGntdbPhK+glLoGuAag\nb9++LWxe4/j2nZ/42XkD4nL+8Tw7SIYW7wWqvhMq3hOxpU/ghvKE5r9gJmMfW5pENHrqK5v6zrVE\n2TJg3ATWfjuXHevX0euQoVFta2lUMuJJKKV6a623KqW6AZ8AN2mt50Zbf9y4cXrhwuQ+CohWMZxu\nB/4aI0KKAwe/vkqV7g+Ho+1jQ/seb7obph5frz3xnuDxHqf69iPe/Brax3ho6EKTCMeYiLofb71J\nBFntM6jYsxdf2VTAiTPzCFyZh5LdIRNombtrpdSiSN3pSWnxa623Wt/FSql3gfFAVMffGoh2MLTW\n/Pu6zyNqgQPblkcExbvvTSmzeC608d4NNUQi8mtJJ9yUOpyoMq2P1nSuVezZSU3FB4AC/Pirv8Wo\nWY02zsTh7ITWBrXVi/B7F+D0jMeVeWiInYbhZ9GHM5n/3luMP+cCxp5xdrN1F7W441dK5QAOrfV+\n6/fJwH3NnU/F9/PYcu21aK8X5fHQ5+mnyZk4obmzabB757t31zd7nkJ0Fny4sVWd/ImgpZ3wf59a\nFpthQgi+/W+Arsbs2QaoRftL8JW9hNNzKP6adWBUALXBi4I750wA9mzfyvv//Dt7tm+l1uvl27de\nZc3XX3Dmb+6gU8/eTbatxbt6lFIHA+9af13Aa1rr++tL09iunorv57FlyhS0bfysysykz9SpCXH+\nT06ZE1VzuBRGbesNz5p2KA6cZ0Kz0KV3DqVbZQa6xuLd/x90bVEExQFE7h4GB/1GjaZo1XL8tbUh\nilIOMtu14/pnX43ZhmhdPS0+nFNrvUFrPdr6DG/I6cfDlmuvDXH6ALq6mi3XXtvcWTXIdU8cV68e\nuAWPtLw1aanC1Q8dlWwT0o6f/7/mbywlg5au366MEYA7bKkbd/bJKGevKKnc+CorUc66XTpaG+T1\n6dc8tjXLVloZ2utt1PJkkiojNBLxUDQRD34zc8NPtOYhEQ9p480vXbqs4i3T+rT6yibekWLx2lK5\nbwBUfR56B6ocODIG4AJqKksA+9y8btzZx3HJ/Tey6qvP+fS5f1NTXXVAzcxixHEnRd2HxpCWjl95\nPBGdvPJ4EpJfQxW4IT0VaOlhiYkazhivs0nE/sebX31di/HS1DrcWt4Naai8o5EoW5S6IaIt2hjC\n3ggXhZwuQwAzyNucaVND0jmsydybg6QM52wszdPH76HP1MQ84BVaF+k+Br6lx78LqUu0Pv60dPwQ\nOqoHoP3Zk+j9978nwjxBEIRWSasax98S5EycwJClZnCkLTfcSMUXX2JUVuLIzk6yZYIgCMmlTYRl\n7nL1Vfj37WPvO+82vLIQlYrv57FmdAGrhwxlzegCKr6f1yq11miPILQm0rarJ5zCiy+htriYAf+b\njXKl7Y1Owqjv3Qggotb74YcxfD6233lnyMN25fHQ88EHUW4X235/W6O2WW9+/3yUrNGjqZw/n223\n31Enz17/9xDK4WTr737XbHk2pOVMnFDvy4TxaoIQC22ujz+c/Z9+StGNN9H7kYdpf/rpzWRZ+hHN\n2awZXRB5OKzDAVqbn3Ql8HZ2pH10Ok097GUbAJWRQc8HH2D7H/7Yai4mQtuizTt+bRhsOP0MHNnZ\n9H97RtxhlNOBaI4hUqsehwNX9+7Ubt+ePIMbQfc//IGdf/tbss2IDaXiupjkP/M0RVOukwuG0CBt\n3vED7PnPf9hxz5/oO/0FciZObAbLUo9oXTZ5119HyWOPg99fN5HDYTqiCFrg3Yj63ptoSW3I0iVR\n704Sk2cGaNC+CC8OuVwRnXfCCLztGek4ZWSQ/+QTFN10c1wXDJBuqVREHD9geL2sP+FEMocOpe+z\ndaYAaBNE7bJpgL7Tpzd7/3citGh3Lsmyxz6k2E6DFxqtI19MnM7IF+emUN+FPSODQV/NpWrVKoqu\nu17uMlKMVhOrJ5k4PB46X3YZFV99RfXatck2J6GEjzIp/+JL9s+ZU6/Tj/Zms/J4yJk4gT5TpwbX\nUR5P8MRuTRrQquzp8/TTqMzM0PLMzKTP00/Xrz3zTESt7/PP13ucor6dXt+ABsOIejHRPh/rJkxk\ny5VXRYx/tfmqq9h89dWRY2Ndcw37Zs82LwpWvdNeL1umTKHi+3kHLtARNJCRUomkTbX4Afz79vHj\nccfT/qQT6ZXiL3Q1qq++AQLpWzKqaVuhuUf1xHtHE8/dBy4X3X7/O4ofbOZzpYG7jPqeY8hIqdiR\nrh4bW26+mfKPPwFo9Qe/USe/x0PHyZPZ8/rrZisuHLebPk/9m6Ibb4rrhBJaDy15wahvVFdDF41m\nf8bhdNLl6qvYPf3FkK6w5ugiTEfE8VuEh3KA5B/8xp6ovf/5T7bedBO6pqaerUZm6JrV4tzbME1q\nKbfUXUYinmPU9+DbGhSQjojjt6iv5ZLIg99Y5979j39kx333QRzOvb7opOlawYXE0yq6pTIyIj/0\nbiJD16xu9m22BsTxW6weEn2m+0Qd/GiVv8c997D9nnviux2OchstffVCa6O5Lxhxj5SqR0vXBpE4\nfouoLf6MDIYsWxr3duur3PEOoVRud8TunFicu3TnCKlOc99F1Kel67khjt8i2ogXZ/duHDxjBq6u\nXZtlm8rjofMvf0ntrhL2vf1O1LTi3AWh8ciontgQx28j/OB3u+33FD/8CBl9+9LvpRdxdujQqO3V\n16J3tG+PUV4ecZSNOHdBEBKJOP4GKP/mG4qmXIe7Xz9qNm9G+3wxO9r6nhsMWbmCygULxbkLgtDi\nyJu7DZB7xBF0ufZafOvXB0cNhL9JGA2VEXk+T+XxoJzOmN40HbJ0CUPXrGbI0iXi9AVBSCgSmN5G\n6bPP1lmmq6vZcu21UZ/6+8vLcfXJp+anDSHL7Q+UIHRGMEEQhGSS1i3+DSXl9L/zw5jXj9ZPH225\nv7yCLb/6NTWbNpN3801RW/SCIAitibR2/I9/9iMAd769jL2VDb/0ETXAlVJULVsWGjRq1GgKL76Y\nqhUr6P3oI3S9/vo20V1TUlnCL2f/kl1Vu1q1JghCdNLa8f/tvJFce8zBvLWoiBMe/pJ3fyiivofZ\nkaIl4nbjaN+OwgsvMqMQBiIJ+nz4fvyRvClTaH/SSYncjXppaYc6ddlUFu9czNSlU1u11pR9TAdN\nEOrDee+99ybbhgZ55pln7r3mmmsanc7tdHDUoK6cPKw7Cwr38OK3m1i4aTeH9u1ELfu44bMbOLL3\nkWS7swHIyM8nq2AMZR99BH4/yuOh7zPP0O222yh9/vmIcT6qli4l77opMdlTUllSJ8+mao8seoTP\nNn1GVW0VR+cfHbP28MKH+WzzZ5R5yxjTbQzlNeWU+crY693Lo4sf5auir9hevp1eub3YWr6Vov1F\nLCtexpNLnsSv/azbs46Ono5s3LeRVaWr+G77d7y44kUMDNbuXouhDVbsWsHinYv5autXvLb6NQwM\n1uxeQ7mvnMXFi5m3Yx6fb/6ct9a9FdQqaipYuWslS0uW8u3Wb3l19avBbWY4Mli/bz1rStewcMdC\nXlj5AoY2WLtnLZ2zOrOjfAeb92+mqLyIreVbeXLJk3y37Tu27N9Cz9yelFSWsKtqF6VVpTz+w+N8\ns/UbdlTsYGDHgez17qXMV8Z+734eW/wYc4vmUlpVysiuI6mqraLaX4231stjix/j8y2fs9+3nyN6\nHQGAQqGUivtYJEJLRF1L1HZbk5Zu/PnPf95+77331pl8JD2Hc049EnYsp8Tp4LauefxfyS7y/Aa7\n2w3mmP1/wVtrUFDwGWsqPubCwRdy98S7G9xkLKEeSipLuG3ubfzfMf9HXlZenfX+8v1feGvtWxHz\njKb5/D7u++4+Zv00i5P7ncylwy6loqaCipoKdlbs5NFFj1Kra3EqJxcPuRi3002Nv4YyXxkfbPgA\nQxs4cDC0y1C8fi/7ffsp85VRVVsVa2kmDIVC0/rrXyw4cGBw4F2NTp5OeFweXMqFUoqi/UVoNArF\n6K6jyXZn43a40Vrz9bavMbSBUzk5a8BZdMjoQIYzA5/fxyurX8Gv/biUi5sPvZlOmZ1wO9xU1VTx\nt/l/o8aowe1w88BRD9A5szMO5cCpnExfOZ05m+dwYr8T+fXIX+NQ5s29Qzl4Ztkz/K/wf5zW/zRu\nGHMDDuUIfh5f/DgfbPiASQMmcevYW1FKoTCnKVUoHl70MDPXz+S8Qedxx/g7cCpnMO398+5vdP1u\nbVq60bbG8X/wW/jhZf7QKZcPcnOYWFXN0d4advUcRfH+reyoKWNhViZaKVxa827RNvp1GYa67uuo\nm4wluFukClVVW8Xe6r1s3LeRG+fcSI1Rg8vh4srhV2Jog/2+/RRXFjO3aC4GBgpFt6xuVBvVVNRU\nUGs0Lo6Px+nB7XDj8/vwGQeea3TL7sbIvJHkunNZVbqKn/b+hIHpbEZ1HcUZB52B0+Hkvxv/y+Kd\ni/FrP07l5Ge9fsZlQy+joraCO+beQY1x4C3jDEcG006ZhkM5+OXsX4bk53F6eHfSuyilOGfmOXj9\n3hBt9vmz0Vpz2jun1dHeP+d9anUt58w8B58/dJuvnP4KfsPPLz76RUh+GY4MnjzhSdpltKNW1/L8\n8ueZWzQ3uB9H9DqCi4ZchKEN3ljzBt9v/z6oje8xnnMGnoOBwXs/vsfCnQuD2phuYzi1/6kYGHy0\n8SOWlSzDr/04lIPhnYdzVJ+jMLTBl1u+NO90MC+0/Tv0Z1TXUdQYNSwrXkZR+QHH3yWrC71yelFj\n1LC1fCtlvrLgfrgdblwOFz6/D79u5giVLUiWMwuX04Xb4QZgd/VuwLx4DOg4gGxXNm6nGzT8UPyD\nWW7KwbG9jyU7IxuHclBj1PC/wv8FL4rnDDyHbHc2TuWkqraKGetmBI/TJUMuIScjBwcOKmoreGXV\nK0HtyhFXkuPOQaGoqK1g2vJp+LU/WA8jNdLShbbl+PfvoORfYzixVxcM26TqLuUiT7nw+SrY43Sg\nLc2pNaPKO5Hb/TYuGDmRQb0M7v72zmDL3W9odnz5Dft+cyPK5vxr3E4+/PVx+Dxfs792H5/kZGMo\nhdKaPL+f/U4X1fXM6e5yuGif0R6f30d5TTlgnhh92/VlYq+J5Kx4j/n+MlZ7MvArhVNrjqys4leu\nrni15vqMCnyOAxl4DIPZ3g5o4DTPPrwOR7NpT7m9vOvwUmPLz21ozjM8aGg12t1XL6Jk6s+aff9b\ng5ZhGLzga0cNmms8FfhsddutNX/3ZZOLg1dqS/gmOytYZyZWVXOBswsG8Ja/lPlZmUFtXHU1Zzk7\nYwCz/Hv4IdMT1EZXeznF2RGOvBX99aP8z9jLMs8BfbjXy7HODhjA51Y9NZTCoTUDfT7GOdvhB+b7\nyynMcKOtc6NnbS39HVn40GzQXnYHJpfXmlzDoKNy40ezBz/VSgU1twa3UmjAizbvr+wT1qt6TrYI\nuA3NeeXl3O3ONxfsWF53pR4jW16b8nWw1yKqHiPRHH96juNv14OpBxfgqN6CAbi05sz9Ffy5dDel\nuXmc1iUr6PQBNLCkXTm68o/s+9JLptYszvRw/7TxTKz28k1GZzZ6IPc8gzvfgoxa8LnggQs0q9t/\ngdtw4MjIwh6UIdvQDCjvzLqsozm3ehYvtvdTq0Kd9EdVmVBRw2meMnNGIkCj2bFvI1OKd6N7TeDV\n0i/xW+n8SvF9Vhb3dhnLU5Ub0NUVIbttKMXUjqbTMKrLmlVbWruPGn/oyKgah2KJ2xwJ1XJaRj2a\nG6rLmNohF8MbYT86tEOj49SIU4u2zdzo6drnmul8oZpWilntzHTaF3rsAebltudady/mlZeH1JmF\nmZn8NXcwWsNdFYtDtCWeTB7MHYLWcH+YttLj4eHcoeR1m0BJh6E8GqavzfDwWO4wtIZnKxYHG1mG\nUmxyZ/B07nC0hvcqFgfPN60UpU4Xr+aONC9u5YsPOGylqFEOXs4tQKPraA6t+TB3rHmnWL4Ir+OA\n5jE0s3PHYhia0ytsGuAxNO+1M9OdW744qNU4FO/l5jKl/WDyHG4oWQN+W9wspxu6jwJ0FG1kPdoI\n84LUaG0k7N9pftfRMyB/fJ3jHg9p2eIvqSzhtLdPxWvvelAuZve9gKe2f8G73m3UqNDW4pk1Dgb5\n4TWXj6IMd8j2cg0nfbWHtY6KYMUHs0K9U9uL6u5juKT0wzqV7Sb/OWzwDWKb8QyLcvbVaaGOKu+E\ny6FYnL27jnasryOlmX1YrpfXsXWMrxebnfvY4a6ss++9fB5Asy2j7vDV/JoMFLDFXVfr7/eggI3O\nut1ZA4wMnvH2ouuOr1G2y5vGwb6uY1HaoP2uxShbf71GUdlhEEobZJX9FKaBL6sryvDj9u7G3k7T\ngFZu0AYKP41rw5lM7tWDtZ66b1MP9pr7nc7aaK+Xd3Nz694NlZebd0pxaHeX7uEvXTo1+3Zbk3Z3\n6Z465dnqcGXCLcugXfeYk7SpFv/UZVMxwh4aGkoxNdNgaU57anzbQ7Qah2JVpof7dlVQ6K7mbbcr\neDt7enkF9+/azV+7dOLH3Fz8Nk9kAC9Vr0NvWoeRmxuaH7Cl6hX+XLqHyb16UOPIqJPnfs8uQFPj\ncNfRNqsS8JZQ46mbbp/axCdFOwDTUSrruxYXXkc2Wiky/FVk4AtqXjyUO3LRGnJ0OVl4TU1DBR72\n6PZooJPaTy7VKAWGhjKyKdad2M1GXCqbjpTjsLRSctm8cy9+HPRTHejK3qC2TXdmze4cDBwMVnnk\nq104lcavFYW6Bwv3D8aPYqxjHQPVNpxKU6sVa3RfvjJGYaA4yrGMYWozLmVQqx0sNw7iE2MsoDjR\nsYhRjg1BbYkxgNmG2RoavQnudMynwPFTUP/BGMhswxz5cqdjXohmpj0KhbbS2bd7MJ8Y5uiduxwL\nGG3TlhoH83EULbBNM79QWxYbA/nIOAaN4g7H94xxrA9qi4xBvG+cAMDvHd8xzrEuqC0wBvOecQoA\nv3V8zXjH2qA2zxjCu8ZRfNT3G2ocoXcKNQ7Fkm4Dzd/VO+tq3S2tKop2zDUsXfNMdL2+tNG0+uzp\nNsDSiuPQNDXVJXW1rgebv71RtImXwvIZsGUeaD8oJ/SdACPON1dc/naYNtHUlDLTbf4+VBt5gZXu\nrcZpI86HgO9aPgO2zDd1ZwYUXNoop18fadninzxrMmv3rK2zfHCnwcyYNMP888FvYdELMPZKOPMR\nwLpTeOtEvLZWrUcrZg+ZwpRNM1gbVqEABrc/CBwu1u79sa7Wrh8zhl0P+7bA4pdg5yrMS4ID8gZB\n/yPNA1r4FRSvPlAB+h0Bh10Nnlyo9cFbV4DfBy4P/PoL6JBv/q7cDY8XQG113dbA/h3w2OiYtdrs\nrvj8BjV7t9H+6cNQ/moMZyabL/+Omqyu1BoaVb6DQ944Eoffi+HMZPnkudRkdUUDropiRr9zNA6/\nF78zk6XnfUlNlhni2l1ZTMG7xwTTLT1/bogWSBfQfJl5ddL5nZn8cO6X+LLyQJvaoTOPxWlpC87+\n3LRFm6dNRlUx42cdF9TnnTUHn5VnRlUxE94/Pqh9H6ZNtGmBdEqpOtucP8nMUylwVxVz2MwD2sKz\nvziwj1XFjLPZuugcU1PU3Y/F535BbVa3oC1jbPu/zCo3pcx0o94+OuRY1Gab6VyVxYyccRQOvxft\nykQ1oV6EOJp404rW/OUdI22qxR907vVxzO1QshqOuSO4aOqyqRgOR0gIZcPpZCq7mXHRnIYPRISL\nSZBhZ9vSZsAV70eoAH6zn+/850K3O+Zyc7sFl0H3YQeWt+9ptgIWvVC3NdCuR6M0F+ByOqBbXxhj\nao4xl9K//8G2nWgPYy4LaqOHDrZpnWGjqTnHXMqhw4fYtC5QeCDdmGGR09XVDqRzjrmUcSPs28yD\nzQe0iaNs5QJAV9hyQP9ZwXCb1g2KDmhH1KOFpgvd5uGjh4VqNnsmjLIP/w21dfzI6NphI+xa6P7X\nKbcN0Y5Fp+BxUk2sFyHEm1a05i/vpqK1bvEPcCqwFlgP3NnQ+mPHjtUtwfkzz9cjpo+o8zl/5vkH\nVnr/Vq3v7Wh+h1O2Xetpp2pdtiNyBvWljXe7okUv79ZkTzporc2edNdi0RsAWKgj+NQW7+pRSjmB\ndcBJQBGwALhYa70qWpqWiMcfwv4dMONKmDy97lW2Pi1Z2xUEQYhAqxnHr5Q6HLhXa32K9f8uAK31\nA9HStLjjFwRBSANa00QsvYEttv9F1rIQlFLXKKUWKqUWlpTUfagqCIIgxEerjc6ptX5Gaz1Oaz2u\naxwToAuCIAiRSYbj3wr0sf3Pt5YJgiAILUAyHP8CYJBS6iClVAbwc2BWEuwQBEFok7T4OH6tda1S\n6kbgf4ATmKa1XtnSdgiCILRVUuLNXaVUCbApzuR5QLQpilpaa232pLvW2uxJB6212ZPuWix6ffTT\nWtd9SBppcH86fYjyAkMytNZmT7prrc2edNBamz3prsWix/NptaN6BEEQhMQgjl8QBKGN0RYcf52J\nhpOoJSPPtqwlI89015KRZ1vWYtEbTUo83BUEQRCaj7bQ4hcEQRBsiOMXBEFoazT3MKHW9CFK3H9g\nGlAMrIiQpg/wObAKWAncYtMygfnAUkv7c4T0TuAH4IOw5YXAcmAJYcOzgI7ADGANsBo43Fo+2Fo/\n8CkDfmNLd6tlxwrgdSDTpt1iLV8J/CbSPgOdgU+AfYAPWGXTLrDSamB3WLqHLFt3A96wdH8BlgGl\nlrYmQhnNt7a72rbsXszQHaVADVAYluYmYC9QC5TYlr9plU0p4AeqbFoB8L1tmz/ZtNHAd9Z+7LK+\ng8fbKpu5QCVQbh2XW2xls9bahw1h6R7CrG/l1vGyp/uL9X+/pa8ltH71sdJqy55bwspmpZV2M3Xr\n5v8DKoBqa39usZVPIJ0PqLJpBcBiS6uy9uUWW/l8b+3/PsvuP1vaQdYxrLaOySqbdiPwk7UPgfoX\n0F7FDMleiVl37NrzmPWm0tpmMD/bubfDOsb2dNMxz60Kax9+smkKeNBaXg1st2lfYdabpVa57Avb\n7gmY53GFdax+tGnHW+W2ArNufWgrl3nWMXzTsjnoC6yyCRzfbmHaq5j1YQXwQpj2vGXnMkw/kdtk\n35hs55yoD6YD/gk4GMiwCm6YpR0NHEpkx98TONT63c6qqIF0KlDogNs6yBPD0v8WeI3Ijj8viq0v\nAr+yfmcAHaPszw7MFzLAjGi6Eciy/v8H+KX1e4RVgbIx387+FLg4fJ+BfwB3WuXxOKEOdSjmhecH\n4NKwdCdb2z0a88Szp2tvK+N/ALvD9qMPptPYTl3H//tIxwY4ztqHEyxtdYTyORp4GdhpW/YxcJql\n3QRU2LQFwDHW8b4X0ykHj7dl+/1WfncCj9q0ocCRwEJgXFi6kzHjTx0K/D0sXXsrv0OBmzFPaHv9\nGgt8i/myYj9bukDZRKybVvnMBSbYHJB9u4E8Hwb+akv3MXCJpZ2O6QwDWqB8coGrrLKYB0zErGs/\nt7SpwA02bQzQ39qHPGzniZWHstK9HpauvU17BPgDtvPLKufXMZ2wfZvTgclEOC+BK4GXgHaW1ouw\nc9bK8z3gF2Fp11nHORe4HvMcnQf8DDO68CGY5/pyYKntHPy59XsqppMO+gJb2RRiXqjtWqBsFOZF\nZb5Na2+z9xFimLyqoU86d/WMB9ZrrTdorX3AG8DZAFrruZgtjjporbdrrRdbv/djtjx6W/+11rrc\nWtVtfYJPx5VS+cAZwHOxGqmU6oDpmJ638vBprfdGWPUEzBar/Q1mF5CllHJhOvlt1vKhwDytdaXW\nuhb4EtPhhu/z2cCLVnm8jHnyBcphtdZ6LWZLKGT2bq31x1rrWivdt1Y5BLQy63suZtmEjx54FPg1\nZsutDlGOzXXAg1rrzywtUtqvMMton31zmCfNXOt/jU07BJirtd6OWfbnhx3vs4EnrLrwIuaJuRro\nbZXN15hOKKSeWGVTZKX7HrNlF9DKbPUrB7OlGaxfwF3WvmrMlqZdq69uXgfcp7WeZ2kbCa232zEv\n4Bda+xLQNOC3ttkB06EFtED5lGPeFZ7Hgfp+PDDD0l4EzgloWusftNaFHDjubpv2X9s5NB/oa9PK\ntOnZKoAszG5oN6CtyZsewnS0Idu0lU2k8zJQLvstbW94OswL6DGYzt+eNlB3yq2y2Wlpfuu4VXLg\nXO+plFKBcrG2+1/MC3LQF9jKxok5EZVd+6+1/70xLzbrbFoZgJVHFnXPqcbT1CtHa/1gtgKes/2/\nHPNEDvzvT4QWf9g2+mPeVtuvuE7MW8Ry4O9h68/AbLUdS90W/0bMK/ki4Brb8gLMk2A65sn5HJAT\nwZZpwI1hy26x7CgBXrUtH2pVnC6YF4TvgH+F7zOwN2xf/RHy/QI4K1pZYbbEt4Qtux/TiawltFV/\nNvCY9buIui3+Qszb2f8Q2n20BPgzZovre2xdNrZ1jrbSrggrh82WLTuAtTbtW+Ac6/dvMbs7gsc7\nrGwU5sUvvC58gdkSrVNPLP19zG62oGYrmxWYLe1AfvayKcRsHQY0e9lMAzqF2Wovny+BSRFsPRrz\nDsWezl4+W4EjbNq3mA7daWka8w4mD7NBhaWtxHSG4edCIWZrONJ54sF0nJV2DbOLYycHusL+bqvn\nt1r5+cO06Zj1bBlmV6ZdKwX+aO13GeZFJdyWX2Cet0vC0h5lpS/C7CYqt/ZfYd7NfIZ5rs+wth0s\nFyv9h5jdOsdS1xdUYaTQxQAACFlJREFUYDZSImlvY158b7JrtrL5HMhusn9s6gZa64cmOn7Mq+4i\n4LwoekfrIIyw/p8J/Nv6HemA9ra+u2F2Ox1t/R+H2W8duE1/DPhLWNoMzH7b7rZlnYA5QFfMlsh7\nwGU2/WrL/rnAU8A/w/eZJjp+66T6X7RytE6UYut3NqZj6mD9D3f83TFPbAfwBLDHpq3AvHApTAfp\nwxqKbFvnKcxuDPv+PY7ZkgezW6Hcpg3B7OpYBPwJ8yQPHu+wssm1jtF5EcrmqEj1xCqbWdHqkJXn\nNsyWdHjZbMJ0ROdFKJv7Mbsv7Lbay+cYzGcr4fY8hXlHYU9nL5/LMR3YeVHKZzdmfT+SUAfXB7OP\nP3guWMsLMZ1hxwjas5j1MZLmBP6N2b3yOeYF62vAZenl9nSY3VgK82LyIvA3m1YO/M5Kdx7mxSw8\nv49sZWDf7jscOCdvs8o8oP3eOnbzMe+U9xF6QTzTWn8FYb7A0gIXikjaKqtsQrSwsrmyyf6xqRto\nrR/gcOB/tv93AXfZ/vcnusNyYzq03zaQxz3A763fD2A6s0LM1mUl8EqUdPfa0vXA9iAT05F8GLb+\n2cDHYcsuAJ63/f8F1oUnQn5/s06kkH3GbCn1tH4fBngjpP2CCI4f+CXmncSQesrxZ0C19XskZous\n0PrUYjrwHhHSHRlIZ/2fDRxnO25eoKtNd2G2hiaG7d8+Dryr0p8IFzZLG2at+1vbsrWYTsWNecIX\nR0j3pVUGv41QNt9jdpHUqUPWNr8EtkcpGwPYE6VsBmK2iH8bXj4cqLe7opTPF2Hp9mE6zUC66ijl\ncwimk7sH0wnu4oAjPtxKGzwXrOWFWM+0CD1P/oTZSHGEa7a0RwMfWNqfMM8ne9msj5LuWFu632M+\nID/I0pS1v3Zb8jAv+PZBEYF9tA8E6IvpkAPbtZ/ruzHr8quBcrH0YsyHyiG+wNJqMe+swrWvrDSF\n4Vp42dTnl2L5pHMff1xx/61+tOcxW6OPhGldlVIdrd9ZmP10awC01ndprfO11v2tvOZorS+z1s1R\nSrUL/MZ8ALjCSrcD2KKUGmxlcwJmJbNzMeaDLTubgYlKqWzL5hMwbxEDtnazvvtitnZei7C7s4Ar\nrN+TCevLj4ZS6lTgdswuheowbZDt70mYThqt9XKtdTetdX+rjHZgnlw7rHQ9belODtvue5iODcwH\nlw5CoxWeiHkcdoSZug2zBQzmRchnszNQPg7MLpl5Ycc7UDbPYzrG6WH7qTAffm+0p7OVzSZgZZg2\nyFa/DOAbe9lY+zYXs6U6KLxsrLSvA9vCbA2Uz/OYD82rIpSPBpaEpQuUz/NWnsHw6EqpblZ97wTc\nba1zEmYd+xy40joXrsDszw6eC0qprlhDxe3niVLqV5j94lO01oZNW6uUGmg7vyZhOveTgEVa6x6Y\nDZMCTGc40rbNnrZ051g2BGx5DzjL0o7BHJkTtBOzzn+COfrGbutqoINSaoKV9iTMhkAg7aNa63ys\n4w8s0FpfapXLZK31XZh3DL8jzBdYWhFmN19Qs8rGCXS2+xDgcqXUQNvxn2SzP36aeuVozR/MB3Lr\nMEf3/NG2/HXME6TGOghX27QjMU+SZRwYRnm6pY3C7Idfhum474mS77GE3sIdjNm9ExgG+sew9Qsw\n+yGXYVbWTjYtB7NV0iFCPn+2KsEKzFtOj037CvMCshTzolBnnzGfAXyG2YL0hmnnWr/91sewaesx\n+4X3WGn8Nu1ty569mM47Uhm/jtnqsef3MmafcJ10mF1dr1hajZU2uE1Mp7wgwv4didlVsQfT6du1\nW6y6sTnS8bbKZqGl7efAUNzTrbIptrQazAtmQFuP2brWHHDAAe1tzCGT2kqzktD6Fah7vrD8AmUT\nGAq4KszWDMxWdyDP9WHb/W+UfTwSs/5oTIe61qbdgtnyrLb2NVjfMevzcsw6s9faj4B2s23/azBb\nxAGtFrPeVFp27sRsRTswL4I/Wsv3WPt4j63OBM49f5gtc6Klw+y6mWtpFVa52Lf5BeYD4DrntHWM\nA9sNDL0NaA9hXhzWYnZLfmArl/lWPm9hdj8da9Nvxqx/tZgX3Q9tWi2mnwocn2mYdy+Bsllu2fcq\nYc+S4vlIyAZBEIQ2Rjp39QiCIAgREMcvCILQxhDHLwiC0MYQxy8IgtDGEMcvCILQxhDHL7RplFJ+\npdQS2+fOZtx2f6XUiubaniA0F65kGyAISaZKa12QbCMEoSWRFr8gREApVaiU+odSarlSar7t7cn+\nSqk5SqllSqnPrDejUUp1V0q9q5Raan1+Zm3KqZR6Vim1Uin1sfV2KEqpm5VSq6ztvJGk3RTaKOL4\nhbZOVlhXz0U2bZ/WeiTm25n/tJb9CzOU9SjMtygft5Y/DnyptR6N+Tp+IPzBIOBJrfVwzLdcz7eW\n3wmMsbYzJVE7JwiRkDd3hTaNUqpca50bYXkhcLzWeoNSyg3s0Fp3UUrtwgxsV2Mt3661zlNKlQD5\nWmuvbRv9gU+01oOs/3cAbq31X5VSszFDAbwHvKcPxJMXhIQjLX5BiI6O8rsxeG2//Rx4rnYG8CTm\n3cECazIdQWgRxPELQnQusn1/Z/3+FjNyIphTUn5l/f4MM+AXSimnNbPa/2/vDm0QCIIoDL8XFJIC\n6IJmkBcUgqAIfSAxmCsCRwuEOuhhELMkJGyCOkHm/9xuTs++nVx2utqLoMuIuEk6Kic8fd06gKmQ\nMlDd3Pb9Y32NiPcvnQvbD2VqX7e9naSL7YNy8tnQ9veSzrY3ymS/Vb4W2jOTNLbDwZJO0R+3CUyC\nHj/Q0Xr8q4h4/voW+De0egCgGBI/ABRD4geAYij8AFAMhR8AiqHwA0AxFH4AKOYFIzOtUt9BPBYA\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}